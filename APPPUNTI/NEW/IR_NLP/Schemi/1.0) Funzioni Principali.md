
##### Linguaggio Naturale, IR e NLP

* **Linguaggio Naturale:** Complesso e multimodale, al centro di IR e NLP.
* **Recupero delle Informazioni (IR):**
	* Trova dati testuali (non strutturati) rilevanti a una query in grandi collezioni.
	* Utilizza modelli di recupero per valutare la corrispondenza query-documento.
* **Elaborazione del Linguaggio Naturale (NLP):**
	* Sviluppa sistemi automatici per comprendere e generare linguaggio naturale.
	* Affronta sfide come ambiguità (morfologica, sintattica, semantica, pragmatica), multilinguismo e grandi dataset.

##### IR vs. Altre Discipline

* **Obiettivo Comune:** Facilitare la ricerca di informazioni (es. sul Web).
* **Attività Comuni:** SEO, crawling, estrazione di documenti.
* **Differenze:**
	* **Web scraping:** Estrazione di informazioni.
	* **Ricerca di schemi:** NLP, Linguistica computazionale.
	* **Scoperta di informazioni sconosciute:** NLP, Estrazione di testo.
	* **Discriminazione del testo:** NLP (Machine Learning).
	* **Comprensione del testo:** NLP (Machine Learning, AI generativa).

##### Topic Detection and Tracking (TDT)

* **Definizione:** Acquisizione e analisi incrementale di dati (es. news feed) per identificare topic emergenti e obsoleti.
* **Caratteristiche:**
	* Analisi incrementale dei dati.
	* Supervisionato o non supervisionato.
* **Difficoltà:**
	* Task incrementale (riconoscimento di nuovi e obsoleti topic).
	* Risorse computazionali limitate.
	* Definizione di "topic" (insieme di termini).
	* Tracciamento del segnale (dati in ingresso).

##### Modellazione di Topic Stocastica

* **Descrizione:** Tecnica che usa modelli probabilistici per analizzare grandi quantità di testo e identificare i topic principali.
* **Principio:** Ogni documento è una combinazione di topic; ogni parola ha una probabilità di appartenere a un topic.
* **Applicazioni:** Scoperta di temi principali, analisi della loro distribuzione, classificazione di documenti.
* **Esempio:** Latent Dirichlet Allocation (LDA).

##### Relation Extraction

* **Definizione (NLP):** Identificazione di relazioni lessicali tra entità nominate.
* **Relazione con NER:** Richiede prima l'identificazione delle entità nominate.
* **Metodo:** Ricerca di pattern frequenti.

##### Summarization

* **Approccio Tradizionale (anni '90):** Estrazione di parole chiave.
* **Guida al Processo:** Utilizzo delle proprietà del documento per guidare la summarization.

##### KDD Pipeline in NLP

* **Fasi Sequenziali:**
	* Indicizzazione degli elementi costitutivi.
	* Rappresentazione dei contenuti informativi.
	* Apprendimento a valle del *result set*.
	* *Feature selection* (possibile utilizzo del machine learning).

##### Valutazione dei Risultati

* **Criteri:** Basati su statistiche (es. *accuracy*), con limitazioni.
* **In assenza di *gold standard*:** Utilizzo di un *silver standard* generato automaticamente (es. GPT-4).

##### Funzioni Principali di un Sistema NLP

* **Compito Principale:** Estrazione di informazioni da testi.
* **Macro Categorie:**
	* **Indicativa:** Rivelazione di elementi per determinare la rilevanza rispetto alle query (fondamentale per esplorazione e retrieval).
	* **Informativa:** Creazione di un surrogato del testo (o porzioni) senza riferimento al testo originale (valido anche per il retrieval).

##### Browsing

* **Descrizione:** Esplorazione di collezioni di testo senza query predefinite, utile per utenti con bisogni poco chiari.
* **Caratteristiche:**
	* Indicazione di documenti rilevanti da parte dell'utente.
	* Supporto all'annotazione.

##### Estrazione di Informazioni

* **Descrizione:** Recupero di informazioni specifiche da documenti già identificati come rilevanti.
* **Esempi:** *Web wrapping*, estrazione da siti di *e-commerce*.
* **Processo:** Identificazione di informazioni specifiche all'interno di un documento rilevante.
* **Tipi di Template:**
	* *Slot*: Spazi da riempire con sottostringhe.
	* *Riempitivi pre-specificati*: Valori fissi.
	* *Multipli riempitivi*: Slot con più valori.
	* *Ordine fisso*: Sequenza fissa degli slot.
* **Modelli di Estrazione:**
	* Specificazione di elementi (es. espressioni regolari).
	* Modelli precedenti e successivi (contesto pre e post-slot).
	* Estrazione di termini da un modello (definizione a priori di template e pattern per ogni slot).

##### Recupero di Documenti

* **Descrizione:** Selezione di documenti da una collezione in risposta a una query (solitamente in linguaggio naturale).
* **Processo:**
	* Classificazione dei documenti per rilevanza.
	* Abbinamento tra rappresentazione del documento e della query.
	* Restituzione di un elenco di documenti pertinenti.
	* **Modelli:** Booleano, spazio vettoriale, probabilistico.

##### Applicazioni di Base del Text Mining

* **Scoperta della Conoscenza:**
	* Estrazione di informazioni.
	* Distillazione di informazioni (estrazione basata su struttura predefinita).
* **Filtraggio dell'Informazione:**
	* Rimozione di informazioni irrilevanti.
	* Applicazioni in web personalization e sistemi di raccomandazione (anche *collaborative based*).
	* Utilizzi tipici:
	* Categorizzazione gerarchica.
	* Riassunto del testo (Summarization).
	* Disambiguazione del senso delle parole (WSD).
	* Filtraggio del testo/informazione.
	* CRM e marketing (cross-selling e raccomandazioni di prodotti).
	* Filtraggio di notizie e spam.

##### Tecniche Specifiche

* **Categorizzazione Gerarchica:**
	* Organizzazione di documenti in struttura gerarchica tramite tassonomie.
	* Navigazione strutturata per affinare la ricerca.
	* Flessibilità nell'aggiunta/rimozione di categorie.
	* Caratteristiche:
	* Analisi degli hyperlink (natura ipertestuale).
	* Struttura gerarchica delle categorie.
	* Decomposizione della classificazione come decisione ramificata (a un nodo interno).
* **Summarization:**
	* Generazione di riassunti di testi.
	* Utilizzo di profili per strutturare informazioni importanti.
	* Tecniche dipendenti dalla natura dei documenti (es. analisi di aspetti specifici per recensioni).
	* Facilita l'accesso alle informazioni:
	* Estrazione di parole chiave da un insieme di documenti.
	* Astrazione di documenti per evitare lettura completa.
	* Riassunto di documenti recuperati da una ricerca.
	* Tipi di riassunti:
	* Riassunti di parole chiave.
	* Riassunti di frasi.
* **Disambiguazione del Senso delle Parole (WSD):**
	* Assegnazione del significato corretto di una parola in base al contesto.
	* Analisi simultanea di tutti i termini nel contesto.
	* Approccio efficace: utilizzo di inventari di sensi esistenti e misure di correlazione semantica.
	* Rinnovato interesse grazie a risorse linguistiche elettroniche (es. Wikipedia).
	* Esempio: disambiguazione del significato di "bank".
* **Filtraggio nel Text Mining:**
	* Classifica documenti come rilevanti o irrilevanti per un utente, bloccando quelli irrilevanti.

##### Filtraggio delle Informazioni

* **Feed di Notizie (Produttore/Consumatore):**
	* Caso di Text Classification (rilevante/irrilevante).
	* Implementazione lato produttore (instradamento) o consumatore (blocco).
	* Richiede profilo utente (produttore) o profilo generale (consumatore).
* **Filtraggio Adattivo:**
	* Profilo iniziale definito dall'utente.
	* Aggiornamento profilo basato sul feedback utente.
* **Filtraggio - CRM:**
	* Analisi feedback clienti tramite standardizzazione e raggruppamento dati.
* **Filtraggio - Raccomandazione Prodotti:**
	* Approcci basati sul contenuto (preferenze utente).
	* Approcci collaborativi (analisi utenti simili).
* **Rilevamento Spam:**
	* Sfide legate a costi asimmetrici degli errori (falsi positivi/negativi).
	* Distribuzione non uniforme delle classi (più spam che email legittime).

##### Modelli di Rappresentazione dei Testi

* **Definizione di Termine:**
	* **Problema:** Selezione termini da includere, bilanciando completezza e importanza, gestendo frequenze.
	* **Contesto:** Composizione testuale e obiettivo dell'indice.
	* **Soluzione:** Modellazione relazioni tra parole, creando pattern relazionali per definire l'importanza.
	* Definizione flessibile: parola singola, coppia di parole, frase, radice, n-gramma, tipo di parola.
	* Modellazione relazioni: relazioni semantiche (*is-a*, *part-of*), evitando relazioni complesse basate su struttura sintattica.
* **Argomenti Correlati:**
	* Analisi lessicale e morfologica (punteggiatura, minuscolo, stopwords, stemming, lemmatizzazione, tagging).
	* Analisi semantica del discorso (anafora, ellissi, meronomia).
	* Pragmatica, semiotica e morfologia.

##### Tokenizzazione: Problemi Lessicali e Morfologici

* **Gestione della Punteggiatura:**
	* Sequenze con trattino (*state-of-the-art*, ecc.): problema di separazione vs. mantenimento della semantica.
	* Apostrofi (*Italy’s capital*): diverse rappresentazioni possibili (*Italy AND s*, *Italys*, *Italy’s*).
	* Acronimi (*U.S.A*, *USA*): trattamento variabile a seconda del contesto.

##### Preprocessing del Testo per l'Information Retrieval

* **Gestione delle Entità Nominate:**
	* Trattamento specifico per entità come *San Francisco* e *Hewlett-Packard* per evitare frammentazione non semantica.

* **Gestione dei Numeri:**
	* Rimozione di stringhe puramente numeriche.
	* Mantenimento di stringhe alfanumeriche e numeri con significato informativo:
	* Preservazione di informazioni numeriche.
	* Identificazione di codici di errore, intervalli temporali, ecc.
	* Varietà di tipi numerici: date, tempo, codici, identificatori, numeri di telefono (esempi forniti nel testo).

* **Gestione dei Metadati:**
	* Indicizzazione separata dei metadati (data di creazione, formato, ecc.).
	* Complessità dell'interazione numeri-testo rende difficile una soluzione universale.

* **Gestione delle Stopwords:**
	* Rimozione di parole grammaticali (articoli, preposizioni) a basso potere informativo.
	* Motivazioni:
	* Scarsa rilevanza semantica.
	* Alta frequenza.
	* Impatto sulla dimensionalità e sparsità della rappresentazione, con conseguente perdita di potere discriminante ($\to$ *perdita di potere discriminante*).
	* Casi in cui potrebbero essere necessarie: query di frase, titoli, query relazionali (esempi forniti nel testo).
	* Gestione ottimale: tecniche di compressione e ottimizzazione delle query.
	* Personalizzazione della Stop-List:
	* Rimozione di termini molto frequenti nel corpus (poco esplicativi).
	* Eventuale esclusione di termini super rari (operazione delicata).
	* Decisione sull'esclusione di termini che appaiono una sola volta dipende dal tipo di termine.

* **Normalizzazione:**
	* Uniformazione della forma delle parole per trovare corrispondenze tra termini con forme diverse ma stesso significato.
	* Operazioni di normalizzazione:
	* Eliminazione di punti, trattini, accenti, umlaut (esempi forniti nel testo).
	* Risultato: creazione di *termini* (voci nel dizionario IR) spesso organizzati in *classi di equivalenza*.
	* Semplificazione della rappresentazione del testo, focalizzandosi sulla struttura sintattica.
	* Espansione asimmetrica come alternativa alle classi di equivalenza.

* **Case delle lettere:**
	* Conversione del testo in minuscolo (lowercase).

##### Preprocessing del Testo per la Ricerca di Informazioni

##### Normalizzazione del Testo:

- **Gestione delle Varianti:** L'inserimento di un termine può generare diverse varianti (es: "window", "windows", "Windows"). Questo approccio è potente ma meno efficiente.
- **Influenza della Lingua:** La scelta del metodo dipende dalla lingua. Spesso si preferisce rimuovere accenti e trattini per gestire le omissioni degli utenti.
- **Case Folding:** Tipicamente si converte tutto in minuscolo, eccetto le named entities (es. General Motors) e gli acronimi.

##### Riduzione della Matrice dei Dati:

- **Algebra Lineare:** Applicazione dell'algebra lineare per ridurre la matrice identificando e raggruppando colonne linearmente dipendenti (sinonimi), focalizzandosi sui pattern sintattici.

##### Spell Checking:

- **Prossimità tra Stringhe:** Gli algoritmi devono gestire la prossimità tra stringhe per correggere errori di battitura.
- **Edit Distance:** Misura la differenza tra stringhe, ma ignora il contesto.
- **Contesto Semantico:** Una correzione accurata richiede il contesto, ma spesso si lavora solo sul campo lessicale.
- **Evitare se non Necessario:** Il spell checking è sconsigliato se non essenziale, soprattutto con corpus rumorosi (es. messaggi istantanei).

##### Gestione delle Emoticon:

- **Sostituzione o Markup:** Le emoticon possono essere sostituite con termini o mantenute con un markup, con la pesatura delegata a fasi successive. Importanti per l'analisi del sentiment.

##### Utilizzo dei Tesauri:

- **Gestione Sinonimi e Omonimi:** I tesauri generalizzano termini correlati, gestendo sinonimi (significato simile, forma diversa) e omonimi (forma uguale, significato diverso).
- **Esempio:** `color = colour`
##### Implementazione:

- **Indicizzazione Multipla:** Indicizzazione di un termine anche con le sue varianti (es. "color-colour").
- **Espansione della Query:** Espansione della query per includere termini correlati.

##### Gestione degli Errori di Ortografia:

- **Algoritmi come Soundex:** Creano classi di equivalenza basate su euristiche fonetiche, raggruppando parole che suonano simili.

## Lemmatizzazione e Stemming: Confronto

##### Lemmatizzazione

* **Definizione:** Riduzione delle forme flessionali di una parola al suo lemma (forma base).
* Applicabile a verbi (infinito) e sostantivi (singolare).
* Richiede analisi morfologica completa.
* **Esempio:** "the boy's cars are different colors" → "the boy car be different color"
* **Benefici per il retrieval:** Generalmente modesti.
* **Ruolo:** Effetto collaterale dell'analisi sintattica.

##### Stemming

* **Definizione:** Riduzione delle parole alle loro radici (prefisso) tramite "suffix stripping".
* Intuitivo per sostantivi, più complesso per verbi.
* **Perdita di informazioni lessicali:** Distrugge informazioni semantiche.
* Utilizzo consigliato: Solo quando non è necessaria elaborazione semantica.
* Spesso combinato con rimozione delle *stop words*.
* **Non combinare con lemmattizzazione:** Stemming è più aggressivo.
* **Dipendenza dalla lingua:** Algoritmi specifici per ogni lingua.
* **Esempio:** "automate(s)", "automatic", "automation" → "automat"
* **Esempi di equivalenze (semplificazione):** "compressed" e "compression" → "compress"; "compress" → "compress".

##### Stemming di Porter (inglese)

* **Algoritmo:** Iterazione su regole pre-costruite, applicando riduzioni basate sul *longest match*.
* **Notazione:** $[c](vc)m[v]$ (c=consonante, v=vocale, m=misura)
* **Struttura:** 5 fasi sequenziali con regole basate su condizioni e sostituzioni di suffissi.
* Esempi di regole: `sses` → `ss`, `ed` → (vuoto se preceduto da vocale).
* **Esempio di applicazione:** `GENERALIZATIONS` → `GENERALIZATION` → `GENERALIZE` → `GENERAL` → `GENER`
* **Condizioni e sostituzioni (esempio parziale):**

| Conditions | Suffix | Replacement | Examples |
|---|---|---|---|
| | sses | ss | caresses -> caress |
| | ies | i | ponies -> poni, ties -> ti |
| | ss | ss | caress -> caress |
| | s | | cats -> cat |
| (m > 0) | eed | ee | feed -> feed, agreed -> agree |
| (*v*) | ed | | plastered -> plaster, bled -> bled |
| (*v*) | ing | | motoring -> motor, sing -> sing |
| (m > 1) | e | | probate -> probat, rate -> rate |
| (m = 1 and not *o) | e | | cease -> ceas |
* `*v*` = stem contiene vocale.
* `*o` = stem termina in `cvc` (seconda c ≠ W, X, Y).

##### Vantaggi dello Stemming

* **Miglioramento del retrieval:** Risultati contrastanti, dipende dal vocabolario.
* **Perdita di distinzioni semantiche:** Possibile perdita di sottili sfumature di significato.
* **Inglese:** Migliora il recall ma danneggia la precisione per alcune query.

##### Algoritmi di Stemming

* **Stemming:** Processo di riduzione delle parole alla loro radice (stem).
* **Differenze linguistiche:** L'approccio "operativo" (es. "operative" → "oper") è più efficace per alcune lingue (inglese), mentre altri metodi sono preferibili per altre (spagnolo, tedesco, finlandese).
* **Algoritmi di Stemming:** Prestazioni generalmente simili.
* **Stemmer di Lovins:**
	* Algoritmo a singolo passaggio.
	* Rimuove il suffisso più lungo possibile.
	* Si basa su circa 250 regole.
	* **Stemmer di Paice/Husk:** (Nessun dettaglio fornito nel testo, necessita di ulteriore informazione per un'espansione)
	* **Stemmer Snowball:** (Nessun dettaglio fornito nel testo, necessita di ulteriore informazione per un'espansione)
