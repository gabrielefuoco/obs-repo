
##### Modello Booleano di Ricerca

##### Descrizione:

* Utilizza query booleane (termini di indice + operatori booleani: `AND`, `OR`, `NOT`) per interrogare un indice.
* Corrispondenza binaria: documento soddisfa o non soddisfa la query.
* Utilizzato in sistemi come WestLaw, sistemi di posta elettronica, cataloghi di biblioteche e macOS Spotlight.

##### Esempio: WestLaw

* Servizio di ricerca legale commerciale.
* Utilizza query booleane con operatori di prossimità (es. `/3`, `/S`).
* Esempio di query: `LIMIT! /3 STATUTE ACTION /S FEDERAL /2 TORT /3 CLAIM`
* Dimostra sia vantaggi (precisione, raffinamento incrementale) che svantaggi (rigidità).

##### Vantaggi:

* Query precise e lunghe.
* Operatori di prossimità.
* Sviluppo incrementale delle query.
* Maggiore precisione rispetto alle ricerche web.

##### Limitazioni:

* **Rigidità:**
	* `AND`: richiede tutti i termini.
	* `OR`: richiede almeno un termine.
	* Incoraggia query brevi e semplici.
	* Scarsa flessibilità; non supporta l'espansione della query.
	* Ogni termine è considerato in modo isolato.
* **Difficoltà nel controllo dei risultati:**
	* Nessun controllo sul numero di documenti recuperati.
	* Nessuna classificazione dei risultati in base alla rilevanza.
	* Impossibile utilizzare il feedback di rilevanza per migliorare la query.
* **Espressività limitata:**
	* Difficoltà nell'esprimere richieste complesse.
	* Impossibilità di regolare l'importanza dei termini.
	* Problema della sparsità nella rappresentazione dei dati.

##### Esempio di difficoltà:

* Trovare opere di Shakespeare con "Brutus" e "Caesar" ma non "Calpurnia" è complesso e inefficiente.
* Operazioni di prossimità (es. "Romans" vicino a "countrymen") sono problematiche.
* Non supporta il recupero classificato.
* Adatto solo per query corte e semplici, quando l'obiettivo è solo determinare la presenza/assenza di un elemento.

##### Estensione del Modello Booleano con Classificazione:

* **Obiettivo:** Ordinare i risultati del recupero booleano.
* **Metodo:** Assegnazione di pesi (in [0,1]) ai termini; calcolo della similarità (es. Jaccard) tra query e documenti; ordinamento in base alla similarità.
* **Feedback di Rilevanza:** Raffinamento dell'ordinamento basato sulla classificazione dei documenti.
* **Risultato:** Lista di risultati ordinata per rilevanza.

##### Insiemi Fuzzy nel Recupero dell'Informazione:

* **Concetto:** Rilassamento dei confini degli insiemi booleani.
* **Standard Booleano:** `d ∈ A` o `d ∉ A`.
* **Fuzzy:** `d` è "più o meno" in `A`.
* **Grado di Appartenenza:** `wA` indica il grado di appartenenza di `d` ad `A`.
* **Operazioni Fuzzy:**
	* Intersezione: $w(A∩B) = min(wA, wB)$
	* Unione: $w(A∪B )= max(wA, wB)$

##### Modelli di Similarità:

* **MMM (Mixed Min and Max Model):**
	* **Query Disgiuntiva ($q_{or} = (t_1 \lor t_2 \lor \dots \lor t_n)$):** $S(q_{or}, d) = \lambda_{or} \cdot \max(w_1, \dots, w_n) + (1 - \lambda_{or}) \cdot \min(w_1, \dots, w_n)$ ($0 \le \lambda_{or} \le 1$)
	* **Query Congiuntiva ($q_{and} = (t_1 \land t_2 \land \dots \land t_n)$):** $S(q_{and}, d) = \lambda_{and} \cdot \min(w_1, \dots, w_n) + (1 - \lambda_{and}) \cdot \max(w_1, \dots, w_n)$ ($0 \le \lambda_{and} \le 1$)
* **Modello di Paice:**
	* **Differenza da MMM:** Considera tutti i pesi dei termini, non solo il massimo e il minimo.
	* **Vantaggio:** Migliore risposta alle query.
	* **Svantaggio:** Maggior costo computazionale.
* **Modello P-norma:**
	* **Caratteristiche:** Documenti e query come punti multidimensionali con pesi dei termini e operatori con coefficienti.
	* **Calcolo della Similarità:** Basato su due schemi di pesatura.

##### Sparsità della Matrice Termine-Documento:

* **Rappresentazione:** Una matrice termine-documento densa è irrealistica.
* **Esempio:** `N = 1M` documenti, `1000` parole/documento, `6 byte/parola` → `6 GB` di dati; `M = 500K` termini distinti.
* **Problema:** Matrice `500K x 1M` con circa mezzo trilione di zeri. In realtà, non più di un miliardo di uni.
* **Soluzione:** Rappresentazione sparsa: registrare solo le posizioni degli uni.
* **Desiderata:** Struttura dati che rappresenti concetti e relazioni.

##### Definizione e Costruzione dell'Indice Inverso:

**Definizione:** Mappatura di ogni termine all'insieme dei documenti in cui appare. Vantaggi: efficienza di memorizzazione e velocità di ricerca.
##### Costruzione:

- Identificazione dei documenti indicizzati per ogni termine (memorizzazione docID).
- Creazione della matrice termine-documento (traspone un array di documenti indicizzati).
##### Struttura:

- Liste di postings (docID + frequenza): liste concatenate o array di lunghezza variabile.
- Memorizzazione: su disco (sequenza continua) o in memoria.
**Considerazioni:** Compromessi tra efficienza di memorizzazione, velocità di accesso e facilità di aggiornamento.

##### Struttura dell'Indice:

**Dizionario:** Parole del corpus con puntatori alle liste di postings.
**Liste di postings:** Documenti in cui appare una parola (con frequenza).
##### Doppia indicizzazione:

- Per chiave (dizionario).
- Per documento (liste di postings).

##### Processo di Indicizzazione (Indexer):

**Input:** Stream di coppie (termine, docID).
##### Fasi:

- Generazione della sequenza di coppie (termine, docID).
- Ordinamento per termine.
- Ordinamento per docID (per ogni termine).
- Unione di voci multiple (stesso termine, stesso documento).
- Aggiunta della frequenza del termine nel documento.
- Divisione in Dizionario (termini distinti con termID) e Postings (liste di postings con frequenze).

##### Elaborazione delle Query:

**Esempio:** Query "*Brutus AND Caesar*".
##### Passaggi:

- Recupero dei postings di "Brutus" dal dizionario.
- Recupero dei postings di "Caesar" dal dizionario.
- Intersezione delle liste di postings (algoritmo `INTERSECT`, tempo lineare rispetto alla somma delle dimensioni delle liste).

##### Unione di Postings (Intersezione di Insiemi)

* Algoritmo di intersezione lineare per due postings ordinati.
* Tempo di elaborazione proporzionale alla somma delle dimensioni dei postings.
* Esempio di elaborazione di query booleane AND.
* Pseudocodice:
        ```
        INTERSECT(p1, p2) 
        answer ← ⟨ ⟩ 
        while p1 ≠ NIL and p2 ≠ NIL do 
            if docID(p1) = docID(p2) then 
                ADD(answer, docID(p1)) 
            p1 ← next(p1) 
            p2 ← next(p2) 
            else if docID(p1) < docID(p2) then 
                p1 ← next(p1) 
            else 
                p2 ← next(p2) 
        return answer 
        ```

##### Ottimizzazione dell'Elaborazione di Query

* **Query AND:** Ordinare i termini in base alla frequenza crescente (dal meno frequente al più frequente) per minimizzare la dimensione degli insiemi intermedi.
* **Esempio:** Query "Brutus AND Caesar AND Antony" (frequenze: Brutus 1000, Caesar 500, Antony 200) -> ordine ottimale: Antony, Caesar, Brutus.
* **Query Booleane arbitrarie (OR, NOT):** Stimare la dimensione degli insiemi OR (somma delle frequenze) e procedere in ordine crescente di queste stime.
* Tempo di elaborazione lineare rispetto al numero totale di voci nei postings.

##### Query di Frase

* Importanza: Ricerca avanzata, comprensibilità per l'utente.
* Approcci:
* **Indici Biword:** Indizza coppie consecutive di termini. Semplice per frasi a due parole.
* **Scomposizione di frasi più lunghe:** Trasforma la frase in una query booleana sui biword. Rischio di falsi positivi e aumento della dimensione del dizionario. Non scalabile per frasi lunghe.
* Gli indici biword non sono la soluzione standard, ma parte di una strategia più complessa.

##### Etichettatura Morfologica (POST) e Biword Estensi

* Analisi POST: suddivisione del testo in termini e assegnazione di categorie grammaticali.
* Classificazione dei termini come nomi (N) o articoli/preposizioni (X).

##### Indicizzazione Biword Estesa

* **Definizione:** Identifica sequenze di termini $NX*N$, gestendo frasi complesse.
* **Esempio:** "il cacciatore nella segale" -> "cacciatore segale"
* **Elaborazione Query:**
	* Analisi: suddivisione della query in termini N e X.
	* Segmentazione: creazione di biword estesi dalla query.
	* Ricerca: ricerca dei biword estesi nell'indice.

##### Indici Posizionali

* **Funzionalità:** Memorizzano le posizioni di ogni termine nei documenti. `<termine, numero di documenti; doc1: posizione1, posizione2 … ; doc2: posizione1, posizione2 … ; …>`
* Supporta query di frase e prossimità.
* **Confronto con Biword:**
	* Indici posizionali: supportano query di frase e prossimità.
	* Indici biword: non supportano query di prossimità.
* **Algoritmo di Unione Ricorsivo:**
	* Utilizza la fusione delle liste di `doc:posizione` per query di frase, gestendo complessità oltre la semplice uguaglianza.
	* Esempio: "to be or not to be".

##### Dimensione dell'Indice Posizionale

* **Espansione dell'archiviazione:** Una voce per ogni occorrenza, non solo per documento.
* **Dipendenza dalla dimensione del documento:** La dimensione dipende dalla dimensione media dei documenti (compressione possibile).
* **Regola empirica:**
	* 2-4 volte più grande di un indice non posizionale.
	* 35-50% del volume del testo originale.
	* **Utilizzo standard:** La potenza delle query di frase e prossimità ne giustifica l'utilizzo, anche implicito.

##### Costruzione dell'Indice: Scalabilità e Basi Hardware

* **Limiti della costruzione in memoria:** Non scalabile per collezioni di grandi dimensioni (es. New York Times).
* **Necessità di utilizzo del disco:** Vincoli di performance dovuti all'accesso ai dati.
* **Basi hardware:** Server con ampia memoria (GB) e spazio su disco maggiore (2-3 ordini di grandezza). Preferenza per macchine standard a sistemi costosi con tolleranza ai guasti. Ottimizzazione I/O del disco tramite lettura/scrittura a blocchi (8KB-256KB).
* **Ordinamento esterno:** Necessario per collezioni di grandi dimensioni, in quanto l'ordinamento diretto su disco è troppo lento.

##### Block Sort-Based Indexing

* **Soluzione per la scalabilità:** Algoritmo di ordinamento esterno per la costruzione dell'indice su disco per grandi quantità di dati. (Dettagli non forniti nel testo).

##### Indicizzazione di Grandi Collezioni di Documenti

##### Algoritmo BSBI (Block-Sort-Based Indexing)

**Problema:** L'indicizzazione di grandi dataset (es. 100 milioni di record) in memoria è inefficiente.
**Soluzione:** Ordinamento esterno.
- Suddivisione dei dati in blocchi più piccoli (es. 10 milioni di record).
- Ordinamento interno di ogni blocco (es. Quicksort, $O(N \log N)$).
- Scrittura dei blocchi ordinati (run) su disco.
- Unione delle run tramite merge esterno.
##### Pseudocodice:

```
BSBIndexConstruction()
1 n ← 0
2 while (all documents have not been processed)
3 do n ← n + 1
4 block ← ParseNextBlock()
5 BSBI-Invert(block) 
6 WriteBlockToDisk(block, fn) 
7 MergeBlocks(f_1, ..., f_n; f_merged)
```
**Ordinamento di 10 blocchi:** Due fasi: ordinamento interno (Quicksort) e merge esterno. Ottimizzazione dello spazio su disco per evitare due copie complete dei dati.

##### Tecniche di Merge

##### Merge Binario:

- Albero di merge con $\log_2(n)$ livelli (n = numero di run).
- Merge parziali a ogni livello, leggendo, unendo e riscrivendo blocchi su disco.
- Struttura a livelli: Partizionamento, merge parziale, aggiornamento dell'indice.
##### Multi-way Merge:

- **Assunzione:** Condivisione parziale del lessico tra documenti.
- Lettura simultanea da tutti i blocchi.
- Richiede: apertura simultanea di file, buffer di lettura/scrittura, coda di priorità per `termID` più basso, unione di liste di postings.
- Efficiente con blocchi di dimensioni adeguate.

##### Problema della Crescita del Lessico durante il Merge

**Gestione di termini e ID:** Necessità di una corretta gestione.
**Compressione con perdita:** Applicabile solo a termini non essenziali.
**Valutazione dei token:** Strategie per valutare l'importanza dei token per la compressione.

##### Algoritmo SPIMI (Single-Pass In-Memory Indexing)

**Soluzione:** Approccio lazy per risolvere il problema della crescita del lessico durante l'indicizzazione di grandi collezioni.

##### Superamento delle Limitazioni degli Algoritmi Basati sull'Ordinamento

* **Idea Chiave 1: Generazione di Dizionari Separati per Blocco**
	* Elimina la necessità di mantenere la mappatura termine-termID tra blocchi (mapping across block).
* **Idea Chiave 2: Eliminazione dell'Ordinamento**
	* Accumulo di postings nelle liste di postings durante l'elaborazione.
	* Generazione di indici invertiti completi per ogni blocco, successivamente mergeabili.
	* Maggiore velocità e risparmio di memoria rispetto agli algoritmi basati sull'ordinamento.
	* Liste di postings come strutture dinamiche riallocate all'occorrenza.
	* Esempio: Algoritmo SPIMI (vedi sotto).

##### Algoritmo SPIMI (Single-Pass Inverted index with Memory-mapped files)

* **Pseudocodice:**
    ```python
    1. output_file = NEWFILE()
    2. dictionary = NEWHASH()
    3. while (free memory available)
    4. do token ← next(token_stream)
    5. if term(token) ∉ dictionary
    6. then postings_list = ADDToDICTIONARY(dictionary, term(token))
    7. else postings_list = GETPOSTINGSLIST(dictionary, term(token))
    8. if full(postings_list)
    9. then postings_list = DOUBLEPOSTINGSLIST(dictionary, term(token))
    10. ADDToPOSTINGSLIST(postings_list, docID(token))
    11. sorted_terms ← SORTTERMS(dictionary)
    12. WRITEBLOCKToDISK(sorted_terms, dictionary, output_file)
    13. return output_file
    ```
* **Spiegazione:**
	* Linea 5: pre-processing del token raw in index-term.
	* Linea 10: aggiunta immediata del posting.
	* Linee 8-9: raddoppio della lista di postings se piena.
	* Linea 11: ordinamento dei termini dopo aver raccolto tutti i postings per un blocco.

##### Indicizzazione Distribuita

* **Architettura:**
	* Macchina master per la coordinazione.
	* Suddivisione dell'indice in task paralleli (blocchi).
	* Assegnazione di ruoli ai nodi.
* **Parsing Distribuito:**
	* Assegnazione di porzioni di documenti (split) a parser inattivi.
	* Estrazione di coppie (termine, documento ID).
	* Scrittura in *j* partizioni (fold) basate su suddivisione lessicografica dei termini.
* **Inversione Distribuita dell'Indice:**
	* Raccolta delle coppie (termine, documento ID) per partizione.
	* Ordinamento delle liste di postings per termine.
	* Scrittura su disco.
* **Modello MapReduce:**
	* **Fase di Map:** Produzione di liste di coppie (termine, documento).
	* **Fase di Reduce:** Produzione delle liste di postings (liste di documenti in cui un termine compare).

##### MapReduce e Sistemi di Indicizzazione

* **MapReduce:** Framework robusto e semplice per il calcolo distribuito.
* **Sistema di indicizzazione di Google (circa 2002):** Composto da fasi implementate in MapReduce.

##### Schema MapReduce per la Costruzione dell'Indice

* **Funzioni Map e Reduce:**
	* `map`: input → list(k, v)
	* `reduce`: (k,list(v)) → output
* **Istanza per l'Indicizzazione:**
	* `map`: collection → list(termID, docID)
	* `reduce`: (<termID1, list(docID)>, <termID2, list(docID)>, …) → (postings list1, postings list2, …)

##### Gestione di Documenti Dinamici

* **Strategie:**
	* **Indice Principale e Ausiliario:** Indice principale + uno o più indici ausiliari per nuovi documenti. Ricerca su entrambi, combinando i risultati. *Problemi*: Inefficiente con un unico grande file per l'indice a causa di merge frequenti.
	* **Eliminazione:** Vettore di bit per indicare documenti eliminati, filtrando i risultati di ricerca.
	* **Re-indicizzazione:** Re-indicizzazione periodica di tutto l'indice. Aggiornamento liste di postings per termini esistenti, aggiunta di nuovi termini al dizionario.

##### Tecniche di Fusione

* **Fusione Logaritmica:**
	* **Principio:** Serie di indici di dimensioni crescenti (1, 2, 4, 8...). L'indice più piccolo in memoria, gli altri su disco. Fusione iterativa fino all'ordinamento completo.
	* **Memoria e Disco:** $Z_0$ (in memoria), $I_0, I_1, ...$ (su disco).
	* **Complessità:** Ogni posting fuso al massimo $O\left( log\left( \frac{T}{n} \right) \right)$ volte, complessità totale $O\left( T \cdot log\left( \frac{T}{n} \right) \right)$.
* **Confronto con Fusione T/n (Indice Ausiliario e Principale):**
	* **Fusione T/n:** Complessità nel caso peggiore $O\left( \frac{T^2}{n} \right)$.
	* **Vantaggi Fusione Logaritmica:** Più efficiente della fusione T/n per la costruzione dell'indice.
	* **Svantaggi Fusione Logaritmica:** Elaborazione query più complessa: $O\left( log\left( \frac{T}{n} \right) \right)$ contro $O(1)$ della fusione semplice.

##### Problemi con Più Indici

* **Gestione delle statistiche:** Difficoltà nel mantenere statistiche a livello di collezione (es. correzione ortografica).
* **Problema:** Come mantenere le migliori alternative con più indici e vettori di bit di invalidazione?
* **Possibile soluzione:** Ignorare indici ausiliari per l'ordinamento, basando il ranking solo sull'indice principale.

##### Indicizzazione Dinamica nei Motori di Ricerca

* **Approccio:** Modifiche incrementali frequenti per gestire dati dinamici (notizie, blog, nuove pagine web).

##### Ricostruzione Periodica dell'Indice:

* Commutazione dell'elaborazione delle query su un nuovo indice.
* Eliminazione del vecchio indice.

##### Requisiti per la Ricerca in Tempo Reale:

* Bassa latenza: elevata produttività di valutazione delle query.
* Elevato tasso di ingestione: immediata disponibilità dei dati.
* Letture e scritture concorrenti: gestione simultanea di letture e scritture sull'indice.
* Dominanza del segnale temporale: priorità ai dati più recenti.

##### Tecniche di Indicizzazione:

##### Indicizzazione basata sull'ordinamento:

* Inversione in memoria naive.
* Indicizzazione basata sull'ordinamento bloccato (BSBI).
* Ordinamento per fusione (efficace per l'ordinamento basato su disco rigido).
##### Indicizzazione in memoria a passaggio singolo (SPIMI):

* Nessun dizionario globale.
* Generazione di un dizionario separato per ogni blocco.
* Postings non ordinati.
* Accumulo dei postings nelle liste man mano che si verificano.

