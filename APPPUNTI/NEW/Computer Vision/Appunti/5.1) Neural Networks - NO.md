```python
import os
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import image as mp_image
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
from matplotlib import cm

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
```

## Funzioni di attivazione

## Funzione logistica

```python
x = torch.tensor(np.linspace(-20,20,1000))
```

```python
sigmoid = nn.Sigmoid()
```

```python
y = sigmoid(x)
```

```python
plt.figure()

plt.plot(x,y,color='r')

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.title("$y=\sigma(x)$")
plt.show()
```

![png](output_6_0.png)

**La derivata della funzione logistica è esprimibile come:** $$\sigma'(x) = \sigma(x)\cdot (1-\sigma(x))$$

Se plottiamo quest'ultima abbiamo

```python
plt.figure()

plt.plot(x,y,color="r",label="$y=\sigma(x)$")
plt.plot(x,y*(1-y),color='b',label="$y=\sigma'(x)$")

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
#plt.grid(True, which='both')
plt.show()
```

![png](output_8_0.png)

rosso= valore funzione, blu =derivata
## Tangente iperbolica

La differenza con la funzione Logistica è che la prima è sempre positiva e la Tangente Iperbolica invece è compresa tra 0 e 1
```python
tanh = nn.Tanh()
```

```python
y = tanh(x)
```

```python
plt.figure()

plt.plot(x,y,color='r')

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.title("$y=\sigma(x)$")
plt.show()
```

![png](output_12_0.png)

La derivata della tangente iperbolica è $$\frac{\partial}{\partial x}tanh(x) = 1- tanh(x)^2$$

Plottandola otteniamo

```python
plt.figure()

plt.plot(x,y,color="r",label="$y=tanh(x)$")
plt.plot(x,1-y**2,color='b',label="$y=tanh'(x)$")

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
#plt.grid(True, which='both')
plt.show()
```

![png](output_14_0.png)

### Utilizziamo autograd di Pytorch

```python
x = torch.tensor(np.linspace(-20,20,1000),requires_grad=True)

```

```python
y = torch.tanh(x)

y.backward(torch.ones(1000))
```

```python
plt.figure()

plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=tanh(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=tanh'(x)")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.show()
```

![png](output_18_0.png)

Vediamo le altre funzioni di attivazione

```python
#g = F.relu
#g = F.relu6 
#g = F.elu 
#g = F.selu 
#g = F.celu
#g = F.gelu
g = lambda x: F.leaky_relu(x,.1)
#g = F.tanhshrink
#g = F.softplus

y = g(x)

x.grad.zero_()
y.backward(torch.ones(1000))

plt.figure()

plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=g(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=g'(x)")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.show()

```

![png](output_20_0.png)

### Automatic differentiation

### Esercizio

Calcolare il grafo e le derivate

```python
x = torch.ones((3,2),requires_grad = True)

y = torch.ones((2,2),requires_grad = True)*0.5
y.retain_grad()
z = torch.ones((3,2),requires_grad = True)*0.25
z.retain_grad()

z1 = torch.mm(x,y)
z2 = z1 + z
z2.retain_grad()

y1 = z2*torch.tensor([[1,0],[2,1],[0,1]]) + z

o = torch.sum(y1)

```

## Calcolo del Gradiente in un Grafo di Calcolo

### Definizione dei Tensori

Iniziamo definendo una serie di tensori:
$$x=
\begin{bmatrix}
1 & 1 \\1 & 1 \\1 & 1\end{bmatrix}
$$
$$y=
\begin{bmatrix}
1 & 1 \\1 & 1\end{bmatrix}
$$
$$z=
\begin{bmatrix}
1 & 1 \\1 & 1 \\1 & 1\end{bmatrix}
$$

### Operazioni sui Tensori

Vengono quindi eseguite le seguenti operazioni sui tensori:

* $\tilde{y}:$ Moltiplicazione di y per 0.5.
* $\tilde{z}:$ Moltiplicazione di z per 0.25.
* **z1:** Moltiplicazione di matrici (mm) tra x e $\tilde{y}$, risultando in una matrice 3x2.
* **z2:** Somma di z1 e z.
* **y1:** Somma di z2 moltiplicato per il tensore:
$$
\begin{bmatrix}
1 & 0 \\2 & 1 \\0 & 1\end{bmatrix}
$$
e z.

Infine, viene eseguita un'operazione di `sum` che collassa il tensore y1 in uno scalare.

### Interpretazione del Grafo

Questo grafo di calcolo è simile alle strutture su cui si desidera lavorare. Lo scalare finale rappresenta la somma dei contributi costruiti tramite la rete neurale (prodotto di alcuni tensori). L'attributo `requires_grad = True` nei tensori indica che su questi tensori è possibile calcolare il gradiente.

### Calcolo del Gradiente

Si parte dai nodi foglia e si calcola la radice, indicata come `o`. Viene quindi eseguita l'operazione `backward`:

```python
o.backward()

y.grad
```

Il risultato è:

```
tensor([[3., 2.],
        [3., 2.]])
```

L'operazione `backward` propaga all'indietro tutti i gradienti. Dopo questa operazione, ogni variabile ha una componente `.grad`, che definisce il gradiente (in questo caso rispetto ad `o`). Il `backward` annota tutti i nodi con il gradiente della variabile con cui è stato eseguito il `backward`.

In questo caso, si sta calcolando la derivata di `o` rispetto a `x`. Poiché `x` è un tensore, si sta calcolando il gradiente di una funzione scalare rispetto a una matrice. Il risultato è una matrice, in cui ogni punto rappresenta...

## Gradiente evanescente

![[5.Reti neurali_parte1.pdf#page=54&rect=183,172,765,348|5.Reti neurali_parte1, p.54]]

x è l'input
i valori sono tutti scalari ma possono essere anche tensori
la rete è a 5 livelli

![[5.Reti neurali_parte1.pdf#page=58&rect=121,63,889,360|5.Reti neurali_parte1, p.58]]

il range della derivata della funzione logistica è tra 0 e 0.25.
questo ci interessa perchè la troviamo moltiplicata 5 volte in questa rete. tutta quessta formula è limitata da $0.25^4$

il gradiente quidni tende ad azzerarsi
![[5.Reti neurali_parte1.pdf#page=60&rect=67,8,872,411|5.Reti neurali_parte1, p.60]]
questa cosa ha impatto perchè l'aggiornamento dei parametri non funziona più (per calcoalre v^t+1 sottraggo a v^t il gradiente per lambda, ma in questo caso il gradiente è prossimo allo 0)
la sigmoide dunque non va bene

Esploriamo il problema del gradiente evanescente

```python
sigmoid = torch.sigmoid

x = torch.tensor(2.0)

w1 = torch.tensor(1.2,requires_grad=True)
a1 = x*w1
z1 = sigmoid(a1)

w2 = torch.tensor(0.1,requires_grad=True)
a2 = z1*w2
z2 = sigmoid(a2)

w3 = torch.tensor(1.2,requires_grad=True)
a3 = z2*w3
z3 = sigmoid(a3)

w4 = torch.tensor(-0.5,requires_grad=True)
a4 = z3*w4
z4 = sigmoid(a4)

w5 = torch.tensor(1.0,requires_grad=True)
a5 = z4*w5
y = sigmoid(a5)

```

```python
print(y)

y.backward()
```

tensor(0.6033, grad_fn=<SigmoidBackward>)

```python

w1.grad
```

tensor(-3.0186e-05)

```python
with torch.no_grad():
    print(sigmoid(a2)*(1-sigmoid(a2))*w2*sigmoid(a1)*(1-sigmoid(a1))*x)
```

tensor(0.0038)
## ReLU

l'alternativa è la relu
![[5.Reti neurali_parte1.pdf#page=61&rect=76,5,806,396|5.Reti neurali_parte1, p.61]]
la derivata (linea blu) è costante

Riscriviamo il tutto usando la RELU

```python
activation = torch.relu

x = torch.tensor(2.0)

w1 = torch.tensor(1.0,requires_grad=True)
a1 = x*w1
z1 = activation(a1)

w2 = torch.tensor(0.1,requires_grad=True)
a2 = z1*w2
z2 = activation(a2)

w3 = torch.tensor(1.2,requires_grad=True)
a3 = z2*w3
z3 = activation(a3)

w4 = torch.tensor(0.5,requires_grad=True)
a4 = z3*w4
z4 = activation(a4)

w5 = torch.tensor(1.0,requires_grad=True)
a5 = z4*w5
y = torch.sigmoid(a5)

```

```python
y
```

tensor(0.5300, grad_fn=<SigmoidBackward>)

```python

y.backward()

w1.grad
```

tensor(0.0299)

## Reti convoluzionali

Riprendiamo il dataset MNIST.

```python
import torchvision
import torchvision.transforms as transforms

batch_size = 64

# MNIST dataset 

train_dataset = torchvision.datasets.MNIST(root='data', 
                                           train=True, 
                                           transform=transforms.ToTensor(),  
                                           download=True)

test_dataset = torchvision.datasets.MNIST(root='data', 
                                          train=False, 
                                          transform=transforms.ToTensor())

# Data loader

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)
```

```python
image, label = train_dataset[0]

print(image.shape)
```

torch.Size([1, 28, 28])

```python
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.title("Class {}".format(label))
    plt.axis('off')
```

![png](output_40_0.png)

```python
class LeNet(nn.Module):
    def __init__(self,input_size):
        super(LeNet, self).__init__()
        # Convolutional Layers

        self.features = nn.Sequential(
            nn.Conv2d(1, 6, 5),
            nn.Tanh(),
            nn.AvgPool2d(2,stride = 2), 
            nn.Conv2d(6, 16, 5),
            nn.Tanh(),
            nn.AvgPool2d(2,stride = 2)
        )
        fm_size = ((input_size - 6 )//2 - 5)//2 + 1
        fc_layer_in_size = 16*fm_size*fm_size    

        # Linear layers

        self.fc = nn.Sequential(
            nn.Linear(fc_layer_in_size, 120),
            nn.Tanh(),
            nn.Linear(120, 84),
            nn.Tanh(),
            nn.Linear(84, 10)
        )

    def forward(self, x):
        features = self.features(x)

        # Flatten the tensor along the second dimension

        features_flattened = features.view(features.size(0),-1)  

        out = self.fc(features_flattened)

        output = F.log_softmax(out, dim=1)

        return output
```

## Da Fare

### Esercizio

Modificare la rete utilizzando attivazioni `ReLU` e `MaxPool`

```python

# Device configuration

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

lenet_model = LeNet(28).to(device)
```

```python
lenet_model
```

LeNet(
(features): Sequential(
(0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
(1): Tanh()
(2): AvgPool2d(kernel_size=2, stride=2, padding=0)
(3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
(4): Tanh()
(5): AvgPool2d(kernel_size=2, stride=2, padding=0)
)
(fc): Sequential(
(0): Linear(in_features=256, out_features=120, bias=True)
(1): Tanh()
(2): Linear(in_features=120, out_features=84, bias=True)
(3): Tanh()
(4): Linear(in_features=84, out_features=10, bias=True)
)
)

```python
# Loss and optimizer

criterion = nn.CrossEntropyLoss()
learning_rate = 0.0005
optimizer = torch.optim.Adam(lenet_model.parameters(), lr=learning_rate)  

num_epochs = 3

train_losses = []
train_counter = []
test_losses = []
test_counter = [i*len(train_loader.dataset) for i in range(num_epochs + 1)]
```

```python
# The number of steps for each epoch, defined by the number of instances divided by the batch size. 

total_step = len(train_loader)

def train(epoch,model,criterion,optimizer,reshape=True):
    for batch_idx, (images, labels) in enumerate(train_loader):  
        # Move tensors to the configured device

        if reshape:
            images = images.reshape(-1, 28*28)
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass

        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (batch_idx+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))

        train_losses.append(loss.item())
        train_counter.append(
        (batch_idx*batch_size) + ((epoch-1)*len(train_loader.dataset)))

def test(model,criterion,reshape=True):
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for images, labels in test_loader:
            if reshape:
                images = images.reshape(-1, 28*28)

            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            correct += (predicted == labels).sum().item()

            loss = criterion(outputs,labels,)

            test_loss += loss.item()

    test_loss /= len(test_loader.dataset)
    test_losses.append(test_loss)

    print('\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
```

```python
test(lenet_model,criterion,reshape=False)
for epoch in range(1,num_epochs+1):
    train(epoch,lenet_model,criterion,optimizer,reshape=False)
    test(lenet_model,criterion,reshape=False)
```

Test set: Avg. loss: 0.0362, Accuracy: 981/10000 (10%)

Epoch [1/3], Step [100/938], Loss: 0.8890
Epoch [1/3], Step [200/938], Loss: 0.4567
Epoch [1/3], Step [300/938], Loss: 0.3624
Epoch [1/3], Step [400/938], Loss: 0.5452
Epoch [1/3], Step [500/938], Loss: 0.2322
Epoch [1/3], Step [600/938], Loss: 0.3529
Epoch [1/3], Step [700/938], Loss: 0.2615
Epoch [1/3], Step [800/938], Loss: 0.2235
Epoch [1/3], Step [900/938], Loss: 0.1675

Test set: Avg. loss: 0.0027, Accuracy: 9476/10000 (95%)

Epoch [2/3], Step [100/938], Loss: 0.1317
Epoch [2/3], Step [200/938], Loss: 0.2805
Epoch [2/3], Step [300/938], Loss: 0.1369
Epoch [2/3], Step [400/938], Loss: 0.1041
Epoch [2/3], Step [500/938], Loss: 0.1543
Epoch [2/3], Step [600/938], Loss: 0.1247
Epoch [2/3], Step [700/938], Loss: 0.0500
Epoch [2/3], Step [800/938], Loss: 0.1668
Epoch [2/3], Step [900/938], Loss: 0.1456

Test set: Avg. loss: 0.0015, Accuracy: 9705/10000 (97%)

Epoch [3/3], Step [100/938], Loss: 0.0986
Epoch [3/3], Step [200/938], Loss: 0.0452
Epoch [3/3], Step [300/938], Loss: 0.0577
Epoch [3/3], Step [400/938], Loss: 0.0963
Epoch [3/3], Step [500/938], Loss: 0.1170
Epoch [3/3], Step [600/938], Loss: 0.0334
Epoch [3/3], Step [700/938], Loss: 0.0536
Epoch [3/3], Step [800/938], Loss: 0.0911
Epoch [3/3], Step [900/938], Loss: 0.0643

Test set: Avg. loss: 0.0012, Accuracy: 9743/10000 (97%)

```python
lenet_model.features
```

Sequential(
(0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
(1): Tanh()
(2): AvgPool2d(kernel_size=2, stride=2, padding=0)
(3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
(4): Tanh()
(5): AvgPool2d(kernel_size=2, stride=2, padding=0)
)

```python
extractor_1 = lambda im: lenet_model.features[:1](im.unsqueeze(0))

extractor_2 = lambda im: lenet_model.features[:4](im.unsqueeze(0))
```

```python
from torchvision.utils import make_grid

plt.figure(figsize=(20,20))

n = 6
k = 1

for i in range(n):
    plt.subplot(n,2,k)
    k = k+1
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.axis('off')
    features = extractor_1(image).permute(1,0,2,3)
    img = make_grid(features,padding=5,normalize=True).permute(1,2,0).detach().numpy()
    plt.subplot(n,2,k)
    k = k + 1
    plt.tight_layout()
    plt.imshow(img,cmap='gray', interpolation='none')
    plt.axis('off')

```

![png](output_50_0.png)

```python

plt.figure(figsize=(20,20))

n = 6
k = 1

for i in range(n):
    plt.subplot(n,2,k)
    k = k+1
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.axis('off')
    features = extractor_2(image).permute(1,0,2,3)
    img = make_grid(features,normalize=True).permute(1,2,0).detach().numpy()
    plt.subplot(n,2,k)
    k = k + 1
    plt.tight_layout()
    plt.imshow(img,cmap='gray', interpolation='none')
    plt.axis('off')

```

![png](output_51_0.png)

```python
plt.figure(figsize=(20,20))

kernels = lenet_model.features[0].weight.detach()
img = make_grid(kernels,normalize=True).permute(1, 2, 0)
plt.imshow(img, interpolation='none',cmap=cm.hot)
plt.axis('off')

plt.show()

```

![png](output_52_0.png)

```python
plt.figure(figsize=(20,20))

kernels = lenet_model.features[3].weight

kernels = kernels.view(kernels.shape[0]*kernels.shape[1],1,kernels.shape[2],kernels.shape[3])

img = make_grid(kernels,normalize=True)

img = img.permute(1, 2, 0).detach().numpy()

plt.imshow(img, interpolation='none',cmap=cm.hot)
plt.axis('off')

plt.show()
```

![png](output_53_0.png)

## Esercizio

Adattare la rete LeNet per effettuare classificazione sul dataset CIFAR10

CIFAR-10 consiste di 60000 immagini 32x32 (RGB), etichettate con un intero che corrisponde a 10 classi: airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), truck (9).

```python
tensor_cifar10 = torchvision.datasets.CIFAR10(root='data', train=True, download=True,transform=transforms.ToTensor())
tensor_cifar10_val = torchvision.datasets.CIFAR10(root='data', train=False, download=True,transform=transforms.ToTensor())

```

Files already downloaded and verified
Files already downloaded and verified

