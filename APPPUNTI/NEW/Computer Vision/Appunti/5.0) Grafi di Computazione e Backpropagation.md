
Il flusso di forward è abbastanza standard e viene automatizzato. Il flusso di backward, invece, è definito dalle regole di backpropagation. 

![[Pasted image 20241017103026.png|566]]
### Tensori e Operazioni Multidimensionali

In questo corso ci concentreremo sui tensori, ovvero strutture multidimensionali. Di conseguenza, dovremo fare l'upgrade di tutti i calcoli matriciali, inclusi quelli sul grado di computazione, considerando operazioni su tensori.

Le operazioni su tensori possono essere di due tipi:

* **Operazioni di punto a punto:** Ogni nodo rappresenta un'operazione su tensori, gli input sono tensori e l'obiettivo è ottimizzare questi tensori.
* **Operazioni matriciali:** Le matrici sono coinvolte nelle operazioni.

### Esempi di Calcolo del Gradiente

Consideriamo alcuni esempi di calcolo del gradiente:

* **Input scalare, output scalare:** Il gradiente è uno scalare.
	* Derivata $\frac{\delta y}{\delta x} \in R$
* **Input vettore, output scalare:** Il gradiente è un vettore.
	* Gradiente $\frac{\delta y}{\delta x} \in R, \ \left( \frac{\delta y}{\delta x} \right)_{n}=\frac{\delta y}{\delta x_{n}}$
* **Input vettore, output vettore:** Il gradiente è una matrice.
	* Jacobiano $\frac{\delta y}{\delta x} \in R^{N \times M}, \ \left( \frac{\delta y}{\delta x} \right)_{n,m}=\frac{\delta y_{m}}{\delta x_{n}}$
Questi esempi possono essere estesi a qualsiasi vettore multidimensionale, quindi invece di avere vettori, potremmo avere matrici come input e output.

### Propagazione della Derivata Vettoriale

Se abbiamo due vettori di input, uno in $\mathbb{R}^M$ e l'altro in $\mathbb{R}^K$, che vengono combinati con una passiva operazione per ottenere un altro vettore in $\mathbb{R}^M$, la propagazione della derivata viene fatta usando il calcolo differenziale, in particolare il calcolo tensoriale.
![[1-transcripted-processed-20241017103350229.png|452]]
## Grafo di computazione: un esempio

Il grafo di computazione è un modo per rappresentare le operazioni che vengono eseguite in un modello di apprendimento automatico. In questo esempio, analizziamo un grafo di computazione specifico.

**Nodi:**

Iniziamo definendo una serie di tensori:
 $$x=
 \begin{bmatrix}
 1 & 1 \\
 1 & 1 \\
 1 & 1
 \end{bmatrix}
 $$
 $$y=
 \begin{bmatrix}
 1 & 1 \\
 1 & 1 
 \end{bmatrix}
 $$
 $$z=
 \begin{bmatrix}
 1 & 1 \\
 1 & 1 \\
 1 & 1
 \end{bmatrix}
 $$
### Operazioni sui Tensori

Vengono quindi eseguite le seguenti operazioni sui tensori:

* $\tilde{y}:$ Moltiplicazione di y per 0.5.
* $\tilde{z}:$ Moltiplicazione di z per 0.25.
* **z1:** Moltiplicazione di matrici (mm) tra x e $\tilde{y}$, risultando in una matrice 3x2.
* **z2:** Somma di z1 e z.
* **y1:** Somma di z2 moltiplicato per il tensore:
 $$
 \begin{bmatrix}
 1 & 0 \\
 2 & 1 \\
 0 & 1
 \end{bmatrix}
 $$
 e z.

Infine, viene eseguita un'operazione di `sum` che collassa il tensore y1 in uno scalare.

**Osservazioni:**

* Il grafo di computazione è un modo visivo per rappresentare le operazioni che vengono eseguite in un modello di apprendimento automatico.
* Le operazioni di moltiplicazione matriciale e moltiplicazione punto a punto sono distinte.
* Il collasso è un'operazione che riduce la dimensionalità di un tensore.

## Strutture e Gradienti

Le strutture su cui ci stiamo concentrando dovrebbero essere simili a questa struttura. Tuttavia, alla fine, questo scalare sarà la nostra ROS, che vedremo in dettaglio più avanti.

**Cosa fa questo scalare?**

Questo scalare opera all'interno dei contributi costruiti tramite la rete neurale, ovvero tramite il prodotto di alcuni tensori. In questo caso, abbiamo tre tensori: x, y e z, che hanno una notazione particolare: `requires_grad=True`.

**Cosa significa `requires_grad=True`?**

Significa che su questi tensori è possibile calcolare il gradiente. In altre parole, rispetto a qualsiasi punto nel grafo di computazione, noi vorremmo calcolare il gradiente rispetto a questi elementi.

## Operazione di Backward nel Grafo di Computazione

Il grafo di computazione rappresenta le operazioni matematiche eseguite per calcolare un output da un insieme di input. L'operazione di **backward** in PyTorch permette di calcolare il gradiente di un output rispetto agli input, percorrendo il grafo al contrario.

### Calcolo del Gradiente

1. **Inizializzazione:** Si parte dal nodo foglia (input) e si calcola l'output, indicato come `o`.
2. **Backward:** Si esegue l'operazione `o.backward()`, che propaga all'indietro i gradienti attraverso il grafo.
3. **Gradiente:** Dopo il backward, ogni variabile nel grafo avrà una componente `.grad`, che rappresenta il gradiente rispetto a `o`.

**Esempio:**

```python
o.backward()

y.grad
```

Il risultato è:

```
tensor([[3., 2.],
        [3., 2.]])
```

Questo significa che il gradiente di `o` rispetto a `y` è una matrice 2x2 con tutti gli elementi uguali a 3 e 2.

### Interpretazione del Gradiente

Il gradiente di un output rispetto a un input rappresenta la derivata della funzione rispetto a quell'input. In altre parole, indica come varia l'output al variare dell'input.

**Esempio:**

Se `x` è un tensore (matrice) e `o` è uno scalare, il gradiente di `o` rispetto a `x` sarà una matrice con lo stesso numero di dimensioni di `x`. Ogni elemento della matrice rappresenta la derivata di `o` rispetto all'elemento corrispondente di `x`.

### Backward e Nodi Foglia

Il backward viene eseguito a partire da un nodo specifico del grafo. Questo nodo può essere un nodo intermedio o un nodo foglia (input). Se il backward viene eseguito a partire da un nodo foglia, il gradiente calcolato sarà rispetto a quel nodo.

**Esempio:**

Se il backward viene eseguito a partire da `x`, il gradiente calcolato sarà il gradiente di `o` rispetto a `x`.

## Grafi di computazione e backpropagation

Un grafo di computazione è una rappresentazione visiva di una serie di operazioni matematiche, dove ogni nodo rappresenta un'operazione e ogni arco rappresenta il flusso di dati tra le operazioni. La backpropagation è un algoritmo utilizzato per calcolare i gradienti di una funzione rispetto ai suoi parametri, permettendo così di ottimizzare i parametri per migliorare la performance di un modello.

**Nodi foglia e gradienti:**

Un **nodo foglia** è un nodo nel grafo di computazione che non ha figli. Un nodo foglia è **annotato** con i gradienti, il che significa che il gradiente della funzione rispetto a quel nodo viene calcolato. Questo è importante perché i gradienti sono utilizzati per aggiornare i parametri del modello durante l'addestramento.

**Esempio di backpropagation:**

Consideriamo un semplice esempio di un grafo di computazione con due nodi, `x` e `y`, e un'operazione di somma. Il nodo `x` è un nodo foglia e il nodo `y` è il risultato della somma di `x` e un valore costante.

Se calcoliamo il gradiente della funzione rispetto a `x`, otteniamo 1, perché la derivata della somma rispetto a `x` è 1. Se calcoliamo il gradiente della funzione rispetto a `y`, otteniamo anche 1, perché la derivata della somma rispetto a `y` è 1.

**Backpropagation e tensori:**

La backpropagation può essere applicata anche a funzioni che operano su tensori, che sono matrici multidimensionali. In questo caso, i gradienti sono anche tensori, e la backpropagation calcola il gradiente di ogni elemento del tensore di output rispetto a ogni elemento del tensore di input.

**Annotazione dei nodi:**

Ogni nodo nel grafo di computazione è annotato con i gradienti delle operazioni precedenti. Ad esempio, se un nodo rappresenta la somma di due nodi, il nodo sarà annotato con la derivata della somma rispetto a ciascun nodo di input.

**Passi di backpropagation:**

La backpropagation procede in modo retrogrado, a partire dal nodo di output e calcolando i gradienti di ogni nodo rispetto ai suoi nodi di input. Questo processo continua fino a raggiungere i nodi foglia, che sono i parametri del modello.

## Propagazione dei Gradienti in PyTorch

Per ottenere la derivata di E rispetto ad A, si attiva la cittura e si ottiene il valore corrispondente. Questo valore viene poi inserito nella formula per calcolare la derivata.

**x_grad** rappresenta la derivata di O rispetto a x. La differenza con il calcolo tradizionale è che si utilizzano le lezioni per ottenere il valore di x_grad.

**Propagazione dei Gradienti:**

La propagazione dei gradienti si basa sulle regole del campo matriciale. I tensori devono essere compatibili per poter effettuare le operazioni matriciali. La propagazione segue le stesse regole illustrate nella slide.

**MyTorch:**

Per default, MyTorch non calcola i gradienti intermedi. I nodi intermedi, che non sono foglie e non sono indicati con `require_grad`, non hanno i valori dei gradienti. Questi valori vengono calcolati durante la propagazione e poi eliminati.

**`require_grad`:**

`require_grad` indica al sistema di conservare il valore del gradiente. Se non si specifica `require_grad`, il valore del gradiente non verrà conservato.

**Esempio:**

La variabile `y1` è un nodo intermedio. Se non si specifica `require_grad` per `y1`, il suo valore non verrà conservato. Se si specifica `require_grad`, il valore verrà conservato.

**Nota:**

Anche se non si conservano i gradienti intermedi, il calcolo dei gradienti durante la fase di backward non viene influenzato. I gradienti vengono comunque calcolati, ma non vengono mantenuti in memoria.

**Motivi per non conservare i gradienti intermedi:**

* Conservare tutti i gradienti richiede molta memoria, soprattutto per grafi grandi.
* Se i gradienti sono importanti, la gestione della memoria diventa complessa.

## Rete neurale banale: Grafo di computazione

Processo di costruzione di un grafo di computazione per una rete neurale banale con una singola funzione sigmoide:

**Funzione Sigmoide:**

La funzione sigmoide, nota anche come funzione logistica, è definita come:
$$\sigma(x)=\frac{1}{1+\exp(-x)}$$
dove `x` può essere un valore scalare, un vettore o una matrice.

**Estensione Vettoriale:**

La funzione sigmoide è estesa ai vettori in modo che ogni elemento del vettore venga elaborato individualmente. Ad esempio, se `x` è un vettore di dimensione `n`, allora `σ(x)` è un vettore di dimensione `n` dove ogni elemento `i` è calcolato come `σ(x[i])`.

**Grafo di Computazione:**

![[1-transcripted-processed-20241017104145934.png|644]]
Consideriamo una rete neurale banale con una singola funzione sigmoide. Il grafo di computazione per questa rete può essere rappresentato come segue:

1. **Input:** Il vettore di input `x` è un vettore in `R^2`.
2. **Somma:** Il vettore di input `x` viene sommato a un vettore `w` in `R^2`.
3. **Funzione Sigmoide:** La somma risultante viene applicata alla funzione sigmoide, producendo un vettore `z` in `R^3`.

**Espressione Matematica:**

Il processo di calcolo può essere espresso matematicamente come:
$$z=\sigma(wx)$$
dove:

* `z` è il vettore di output, $\vec{ z} \in R^3$
* `w` è $\vec{ w} \in R^{3 \times 2}$ che rappresenta i pesi della rete, dove ogni riga corrisponde a un elemento del vettore di output `z` e ogni colonna corrisponde a un elemento del vettore di input `x`.
* `x` è il vettore di input, $\vec{ x} \in R^2$
* `σ` è la funzione sigmoide.

## Operazioni del Framework

Questo framework ci permette di implementare due operazioni fondamentali:

1. **Passo di forward:** 
 - Partendo dai valori attuali di W e V, e dai valori di X, calcoliamo Y.
2. **Passo di backward:**
 - Annotiamo tutto il grafo con i gradienti.

**Differenze con Numpy:**

Questo framework va oltre Numpy, che si limita al livello di tensore e all'operazione di calcolo matriciale. 

**Vantaggi:**

- **Automazione del calcolo dei gradienti:** Il framework automatizza il calcolo dei gradienti.
- **Gradienti discendenti:** L'automazione del calcolo dei gradienti permette di implementare gradienti discendenti con due linee di logica.

## Costruzione di Feature Automatiche in Reti Neurali

![[2-transcripted-processed-20241017105311529.png|493]]
Le reti neurali sono in grado di costruire feature automatiche, dove ogni livello rappresenta una feature derivata dal livello precedente. Questo processo può essere rappresentato da una serie di operazioni matriciali.

L'input iniziale è un'immagine che viene trasformata in un vettore. Questo può essere fatto concatenando i vettori dei pixel di ogni canale (rosso, verde, blu) in un unico vettore.

L'output, o "inizio", può essere un valore numerico, binario (utilizzando una funzione logistica) o continuo (utilizzando una funzione softmax).

Tra i vari livelli, passando dal livello i al livello i+1, vengono eseguite operazioni matriciali. Per rompere la linearità di queste operazioni, si utilizza una funzione di attivazione. 
$$z_{i+1}=f_{i}(w_{i}^T z_{i}+b_{i})$$

**Perché le funzioni di attivazione devono essere derivabili?**
Perché all'interno del grafo di computazione, se dobbiamo propagare le rette, a un certo punto dobbiamo calcolare la derivata della funzione di attivazione. Quindi, la derivata deve essere calcolabile in modo abbastanza semplice. Deve essere una funzione predefinita del nostro framework.

**Quali funzioni di attivazione possiamo utilizzare?**
Ci sono molte funzioni di attivazione che possiamo utilizzare. Due esempi sono la funzione logistica e la funzione ReLU (Rectified Linear Unit).

**Funzione Logistica:**

La funzione logistica è una funzione sigmoidale che restituisce un valore compreso tra 0 e 1. È spesso utilizzata per la classificazione binaria.

**Funzione ReLU:**

La funzione ReLU è una funzione lineare che restituisce il valore di input se è positivo, e 0 se è negativo. È spesso utilizzata per la classificazione multi-classe.

**Funzione Logistica e Tangente Iperbolica:**

La funzione logistica e la tangente iperbolica sono funzioni continue con derivate facilmente calcolabili. La derivata della funzione logistica è data dal prodotto della funzione stessa per il suo inverso, mentre la derivata della tangente iperbolica è simile.

## Regola del Gradiente

### Il Passo di Forward

Il passo di forward calcola la derivata rispetto a tutti i valori che si trovano intorno alla simboide. In questo caso, i valori intorno alla sigmoide saranno tutti 0,1. Al termine del passo di forward, il passo di backward, che rappresenta il passo che ci riporta indietro, dovrebbe cancellare le regali.

Non dobbiamo calcolare la derivata in modo diretto. Dobbiamo applicare ripetutamente la regola della catena, ovvero calcolare la serie di prodotti derivati. Questi prodotti sono rappresentati da questa formula: **NON SO SE SIA CORRETTA** 
$$ \frac{\partial L}{\partial w_{i}} = \frac{\partial L}{\partial z_{n}} \times \frac{\partial z_{n}}{\partial z_{n-1}} \times ... \times \frac{\partial z_{i+1}}{\partial z_{i}} \times \frac{\partial z_{i}}{\partial w_{i}} $$

### Il Problema del Gradiente Evanescente

![[2-transcripted-processed-20241017105550172.png|359]]
Il range della derivata della logistica (linea blu) è limitato a 0,25. Questo significa che la funzione logistica è identica a $0.25^4$, che è un valore molto basso. Questo problema è chiamato **problema del gradiente evanescente**.

Il problema del gradiente vanescente è dovuto al fatto che il passo di forward, se applicato ripetutamente, tende a far sparire il gradiente, ovvero a trasferirlo.

Questo risultato è dovuto alla regola che utilizziamo per aggiornare i parametri, che è molto sensibile al gradiente. La regola dice che:
$$\theta^{(t+1)} = \theta^{(t)} - \alpha \times \nabla \theta$$
Se il gradiente è molto piccolo, come nel caso del problema del gradiente vanescente, l'aggiornamento dei parametri sarà molto lento.

## Calcolo del Gradiente e Funzioni di Attivazione

Il calcolo del gradiente è un processo fondamentale nell'apprendimento automatico, in particolare nelle reti neurali. Questo processo ci permette di aggiornare i parametri della rete per minimizzare la funzione di perdita (loss).

### Gradiente della Loss

Consideriamo una rete neurale con 5 layer. Se volessimo calcolare il gradiente della loss rispetto a un parametro specifico (ad esempio, un peso W), dovremmo considerare come questo parametro influenza la loss attraverso tutti i layer.

**Esempio:**

Se il parametro W si trova nel primo layer, il suo effetto sulla loss si propaga attraverso tutti i layer successivi. Per calcolare il gradiente di W rispetto alla loss, dovremmo considerare la derivata della loss rispetto all'output del primo layer, moltiplicata per la derivata dell'output del primo layer rispetto a W.

### Funzioni di Attivazione

Le funzioni di attivazione sono cruciali nelle reti neurali, in quanto introducono non linearità nel modello, permettendo di approssimare funzioni complesse.

**Funzione di Attivazione ReLU (Rectified Linear Unit):**

![[2-transcripted-processed-20241017105915593.png]]
La ReLU è una funzione di attivazione molto popolare, definita come:
$$ReLU(x) = max(0, x)$$
La ReLU è derivabile dappertutto, tranne che in x = 0. La sua derivata è:
$$ReLU'(x) = \begin{cases}
1 & \text{se } x > 0 \\
0 & \text{altrimenti}
\end{cases}$$

**Vantaggi della ReLU:**

* Semplicità di calcolo
* Riduzione del problema del vanishing gradient 

**Funzione di Attivazione Softmax:**

La Softmax è una funzione di attivazione utilizzata per la classificazione, che restituisce una distribuzione di probabilità sulle classi.

**Vantaggi della Softmax:**

* Garantisce che la somma delle probabilità di tutte le classi sia uguale a 1.
* Permette di ottenere una misura di confidenza per ogni classe.

### Effetto delle Funzioni di Attivazione sul Gradiente

La scelta della funzione di attivazione può influenzare il comportamento del gradiente durante il processo di apprendimento.

**Esempio:**

Se utilizziamo la ReLU, il gradiente può diventare zero per i neuroni con attivazione negativa. Questo può portare al problema del gradiente che svanisce, in cui il gradiente diventa troppo piccolo per aggiornare efficacemente i parametri della rete.

**Soluzioni:**

* Utilizzare altre funzioni di attivazione, come la Softmax o la tanh.
* Utilizzare tecniche di normalizzazione dei dati, come la Batch Normalization.

### Altre Funzioni di Attivazione

Oltre alla ReLU e alla Softmax, esistono altre funzioni di attivazione utilizzate nelle reti neurali, come:

* **Tanh (Tangente Iperbolica):** Restituisce un valore compreso tra -1 e 1.
* **Sigmoid:** Restituisce un valore compreso tra 0 e 1.

La scelta della funzione di attivazione dipende dal problema specifico e dalle caratteristiche del dataset.

## Funzioni di Loss e Gradiente di Computazione

$$l=\sum_{i} Cost(y_{i},\hat{y_{i}}(\theta))$$
Alcune delle funzioni di loss che abbiamo visto sono utilizzate in diverse architetture. 

**Funzioni di Loss:**

* **Negative Log-Likelihood:** Questa funzione è stata già discussa e corrisponde alla **Binary Cross-Entropy** nel caso della classificazione binaria. La Binary Cross-Entropy è semplicemente la Negative Log-Likelihood applicata alla classificazione binaria.
* **Categorical Cross-Entropy:** Questa funzione è utilizzata per la classificazione a più classi ed è un'altra variante della Negative Log-Likelihood.
![[2-transcripted-processed-20241017110124282.png|638]]
**Concetto Generale di Loss:**

Il concetto di loss è più generale e può essere applicato punto a punto. La funzione di loss confronta il risultato corrente della rete ($Y$) con il risultato atteso ($\hat{y}$). La loss è la sommatoria di questa differenza su tutti i punti o su un sottoinsieme di punti.

**Relazione tra Loss e Gradiente di Computazione:**

La funzione di loss è strettamente legata al gradiente di computazione. Il gradiente di computazione è il risultato del calcolo della derivata della funzione di loss rispetto ai parametri della rete. Questo gradiente viene utilizzato per aggiornare i parametri della rete durante l'addestramento.

**Derivabilità della Funzione di Loss:**

La funzione di loss deve essere derivabile per poter calcolare il gradiente. La Binary Cross-Entropy, ad esempio, utilizza il logaritmo, che è una funzione derivabile. Questo permette di estendere il gradiente di computazione alla funzione di loss.

**Calcolo del Gradiente:**

Il gradiente viene calcolato propagando all'indietro (backpropagation) il valore della loss attraverso la rete, rispetto ai parametri che ci interessano.

## Ottimizzazione: Discesa del Gradiente Stocastico e Varianti

![[2-transcripted-processed-20241017110140279.png|574]]
### Discesa del Gradiente Stocastico: Problemi e Soluzioni

La Discesa del Gradiente Stocastico è uno strumento popolare per l'ottimizzazione, ma presenta alcuni limiti. Ad esempio, se la funzione da ottimizzare ha una forma complessa, il gradiente di scendita stocastico può seguire un percorso tortuoso e inefficiente. Questo perché ogni passo si basa solo sull'ultimo gradiente, senza considerare la direzione generale.

**Esempio:**

Consideriamo una rete neurale con una matrice 3x2 e un vettore di 2 elementi. Per linearizzare la rete, abbiamo bisogno di 9 parametri. Applicando un metodo del secondo ordine, dovremmo calcolare la matrice Hessiana di questi parametri, che sarebbe una matrice 9x9. Questa matrice è troppo grande per essere gestibile, soprattutto per reti più complesse.

**Soluzioni:**

Per superare questi problemi, si possono utilizzare varianti della Discesa del Gradiente Stocastico che combinano le direzioni dei gradienti precedenti. Queste varianti cercano di migliorare l'efficienza del processo di ottimizzazione, evitando percorsi tortuosi e inefficienti.

### Varianti della Discesa del Gradiente Stocastico

Esistono diverse varianti della Discesa del Gradiente Stocastico, che modificano il modo in cui viene calcolato il gradiente durante l'addestramento di un modello di apprendimento automatico. L'obiettivo è migliorare la velocità di convergenza e la stabilità del processo di ottimizzazione.

Alcune delle varianti più comuni includono:

* **Momentum update:** Questa variante tiene conto della direzione del gradiente precedente, aggiungendo una componente di inerzia al passo di aggiornamento. Questo aiuta a superare i minimi locali e a raggiungere più rapidamente il minimo globale.
* **RMSprop:** Questa variante adatta la dimensione del passo di aggiornamento in base alla varianza del gradiente. Questo aiuta a stabilizzare il processo di ottimizzazione e a evitare oscillazioni eccessive.
* **Adam:** Questa variante combina i vantaggi di Momentum e RMSprop, adattando sia la direzione che la dimensione del passo di aggiornamento. È una delle varianti più popolari e spesso fornisce risultati eccellenti.

### Adam Optimizer

Una delle varianti più popolari è l'**Adam Optimizer**. L'Adam Optimizer utilizza un gradiente **stocastro** per aggiornare i pesi del modello. Questo significa che ad ogni passo di aggiornamento, il gradiente viene calcolato su un sottoinsieme casuale dei dati di addestramento.

**Formula di Adam:**

L'aggiornamento dei pesi in Adam è dato dalla seguente formula:

$$w = \frac{{w - \alpha \cdot m_t}}{\sqrt{v_t} + \epsilon}$$

Dove:

* **w** è il vettore dei pesi del modello.
* **α** è la learning rate.
* **m_t** è la stima della media del gradiente.
* **v_t** è la stima della varianza del gradiente.
* **ε** è un piccolo valore per evitare divisioni per zero.

**Come funziona Adam:**

Adam combina due tecniche:

* **Momentum:** La stima della media del gradiente (m_t) tiene conto dei gradienti precedenti, permettendo al processo di ottimizzazione di "ricordare" la direzione generale del movimento.
* **RMSprop:** La stima della varianza del gradiente (v_t) aiuta a normalizzare il gradiente, rendendo l'ottimizzazione più stabile.

**Vantaggi di Adam:**

* **Convergenza più rapida:** Adam converge più velocemente rispetto ad altri metodi di ottimizzazione, come il gradiente discendete stocastico (SGD). Questo perché Adam è in grado di adattarsi alla direzione e alla dimensione del passo di aggiornamento e di trovare una direzione di movimento più efficiente.
* **Stabilità:** Adam è più stabile rispetto a SGD, soprattutto quando si lavora con dati ad alta dimensionalità.

## Classificazione di Immagini con Reti Neurali

Questo esempio illustra come utilizzare una rete neurale per classificare immagini. Il dataset utilizzato è composto da immagini di numeri scritti a mano, con dimensioni 28x28 pixel (784 pixel totali). Ogni immagine è in scala di grigi, con un solo canale di valori da 0 a 255. L'obiettivo è classificare ogni immagine come un numero da 0 a 9.

**Esempio:**

* **Immagine:** Un'immagine di un numero scritto a mano.
* **Classificazione:** Il numero corrispondente all'immagine.

**Implementazione:**

Per costruire la rete neurale, possiamo utilizzare PyTorch. La prima cosa da fare è definire il tensore che rappresenta l'immagine. La prima dimensione del tensore rappresenta il canale (in questo caso, 1 per il canale di grigi). Le altre due dimensioni rappresentano l'altezza e la larghezza dell'immagine (28x28).

**Costruzione della rete neurale:**

La rete neurale può essere costruita utilizzando i blocchi di base di PyTorch, come i layer lineari e le funzioni di attivazione.

**Addestramento della rete neurale:**

La rete neurale viene addestrata utilizzando un set di dati di immagini e le loro etichette corrispondenti. L'addestramento consiste nell'aggiornare i pesi della rete in modo da minimizzare l'errore di classificazione.

**Valutazione della rete neurale:**

Dopo l'addestramento, la rete neurale può essere valutata utilizzando un set di dati di test. La valutazione misura la precisione della rete nella classificazione di immagini non viste durante l'addestramento.

