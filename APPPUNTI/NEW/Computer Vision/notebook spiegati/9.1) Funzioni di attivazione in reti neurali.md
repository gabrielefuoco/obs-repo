

Questo codice esplora diverse funzioni di attivazione utilizzate nelle reti neurali, visualizzandone graficamente il comportamento e le derivate, e analizzando il problema del gradiente evanescente.  Utilizzando PyTorch, vengono sfruttate le capacità di autodifferenziazione per calcolare le derivate in modo efficiente.

### 1. Importazione delle librerie

```python
import os
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import image as mp_image
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
from matplotlib import cm
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
```

Questo blocco importa le librerie necessarie: `numpy` per operazioni numeriche, `matplotlib` per la visualizzazione dei grafici, e `torch` con le sue sottolibrerie `nn` (reti neurali) e `functional` (funzioni neurali) per la parte di deep learning.

### 2. Funzione Logistica (Sigmoide)

```python
x = torch.tensor(np.linspace(-20,20,1000))
sigmoid = nn.Sigmoid()
y = sigmoid(x)
plt.figure()
plt.plot(x,y,color='r')
# ... (codice per la visualizzazione del grafico) ...
plt.title("$y=\sigma(x)$")
plt.show()
```

Questo codice crea un tensore `x` contenente 1000 valori equispaziati tra -20 e 20.  Viene poi applicata la funzione sigmoide (`nn.Sigmoid()`) a `x`, ottenendo `y`. Infine, viene generato un grafico che mostra la funzione sigmoide.  `plt.axhline` e `plt.axvline` aggiungono linee orizzontali e verticali per evidenziare gli assi e i valori limite della funzione.

![png](7.Neural_networks_6_0.png)  (Grafico della funzione sigmoide)

La derivata della sigmoide è calcolata analiticamente e visualizzata:

```python
plt.plot(x,y,color="r",label="$y=\sigma(x)$")
plt.plot(x,y*(1-y),color='b',label="$y=\sigma'(x)$")
# ... (codice per la visualizzazione del grafico) ...
plt.show()
```

Il grafico mostra sia la funzione sigmoide che la sua derivata, evidenziando come la derivata sia sempre positiva e abbia valori massimi intorno a x=0.

![png](7.Neural_networks_8_0.png) (Grafico della funzione sigmoide e della sua derivata)


### 3. Funzione Tangente Iperbolica

Analogamente alla sigmoide, il codice visualizza la tangente iperbolica e la sua derivata:

```python
tanh = nn.Tanh()
y = tanh(x)
plt.figure()
plt.plot(x,y,color='r')
# ... (codice per la visualizzazione del grafico) ...
plt.title("$y=\sigma(x)$")
plt.show()
```

![png](7.Neural_networks_12_0.png) (Grafico della funzione tangente iperbolica)

```python
plt.plot(x,y,color="r",label="$y=tanh(x)$")
plt.plot(x,1-y**2,color='b',label="$y=tanh'(x)$")
# ... (codice per la visualizzazione del grafico) ...
plt.show()
```

![png](7.Neural_networks_14_0.png) (Grafico della funzione tangente iperbolica e della sua derivata)


### 4. Utilizzo di `autograd` di PyTorch per la derivata della tangente iperbolica

Questo esempio utilizza la funzione `backward()` di PyTorch per calcolare la derivata della tangente iperbolica:

```python
x = torch.tensor(np.linspace(-20,20,1000),requires_grad=True)
y = torch.tanh(x)
y.backward(torch.ones(1000))
plt.figure()
plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=tanh(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=tanh'(x)")
# ... (codice per la visualizzazione del grafico) ...
plt.show()
```

`requires_grad=True` indica a PyTorch di tracciare il gradiente per `x`. `y.backward()` calcola il gradiente di `y` rispetto a `x`, che viene poi visualizzato nel grafico.  `detach().numpy()` converte i tensori PyTorch in array NumPy per la compatibilità con Matplotlib.

![png](7.Neural_networks_18_0.png) (Grafico della tangente iperbolica e della sua derivata calcolata con autograd)


### 5. Altre funzioni di attivazione

Il codice esplora altre funzioni di attivazione, come ReLU, Leaky ReLU, ecc., visualizzandone il grafico e la derivata usando lo stesso approccio di `autograd`:

```python
g = lambda x: F.leaky_relu(x,.1) # Funzione Leaky ReLU
y = g(x)
x.grad.zero_() # azzera il gradiente precedente
y.backward(torch.ones(1000))
plt.figure()
plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=g(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=g'(x)")
# ... (codice per la visualizzazione del grafico) ...
plt.show()
```

![png](7.Neural_networks_20_0.png) (Grafico di una funzione di attivazione e della sua derivata)


### 6. Automatic Differentiation e Gradiente Evanescente

Questo sezione illustra il calcolo del gradiente tramite autodifferenziazione e poi analizza il problema del gradiente evanescente con la sigmoide e la ReLU.

Il codice mostra un esempio di calcolo del gradiente per un'operazione di moltiplicazione di matrici e addizione, usando `backward()` per ottenere i gradienti.

```python
x = torch.ones((3,2),requires_grad = True)
y = torch.ones((2,2),requires_grad = True)*0.5
z = torch.ones((3,2),requires_grad = True)*0.25
# ... (calcolo di z1, z2, y1, o) ...
o.backward()
print(y.grad)
```

Infine, vengono mostrati due esempi, uno con la sigmoide e uno con la ReLU, per illustrare come la scelta della funzione di attivazione influenzi la propagazione del gradiente durante l'addestramento di una rete neurale profonda, evidenziando il problema del gradiente evanescente (con la sigmoide) e la sua mitigazione (con la ReLU).  Il codice calcola il gradiente di `y` rispetto a `w1` in entrambi i casi, mostrando la differenza significativa nell'entità del gradiente.


In sintesi, il codice fornisce una panoramica completa delle principali funzioni di attivazione utilizzate nelle reti neurali, mostrando graficamente il loro comportamento e le loro derivate, e illustrando l'importanza della scelta della funzione di attivazione per evitare il problema del gradiente evanescente durante l'addestramento.  L'utilizzo di PyTorch semplifica il calcolo delle derivate tramite autodifferenziazione.


Questo documento illustra la costruzione e l'addestramento di una rete neurale convoluzionale (CNN) di tipo LeNet per la classificazione di immagini del dataset MNIST.  Analizziamo passo passo il codice e le immagini generate.

**1. Caricamento del Dataset MNIST:**

```python
import torchvision
import torchvision.transforms as transforms
batch_size = 64
# MNIST dataset
train_dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)
test_dataset = torchvision.datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())
# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)
```

Questo codice importa le librerie necessarie (`torchvision` per il dataset e le trasformazioni, `torch.utils.data` per il caricamento dei dati) e carica il dataset MNIST.  `transforms.ToTensor()` converte le immagini in tensori PyTorch.  `train_loader` e `test_loader` creano iteratori per i dati di training e test, suddividendoli in batch di dimensione 64.  `shuffle=True` mescola i dati di training ad ogni epoca.

```python
image, label = train_dataset[0]
print(image.shape)
```

Questo snippet stampa la forma di una singola immagine del dataset di training, che risulta essere `torch.Size([1, 28, 28])`, indicando un singolo canale (scala di grigi), 28 pixel di altezza e 28 pixel di larghezza.

Il seguente codice visualizza le prime 9 immagini del dataset:

```python
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.title("Class {}".format(label))
    plt.axis('off')
```
![png](7.Neural_networks_38_0.png)
Questo codice crea una griglia 3x3 di immagini, mostrando le prime nove immagini del dataset MNIST con le rispettive etichette.


**2. Definizione della rete LeNet:**

```python
class LeNet(nn.Module):
    def __init__(self,input_size):
        super(LeNet, self).__init__()
        # Convolutional Layers
        self.features = nn.Sequential(
            nn.Conv2d(1, 6, 5), nn.Tanh(), nn.AvgPool2d(2,stride = 2),
            nn.Conv2d(6, 16, 5), nn.Tanh(), nn.AvgPool2d(2,stride = 2)
        )
        fm_size = ((input_size - 6 )//2 - 5)//2 + 1
        fc_layer_in_size = 16*fm_size*fm_size
        # Linear layers
        self.fc = nn.Sequential(
            nn.Linear(fc_layer_in_size, 120), nn.Tanh(),
            nn.Linear(120, 84), nn.Tanh(), nn.Linear(84, 10)
        )
    def forward(self, x):
        features = self.features(x)
        features_flattened = features.view(features.size(0),-1)
        out = self.fc(features_flattened)
        output = F.log_softmax(out, dim=1)
        return output
```

Questa classe definisce l'architettura della rete LeNet.  `__init__` inizializza i layers convoluzionali (`nn.Conv2d`), le funzioni di attivazione `Tanh` e i layers di pooling (`nn.AvgPool2d`). Calcola anche la dimensione dell'input per i layers lineari (`nn.Linear`) dopo l'applattamento.  La funzione `forward` definisce il flusso di dati attraverso la rete: convoluzioni, pooling, applattamento e layers completamente connessi.  `F.log_softmax` applica la funzione softmax logaritmica per ottenere probabilità di appartenenza alle classi.

```python
lenet_model = LeNet(28).to(device)
```

Questa riga crea un'istanza della rete LeNet con input di dimensione 28x28 e la sposta sul dispositivo specificato (`device`, CPU o GPU).

La stampa di `lenet_model` mostra l'architettura della rete:

```python
lenet_model
```
LeNet( (features): Sequential( (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (1): Tanh() (2): AvgPool2d(kernel_size=2, stride=2, padding=0) (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (4): Tanh() (5): AvgPool2d(kernel_size=2, stride=2, padding=0) ) (fc): Sequential( (0): Linear(in_features=256, out_features=120, bias=True) (1): Tanh() (2): Linear(in_features=120, out_features=84, bias=True) (3): Tanh() (4): Linear(in_features=84, out_features=10, bias=True) ) )


**3. Addestramento della rete:**

```python
criterion = nn.CrossEntropyLoss()
learning_rate = 0.0005
optimizer = torch.optim.Adam(lenet_model.parameters(), lr=learning_rate)
num_epochs = 3
train_losses = []
train_counter = []
test_losses = []
test_counter = [i*len(train_loader.dataset) for i in range(num_epochs + 1)]
```

Questo codice definisce la funzione di perdita (`nn.CrossEntropyLoss`), l'ottimizzatore (`torch.optim.Adam`) e il numero di epoche.

Le funzioni `train` e `test` gestiscono rispettivamente l'addestramento e la valutazione della rete:

```python
total_step = len(train_loader)
def train(epoch,model,criterion,optimizer,reshape=True):
    # ... (codice per l'addestramento) ...
def test(model,criterion,reshape=True):
    # ... (codice per la valutazione) ...
```

La funzione `train` esegue un'iterazione sui dati di training, calcola la perdita, esegue la backpropagation e aggiorna i pesi della rete.  La funzione `test` valuta la rete sui dati di test, calcolando la perdita e l'accuratezza.  Il parametro `reshape` permette di gestire l'input sia come immagini (False) che come vettori (True).

```python
test(lenet_model,criterion,reshape=False)
for epoch in range(1,num_epochs+1):
    train(epoch,lenet_model,criterion,optimizer,reshape=False)
    test(lenet_model,criterion,reshape=False)
```

Questo codice esegue l'addestramento per 3 epoche, valutando la rete dopo ogni epoca.  L'output mostra la perdita e l'accuratezza su ogni test.


**4. Visualizzazione delle feature map:**

```python
extractor_1 = lambda im: lenet_model.features[:1](im.unsqueeze(0))
extractor_2 = lambda im: lenet_model.features[:4](im.unsqueeze(0))
```

Queste due funzioni estraggono le feature map dopo il primo layer convoluzionale (`extractor_1`) e dopo i primi quattro layers (`extractor_2`).

Il codice seguente visualizza le feature map estratte da alcune immagini del dataset:

```python
# ... (codice per visualizzare le feature map di extractor_1) ...
![png](7.Neural_networks_48_0.png)
# ... (codice per visualizzare le feature map di extractor_2) ...
![png](7.Neural_networks_49_0.png)
```
Le immagini mostrano le feature map estratte dai diversi layers convoluzionali. Si nota come le feature diventano più complesse man mano che si procede in profondità nella rete.

Infine, il codice visualizza i kernel dei primi due layers convoluzionali:

```python
# ... (codice per visualizzare i kernel del primo layer convoluzionale) ...
![png](7.Neural_networks_50_0.png)
# ... (codice per visualizzare i kernel del secondo layer convoluzionale) ...
![png](7.Neural_networks_51_0.png)
```
Queste immagini mostrano i filtri (kernel) appresi dalla rete durante l'addestramento.  Si può osservare come i kernel del secondo layer siano più complessi rispetto a quelli del primo.


In sintesi, il documento presenta un esempio completo di costruzione, addestramento e analisi di una CNN per la classificazione di immagini MNIST, illustrando i concetti chiave delle reti convoluzionali e fornendo strumenti per la visualizzazione delle feature map e dei kernel.


## Adattamento della rete LeNet per la classificazione CIFAR-10

Questo documento descrive l'adattamento della rete neurale LeNet per la classificazione delle immagini del dataset CIFAR-10.  CIFAR-10 è un dataset composto da 60.000 immagini a colori di dimensione 32x32 pixel, suddivise in 10 classi: aereo (0), automobile (1), uccello (2), gatto (3), cervo (4), cane (5), rana (6), cavallo (7), nave (8), camion (9).

### Caricamento del Dataset CIFAR-10

Il codice seguente mostra come caricare il dataset CIFAR-10 utilizzando la libreria `torchvision`.  Il dataset viene diviso in un insieme di training e un insieme di validazione.

```python
tensor_cifar10 = torchvision.datasets.CIFAR10(root='data', train=True, download=True,transform=transforms.ToTensor())
tensor_cifar10_val = torchvision.datasets.CIFAR10(root='data', train=False, download=True,transform=transforms.ToTensor())
```

**Spiegazione:**

* `torchvision.datasets.CIFAR10`: Questa funzione carica il dataset CIFAR-10.
* `root='data'`: Specifica la directory dove salvare il dataset scaricato.
* `train=True`: Indica che si sta caricando l'insieme di training.  `train=False` indica l'insieme di validazione.
* `download=True`: Scarica il dataset se non è già presente nella directory specificata.
* `transform=transforms.ToTensor()`:  Applica una trasformazione alle immagini, convertendole in tensori PyTorch. Questo è necessario per l'utilizzo con le reti neurali.


Il codice non include la definizione della rete LeNet, né il codice di training.  Per completare l'esercizio, sarebbe necessario:

1. **Definire l'architettura di LeNet:**  Questo implicherebbe la creazione di un modello PyTorch che replichi l'architettura di LeNet, adattandola eventualmente alle dimensioni delle immagini CIFAR-10 (32x32 invece delle 28x28 di MNIST, per cui LeNet è stato originariamente progettato).  Ciò potrebbe richiedere modifiche al numero di filtri e alle dimensioni dei layer convoluzionali e di pooling.

2. **Definire la funzione di loss e l'ottimizzatore:**  Scelta di una funzione di loss appropriata (ad esempio, CrossEntropyLoss) e di un ottimizzatore (ad esempio, Adam o SGD).

3. **Addestrare il modello:**  Utilizzo di un ciclo di training per iterare sul dataset di training, calcolare la loss, effettuare backpropagation e aggiornare i pesi della rete.

4. **Valutare il modello:**  Utilizzo del dataset di validazione per valutare le prestazioni del modello addestrato.


In sintesi, il codice fornito si limita al caricamento del dataset.  Per completare l'esercizio di adattamento di LeNet a CIFAR-10, sono necessari ulteriori passi di definizione del modello, training e valutazione.  Nessuna immagine è stata fornita nel testo originale, quindi non è possibile includere immagini nella spiegazione.


