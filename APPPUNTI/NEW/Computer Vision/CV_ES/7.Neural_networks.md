```python
import os
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import image as mp_image
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
from matplotlib import cm

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
```

# Funzioni di attivazione

## Funzione logistica

```python
x = torch.tensor(np.linspace(-20,20,1000))
```

```python
sigmoid = nn.Sigmoid()
```

```python
y = sigmoid(x)
```

```python
plt.figure()

plt.plot(x,y,color='r')

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.title("$y=\sigma(x)$")
plt.show()
```

![png](7.Neural_networks_6_0.png)

La derivata della funzione logistica è esprimibile come $$\sigma'(x) = \sigma(x)\cdot (1-\sigma(x))$$

Se plottiamo quest'ultima abbiamo 

```python
plt.figure()

plt.plot(x,y,color="r",label="$y=\sigma(x)$")
plt.plot(x,y*(1-y),color='b',label="$y=\sigma'(x)$")

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
#plt.grid(True, which='both')
plt.show()
```

![png](7.Neural_networks_8_0.png)

## Tangente iperbolica

```python
tanh = nn.Tanh()
```

```python
y = tanh(x)
```

```python
plt.figure()

plt.plot(x,y,color='r')

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.title("$y=\sigma(x)$")
plt.show()
```

![png](7.Neural_networks_12_0.png)

La derivata della tangente iperbolica è $$\frac{\partial}{\partial x}tanh(x) = 1- tanh(x)^2$$

Plottandola otteniamo

```python
plt.figure()

plt.plot(x,y,color="r",label="$y=tanh(x)$")
plt.plot(x,1-y**2,color='b',label="$y=tanh'(x)$")

plt.axhline(y=0.5, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
#plt.grid(True, which='both')
plt.show()
```

![png](7.Neural_networks_14_0.png)

### Utilizziamo autograd di Pytorch

```python
x = torch.tensor(np.linspace(-20,20,1000),requires_grad=True)

```

```python
y = torch.tanh(x)

y.backward(torch.ones(1000))
```

```python
plt.figure()

plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=tanh(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=tanh'(x)")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.show()
```

![png](7.Neural_networks_18_0.png)

Vediamo le altre funzioni di attivazione

```python
#g = F.relu
#g = F.relu6 
#g = F.elu 
#g = F.selu 
#g = F.celu
#g = F.gelu
g = lambda x: F.leaky_relu(x,.1)
#g = F.tanhshrink
#g = F.softplus

y = g(x)

x.grad.zero_()
y.backward(torch.ones(1000))

plt.figure()

plt.plot(x.detach().numpy(),y.detach().numpy(),color='r',label="y=g(x)")
plt.plot(x.detach().numpy(),x.grad.detach().numpy(),color='b',label="y=g'(x)")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

plt.axhline(y=-1, color='tab:gray', linestyle='dotted')
plt.axhline(y=1, color='tab:gray', linestyle='dotted')
plt.axhline(y=0, color='tab:gray', linestyle='dotted')
plt.axvline(x=0, color='tab:gray', linestyle='dotted')

#plt.grid(True, which='both')
plt.show()

```

![png](7.Neural_networks_20_0.png)

### Automatic differentiation

### Esercizio

Calcolare il grafo e le derivate

```python
x = torch.ones((3,2),requires_grad = True)

y = torch.ones((2,2),requires_grad = True)*0.5
y.retain_grad()
z = torch.ones((3,2),requires_grad = True)*0.25
z.retain_grad()

z1 = torch.mm(x,y)
z2 = z1 + z
z2.retain_grad()

y1 = z2*torch.tensor([[1,0],[2,1],[0,1]]) + z

o = torch.sum(y1)

```

```python
o.backward()

y.grad
```

 tensor([[3., 2.],
 [3., 2.]])

Esploriamo il problema del gradiente evanescente

```python
sigmoid = torch.sigmoid

x = torch.tensor(2.0)

w1 = torch.tensor(1.2,requires_grad=True)
a1 = x*w1
z1 = sigmoid(a1)

w2 = torch.tensor(0.1,requires_grad=True)
a2 = z1*w2
z2 = sigmoid(a2)

w3 = torch.tensor(1.2,requires_grad=True)
a3 = z2*w3
z3 = sigmoid(a3)

w4 = torch.tensor(-0.5,requires_grad=True)
a4 = z3*w4
z4 = sigmoid(a4)

w5 = torch.tensor(1.0,requires_grad=True)
a5 = z4*w5
y = sigmoid(a5)

```

```python
print(y)

y.backward()
```

 tensor(0.6033, grad_fn=<SigmoidBackward>)

```python

w1.grad
```

 tensor(-3.0186e-05)

```python
with torch.no_grad():
    print(sigmoid(a2)*(1-sigmoid(a2))*w2*sigmoid(a1)*(1-sigmoid(a1))*x)
```

 tensor(0.0038)

Riscriviamo il tutto usando la RELU

```python
activation = torch.relu

x = torch.tensor(2.0)

w1 = torch.tensor(1.0,requires_grad=True)
a1 = x*w1
z1 = activation(a1)

w2 = torch.tensor(0.1,requires_grad=True)
a2 = z1*w2
z2 = activation(a2)

w3 = torch.tensor(1.2,requires_grad=True)
a3 = z2*w3
z3 = activation(a3)

w4 = torch.tensor(0.5,requires_grad=True)
a4 = z3*w4
z4 = activation(a4)

w5 = torch.tensor(1.0,requires_grad=True)
a5 = z4*w5
y = torch.sigmoid(a5)

```

```python
y
```

 tensor(0.5300, grad_fn=<SigmoidBackward>)

```python

y.backward()

w1.grad
```

 tensor(0.0299)

# Reti convoluzionali

Riprendiamo il dataset MNIST. 

```python
import torchvision
import torchvision.transforms as transforms

batch_size = 64

# MNIST dataset 
train_dataset = torchvision.datasets.MNIST(root='data', 
                                           train=True, 
                                           transform=transforms.ToTensor(),  
                                           download=True)

test_dataset = torchvision.datasets.MNIST(root='data', 
                                          train=False, 
                                          transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)
```

```python
image, label = train_dataset[0]

print(image.shape)
```

 torch.Size([1, 28, 28])

```python
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.title("Class {}".format(label))
    plt.axis('off')
```

![png](7.Neural_networks_38_0.png)

```python
class LeNet(nn.Module):
    def __init__(self,input_size):
        super(LeNet, self).__init__()
        # Convolutional Layers
        self.features = nn.Sequential(
            nn.Conv2d(1, 6, 5),
            nn.Tanh(),
            nn.AvgPool2d(2,stride = 2), 
            nn.Conv2d(6, 16, 5),
            nn.Tanh(),
            nn.AvgPool2d(2,stride = 2)
        )
        fm_size = ((input_size - 6 )//2 - 5)//2 + 1
        fc_layer_in_size = 16*fm_size*fm_size    

        # Linear layers
        self.fc = nn.Sequential(
            nn.Linear(fc_layer_in_size, 120),
            nn.Tanh(),
            nn.Linear(120, 84),
            nn.Tanh(),
            nn.Linear(84, 10)
        )

    def forward(self, x):
        features = self.features(x)

        # Flatten the tensor along the second dimension
        features_flattened = features.view(features.size(0),-1)  

        out = self.fc(features_flattened)

        output = F.log_softmax(out, dim=1)

        return output
```

### Esercizio

Modificare la rete utilizzando attivazioni `ReLU` e `MaxPool`

```python

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

lenet_model = LeNet(28).to(device)
```

```python
lenet_model
```

 LeNet(
 (features): Sequential(
 (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
 (1): Tanh()
 (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
 (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
 (4): Tanh()
 (5): AvgPool2d(kernel_size=2, stride=2, padding=0)
 )
 (fc): Sequential(
 (0): Linear(in_features=256, out_features=120, bias=True)
 (1): Tanh()
 (2): Linear(in_features=120, out_features=84, bias=True)
 (3): Tanh()
 (4): Linear(in_features=84, out_features=10, bias=True)
 )
 )

```python
# Loss and optimizer
criterion = nn.CrossEntropyLoss()
learning_rate = 0.0005
optimizer = torch.optim.Adam(lenet_model.parameters(), lr=learning_rate)  

num_epochs = 3

train_losses = []
train_counter = []
test_losses = []
test_counter = [i*len(train_loader.dataset) for i in range(num_epochs + 1)]
```

```python
# The number of steps for each epoch, defined by the number of instances divided by the batch size. 
total_step = len(train_loader)

def train(epoch,model,criterion,optimizer,reshape=True):
    for batch_idx, (images, labels) in enumerate(train_loader):  
        # Move tensors to the configured device
        if reshape:
            images = images.reshape(-1, 28*28)
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (batch_idx+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))

        train_losses.append(loss.item())
        train_counter.append(
        (batch_idx*batch_size) + ((epoch-1)*len(train_loader.dataset)))

def test(model,criterion,reshape=True):
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for images, labels in test_loader:
            if reshape:
                images = images.reshape(-1, 28*28)

            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            correct += (predicted == labels).sum().item()

            loss = criterion(outputs,labels,)

            test_loss += loss.item()

    test_loss /= len(test_loader.dataset)
    test_losses.append(test_loss)

    print('\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
```

```python
test(lenet_model,criterion,reshape=False)
for epoch in range(1,num_epochs+1):
    train(epoch,lenet_model,criterion,optimizer,reshape=False)
    test(lenet_model,criterion,reshape=False)
```

 Test set: Avg. loss: 0.0362, Accuracy: 981/10000 (10%)

 Epoch [1/3], Step [100/938], Loss: 0.8890

 Epoch [1/3], Step [900/938], Loss: 0.1675

 Test set: Avg. loss: 0.0027, Accuracy: 9476/10000 (95%)

 Epoch [2/3], Step [100/938], Loss: 0.1317

 Epoch [2/3], Step [900/938], Loss: 0.1456

 Test set: Avg. loss: 0.0015, Accuracy: 9705/10000 (97%)

 Epoch [3/3], Step [100/938], Loss: 0.0986

 Epoch [3/3], Step [900/938], Loss: 0.0643

 Test set: Avg. loss: 0.0012, Accuracy: 9743/10000 (97%)

```python
lenet_model.features
```

 Sequential(
 (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
 (1): Tanh()
 (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
 (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
 (4): Tanh()
 (5): AvgPool2d(kernel_size=2, stride=2, padding=0)
 )

```python
extractor_1 = lambda im: lenet_model.features[:1](im.unsqueeze(0))

extractor_2 = lambda im: lenet_model.features[:4](im.unsqueeze(0))
```

```python
from torchvision.utils import make_grid

plt.figure(figsize=(20,20))

n = 6
k = 1

for i in range(n):
    plt.subplot(n,2,k)
    k = k+1
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.axis('off')
    features = extractor_1(image).permute(1,0,2,3)
    img = make_grid(features,padding=5,normalize=True).permute(1,2,0).detach().numpy()
    plt.subplot(n,2,k)
    k = k + 1
    plt.tight_layout()
    plt.imshow(img,cmap='gray', interpolation='none')
    plt.axis('off')

```

![png](7.Neural_networks_48_0.png)

```python

plt.figure(figsize=(20,20))

n = 6
k = 1

for i in range(n):
    plt.subplot(n,2,k)
    k = k+1
    plt.tight_layout()
    image, label = train_dataset[i]
    plt.imshow(image[0],cmap='gray', interpolation='none')
    plt.axis('off')
    features = extractor_2(image).permute(1,0,2,3)
    img = make_grid(features,normalize=True).permute(1,2,0).detach().numpy()
    plt.subplot(n,2,k)
    k = k + 1
    plt.tight_layout()
    plt.imshow(img,cmap='gray', interpolation='none')
    plt.axis('off')

```

![png](7.Neural_networks_49_0.png)

```python
plt.figure(figsize=(20,20))

kernels = lenet_model.features[0].weight.detach()
img = make_grid(kernels,normalize=True).permute(1, 2, 0)
plt.imshow(img, interpolation='none',cmap=cm.hot)
plt.axis('off')

plt.show()

```

![png](7.Neural_networks_50_0.png)

```python
plt.figure(figsize=(20,20))

kernels = lenet_model.features[3].weight

kernels = kernels.view(kernels.shape[0]*kernels.shape[1],1,kernels.shape[2],kernels.shape[3])

img = make_grid(kernels,normalize=True)

img = img.permute(1, 2, 0).detach().numpy()

plt.imshow(img, interpolation='none',cmap=cm.hot)
plt.axis('off')

plt.show()
```

![png](7.Neural_networks_51_0.png)

## Esercizio

Adattare la rete LeNet per effettuare classificazione sul dataset CIFAR10

CIFAR-10 consiste di 60000 immagini 32x32 (RGB), etichettate con un intero che corrisponde a 10 classi: airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), truck (9).

```python
tensor_cifar10 = torchvision.datasets.CIFAR10(root='data', train=True, download=True,transform=transforms.ToTensor())
tensor_cifar10_val = torchvision.datasets.CIFAR10(root='data', train=False, download=True,transform=transforms.ToTensor())

```
