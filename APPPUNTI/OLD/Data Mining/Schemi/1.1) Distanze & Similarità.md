##### Distanze

* **Distanza Euclidea:**
 * Formula: $d(x, y) = \sqrt{\sum_{k=1}^n (x_k - y_k)^2}$
 * Richiede normalizzazione per attributi con scale diverse.

* **Distanza di Minkowski:**
 * Generalizzazione della distanza euclidea.
 * Formula: $d(x, y) = \left(\sum_{k=1}^n |x_k - y_k|^r \right)^{1/r}$
 * r = 1: Distanza di Manhattan
 * r = 2: Distanza Euclidea
 * r = ∞: Distanza del Supremum

* **Distanza di Mahalanobis:**
 * Generalizzazione della distanza euclidea per variabili con scale diverse o correlate.
 * Utile per attributi con varianze diverse e distribuzione approssimativamente normale.
 * Formula: $d(x, y) = \sqrt{(x - y)^T \Sigma^{-1} (x - y)}$

* **Proprietà delle Distanze (Metriche):**
 * Positività: $d(x, y) \ge 0$ e $d(x, y) = 0$ sse $x = y$
 * Simmetria: $d(x, y) = d(y, x)$
 * Disuguaglianza Triangolare: $d(p, r) \le d(p, q) + d(q, r)$

##### Range Queries

* Recupero di dati in un intervallo di valori.
* Ottimizzazione con la disuguaglianza triangolare:
 * Punti $x_i$ tali che $d(p,q)-d(p,x_{i})>r$ possono essere scartati.
 * Punti $x_i$ tali che $d(p,x_{i})+d(p,q)<r$ possono essere accettati senza ulteriori calcoli.

##### Dissimilarità non metriche

* Esempio: `size(A-B)` non soddisfa simmetria e disuguaglianza triangolare.
* Definizione alternativa: $d(A,B)=size(A-B)+size(B-A)$

##### Similarità

* Proprietà:
 * $s(p,q)=1$ sse $p=q$
 * $s(p,q)=s(q,p)$ (simmetria)
* Non esiste un equivalente alla disuguaglianza triangolare.

##### Similarità tra Vettori

* **Vettori Binari:**
 * **Coefficienti di Similarità:** Valori tra 0 e 1.
 * **Simple Matching Coefficient (SMC):** $SMC=\frac{M_{11}+M_{00}}{M_{00}+M_{11}+M_{01}+M_{10}}$ (Considera ugualmente presenze e assenze).
 * **Jaccard Coefficient (J):** $J=\frac{M_{11}}{M_{11}+M_{01}+M_{10}}$ (Variante del SMC per attributi asimmetrici).
 * **Similarità del Coseno:** $cos(x,y)=\frac{x \cdot y}{||x|| \cdot ||y||}$ (Non considera M00; utilizzabile anche per vettori non binari).
 * **Tanimoto (Extended Jaccard Coefficient):** $EJ(x,y)=\frac{x \cdot y}{||x||^2+||y||^2-x \cdot y}$ (Per attributi continui o di intervallo).

* **Attributi Eterogenei:**
 * Similarità calcolata separatamente per ogni attributo ($s_k(x, y)$).
 * Parametro $\delta_k$: 0 per attributi asimmetrici con 0 o valori mancanti, 1 altrimenti.
 * Similarità finale: $similarity(x,y)=\frac{\left( \sum_{k=1}^n \delta_{k}s_{k}(x,y) \right)}{\sum_{k=1}^n \delta_{k}}$ (Peso $\omega_k$ aggiungibile per attributi con rilevanza diversa).

* **Correlazione:** Misura la relazione lineare (range [-1,1]).
 * **Correlazione di Pearson:** $corr(x,y)=\frac{Cov(x,y)}{StDev(x)\cdot StDev(y)}$ (Covarianza di popolazione o di campione).

* **Confronto Misure di Prossimità:**
 * Similarità del coseno: invariante a ridimensionamento, non a traslazione.
 * Distanza euclidea: suscettibile a entrambi.
 * Correlazione: invariante a entrambi.

* **Densità:** Misura la vicinanza degli oggetti (rilevazione cluster/anomalie).
 * **Densità Euclidea:** Numero di punti per unità di volume (center-based o grid-based).

##### Preprocessing per Data Mining

I. **Obiettivo:** Preparare i dati per l'applicazione di algoritmi di Data Mining.

II. **Tecniche Principali:**

 A. **Aggregazione:** Combinazione di attributi per ridurre la cardinalità del dataset.

 B. **Campionamento:** Riduzione delle dimensioni del dataset per migliorare l'efficienza.
 1. **Campionamento casuale semplice:** Ogni elemento ha uguale probabilità di selezione.
 a. _Senza reimbussolamento_: elementi non riscelti.
 b. _Con reimbussolamento_: elementi possono essere riscelti. Risultati simili a senza reimbussolamento se campione << popolazione.
 2. **Campionamento stratificato:** Campionamento casuale semplice applicato a sottoinsiemi (strati) della popolazione. Utile per popolazioni eterogenee.

 C. **Riduzione della dimensionalità:** Riduzione del numero di attributi per evitare la "Curse of Dimensionality" e migliorare l'efficienza.
 1. **Selezione degli attributi:** Rimozione di attributi ridondanti o irrilevanti.
 a. **Approcci:** Esaustivo (complessità 2<sup>n</sup>), non esaustivi (embedded, filtro, euristici).
 2. **Creazione degli attributi:** Estrazione di nuove caratteristiche o combinazione di attributi esistenti.

 D. **Discretizzazione:** Conversione di attributi continui in discreti.
 1. **Discretizzazione non supervisionata:**
 a. **Equi-larghezza:** Intervalli di uguale ampiezza.
 b. **Equi-frequenza:** Intervalli con uguale numero di istanze.
 c. **K-mediani:** Minimizzazione della distanza intra-cluster.
 2. **Discretizzazione supervisionata:** Massimizzazione della purezza degli intervalli rispetto alle classi (es. usando l'entropia).
 3. **Binarizzazione:** Rappresentazione di attributi discreti con attributi binari.

 E. **Trasformazione degli attributi:** Mappatura dell'insieme di valori di un attributo in un nuovo insieme, più adatto all'analisi.

