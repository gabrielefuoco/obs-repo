
**I. Modelli di Programmazione**

    A. Definizione: Interfaccia che separa proprietà di alto e basso livello (Skillicorn e Talia, 1998).
    B. Modello di Programmazione Parallela:
        1. Astrazione per architetture parallele.
        2. Aiuta nell'espressione di algoritmi e applicazioni parallele.
        3. Influenza il paradigma di esecuzione dei motori di elaborazione big data.
    C. Caratteristiche:
        1. Astrazione: Operazioni ad alto livello rispetto all'architettura sottostante.
        2. Stabilità: Interfaccia standard.
        3. Riduzione dello sforzo di implementazione.
    D. Livelli di Astrazione:
        1. Alto Livello:
            a. Permette di specificare la logica dell'applicazione.
            b. Nasconde i dettagli di basso livello.
            c. Si affida ai compilatori per l'ottimizzazione.
        2. Basso Livello:
            a. Permette l'interazione diretta con unità di calcolo e storage.
            b. Permette una specifica precisa del parallelismo dell'applicazione.

**II. Sistemi di Programmazione**

    A. Definizione: Implementazioni di uno o più modelli di programmazione.
    B. Strategie di Sviluppo:
        1. Sviluppo del linguaggio: Creazione di nuovi linguaggi o integrazione di costrutti paralleli in linguaggi esistenti.
        2. Approccio mediante annotazioni: Utilizzo di annotazioni per identificare istruzioni parallele.
        3. Integrazione della libreria: Inclusione di librerie per migliorare il parallelismo (approccio più popolare).
    C. Esempi:
        1. Modelli: MapReduce, passaggio di messaggi.
        2. Sistemi: Apache Hadoop, MPI.

**III. Modello MapReduce**

    A. Sviluppato da Google per l'elaborazione di big data.
    B. Ispirato alle funzioni *map* e *reduce* dei linguaggi funzionali.
    C. Strategia: Dividi e conquista.
        1. Dividere il problema in sottoproblemi.
        2. Eseguire sottoproblemi in parallelo.
        3. Combinare i risultati intermedi.
    D. Fasi:
        1. Map:
            a. Input: (chiave, valore)
            b. Output: list(chiave, valore)
            c. Formula: **map (k1, v1) → list(k2, v2)**
        2. Reduce:
            a. Input: (chiave, list(valore))
            b. Output: list(valore)
            c. Formula: **reduce (k2, list(v2)) → list(v3)**

**IV. Parallelismo in MapReduce**

    A. Fase Map: Chiavi elaborate contemporaneamente da computer diversi (sharding dei dati di input).
    B. Fase Reduce: Reducer che lavorano su chiavi distinte eseguiti contemporaneamente.
    C. Scalabilità: Da un singolo server a centinaia di migliaia di server.

---

## Schema Riassuntivo MapReduce

### 1. Astrazione della Parallelizzazione
    *   MapReduce semplifica la programmazione parallela.
    *   Gli sviluppatori si concentrano sulla logica di calcolo, non sull'implementazione della parallelizzazione.

### 2. Esempio: Indice Invertito
    *   Applicazione MapReduce per la creazione di indici invertiti.
    *   **Map:** Genera coppie `<parola, documentID>` per ogni documento.
    *   **Reduce:** Prende tutte le coppie per una parola, ordina gli ID dei documenti ed emette `<parola, lista(documentID)>`.
    *   L'insieme di tutte le coppie di output create dalla funzione reduce forma l'indice invertito.

### 3. Struttura di un Job MapReduce
    *   **Job:** Programma MapReduce composto da:
        *   Codice per le fasi map e reduce.
        *   Impostazioni di configurazione (es. posizione dei dati di output).
        *   Dataset di input (memorizzato su un file system distribuito).
    *   **Task:** Unità più piccole in cui è diviso un job.
        *   **Mapper:** Task Map.
        *   **Reducer:** Task Reduce.
    *   Workflow di job MapReduce: Composizione di più job per applicazioni complesse.

### 4. Modello Master-Worker
    *   **Nodo Utente:** Invia il job al nodo master.
    *   **Nodo Master:**
        *   Identifica i worker inattivi.
        *   Assegna task map o reduce ai worker.
        *   Coordina l'intero flusso del job.
        *   Fornisce il risultato al nodo utente.

### 5. Elaborazione MapReduce
    *   **Job Descriptor:** Inviato al master, descrive il task e la posizione dei dati di input.
    *   **Master:** Avvia processi mapper e reducer su macchine diverse.
        *   Distribuisce i dati di input (chunk) ai mapper.
    *   **Mapper:** Applica la funzione `map` per creare coppie intermedie `(chiave, valore)`.
    *   **Reducer:** Alloca coppie con le stesse chiavi.
        *   Applica la funzione `reduce` per unire i dati con la stessa chiave e produrre un set più piccolo di valori.
    *   **Output:** Raccolti e inviati alla posizione specificata nel job descriptor.

### 6. Fase Combine
    *   Ottimizzazione per aumentare la velocità.
    *   Esegue una fase di minireduce (combinazione) sull'output map locale.
    *   **Combiner:** Aggrega l'output map locale.
        *   `combine (k2, list(v2)) → list(v3)`
    *   Riduce la quantità di dati intermedi e il traffico di rete.
    *   In molti casi, la stessa funzione può essere utilizzata sia per la combinazione che per la riduzione finale.

### 7. Fase Shuffle e Sort
    *   Operazione *group-by* distribuita implicita tra map (con combine) e reduce.
    *   Trasferisce l'output del mapper ai reducer.
    *   Unisce e ordina i dati per chiave prima di raggiungere ogni reducer.
    *   Le chiavi intermedie vengono scritte sul disco locale di ogni computer nel cluster.

---

Ecco lo schema riassuntivo del testo fornito:

**I. Fase di Reduce in MapReduce**

    A.  **Notifica ai Reducer:** Lo scheduler di MapReduce avvisa i reducer al termine della fase di Map.
    B.  **Recupero Dati:** I reducer recuperano le coppie (chiave, valore) ordinate.
        1.  **Provenienza:** I dati provengono dai mapper.
        2.  **Specificità:** I dati sono ordinati per le partizioni assegnate a ciascun reducer.

---
