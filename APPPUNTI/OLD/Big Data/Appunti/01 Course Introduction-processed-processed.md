
# Modelli e Tecniche per il Big Data

## Motivazioni e Obiettivi

Il mondo moderno genera una quantità di dati senza precedenti. La capacità di estrarre informazioni preziose da questi dati è fondamentale per il successo in numerosi campi, tra cui business, scienza e governo. L'implementazione di applicazioni di gestione e analisi dati scalabili, che estraggono efficientemente schemi, modelli e tendenze utili, è il modo migliore per sfruttare il valore di questa massiccia quantità di dati. Programmare applicazioni per il big data è un compito complesso e multiforme che richiede una profonda comprensione di concetti quali analisi dei dati, calcolo distribuito, elaborazione parallela e machine learning.

Questo corso guida gli sviluppatori nello sviluppo di applicazioni big data robuste e scalabili. Fornisce una comprensione approfondita dei principi e delle pratiche necessarie per implementare applicazioni di analisi del big data efficienti, utilizzando gli strumenti più popolari in contesti reali. Il corso offre indicazioni sulla scelta degli strumenti più adatti a ogni caso d'uso specifico, trattando inoltre le ultime tendenze, come l'informatica exascale e il machine learning parallelo e distribuito, e mostrando come sfruttarle per analizzare ed elaborare grandi set di dati.

## Argomenti Principali

1. **Sistemi di Storage Distribuiti:** I principali sistemi di storage distribuiti, essenziali per affrontare la crescita esponenziale dei dati, garantendo scalabilità, efficienza, tolleranza ai guasti, disponibilità e coerenza.

2. **Analisi Dati e Data Science:** I principi fondamentali dell'analisi dei dati e della data science, e il loro sviluppo su sistemi di calcolo scalabili.

3. **Tecnologie per l'Elaborazione del Big Data:** I vantaggi di tecnologie come l'high-performance computing, il cloud computing e il calcolo distribuito nell'elaborazione di grandi quantità di dati in contesti reali.

4. **Modelli di Programmazione per il Big Data:** I principali modelli di programmazione che supportano l'espressione di algoritmi e applicazioni parallele, fornendo un'astrazione per l'architettura di un computer parallelo. Questo include le ultime proposte nell'area del calcolo exascale, mirate a fornire soluzioni e strumenti scalabili in vari campi scientifici (fisica, biologia, simulazione di fenomeni naturali).

5. **Strumenti di Programmazione:** Gli strumenti di programmazione più utilizzati per l'elaborazione del big data, che gestiscono diversi tipi di dati (strutturati, grafi, flussi) e domini (applicazioni batch, streaming, basate su grafi e query).

6. **Scelta del Framework:** Le caratteristiche principali dei diversi framework per aiutare i programmatori nella scelta del framework più appropriato, considerando fattori come il tipo di dati, la scala dell'infrastruttura, le competenze degli sviluppatori e le dimensioni della community.

## Testo di Riferimento

**D. Talia, P. Trunfio, F. Marozzo, L. Belcastro, R. Cantini, A. Orsino** *Programming Big Data Applications* **World Scientific – 2024 ISBN 978-1-80061-504-5**

## Contenuti del Libro

- **Concetti di Big Data** (Capitolo 2)
- **Modelli di Programmazione per il Big Data** (Capitolo 3)
- **Strumenti per le Applicazioni Big Data** (Capitolo 4)
- **Confronto tra Strumenti di Programmazione** (Capitolo 5)
- **Scegliere il Framework Giusto per Dominare il Big Data** (Capitolo 6)

## Dettagli dei Capitoli

### Concetti di Big Data (Cap. 2)

- Principi e Caratteristiche del Big Data
- Concetti di Data Science
- Archiviazione del Big Data
- Analisi Dati Scalabile
- Calcolo Parallelo
- Cloud Computing
- Verso il Calcolo Exascale
- Machine Learning Parallelo e Distribuito

### Modelli di Programmazione per il Big Data (Cap. 3)

- Programmazione Parallela per Applicazioni Big Data
- Il Modello MapReduce
- Il Modello Workflow
- Il Modello a Passaggio di Messaggi
- Il Modello BSP
- Il Modello SQL-like
- Il Modello PGAS
- Modelli per Sistemi Exascale

### Strumenti per le Applicazioni Big Data (Cap. 4)

- Strumenti di Programmazione basati su MapReduce (Apache Hadoop)
- Strumenti di Programmazione basati su Workflow (Apache Spark, Apache Storm, Apache Airflow)
- Strumenti di Programmazione basati sul Passaggio di Messaggi (Message Passing Interface)
- Strumenti di Programmazione basati su BSP (Spark GraphX)
- Strumenti di Programmazione SQL-like (Apache Hive, Apache Pig)
- Strumenti di Programmazione basati su PGAS (UPC++)

### Confronto tra Strumenti di Programmazione (Cap. 5)

- Analisi Comparativa delle Funzionalità del Sistema
- Analisi Comparativa tramite Esempi di Applicazione
- Applicazione Batch: Spark vs Hadoop
- Applicazione Streaming: Storm vs Spark Streaming
- Applicazione SQL: Hive vs Spark SQL
- Applicazione Grafo: MPI vs Spark GraphX

### Scegliere il Framework Giusto per Dominare il Big Data (Cap. 6)

- Dati di Input
- Classe di Applicazione
- Infrastruttura
- Altri Fattori

## Risorse Online

Le diapositive basate sui contenuti del libro sono disponibili tramite Microsoft Teams. Un repository online con codice e dataset utilizzati negli esempi è disponibile all'indirizzo: [https://bigdataprogramming.github.io](https://bigdataprogramming.github.io/). Il repository fornisce container Docker per l'esecuzione senza problemi degli esempi e una guida per l'installazione, la compilazione e l'esecuzione dei programmi.
