## Costruzione di Feature Automatiche in Reti Neurali

Possiamo costruire feature automatiche in reti neurali. La registrazione di un'idea significa una struttura di rete di questo tipo, in cui l'idea è partire dal liquido, che è un vettore o un tensore, e poi propagare su vari livelli, dove ogni livello rappresenta una feature che viene costruita a partire dal livello precedente. Tutto questo può essere rappresentato da una computazione con una serie di operazioni matriciali.

Il problema è che all'inizio il nostro input sarà l'immagine che trasformiamo in un vettore. Come la trasformiamo in un vettore? Basta semplicemente miliarizzare l'immagine. Quindi assumiamo un percorso di esplorazione dell'immagine e su questo percorso si costruisce l'immagine. Sì, abbiamo tre matrici, la stessa cosa, queste tre matrici possono essere contattate con l'altra, rosso, verde e blu, quindi prima il vettore dei verdi, poi il vettore dei rossi, poi il vettore dei verdi e poi il vettore dei rossi, poi il vettore dei verdi e poi il vettore dei rossi. È semplicemente un fatto di protezione. In realtà non faremo neanche questo, però giusto per arrivare alla prima rete cornevale che è come costruirci, facciamo stare per lì.

Quindi questo è l'input, l'output, la nostra inizio, può essere costruita in vari modi, lo score può essere numerico, può essere binario, quindi avremo una funzione logistica, oppure può essere ultima se abbiamo la funzione soltrona. E poi, nei vari layer, passare dal layer i al layer il più unesimo, facciamo questi carabinari, però abbiamo bisogno di rompere la linearità con una funzione di attivazione.

Quali funzioni di attivazione ci servono? Intanto ci servono le funzioni che sono derivabili. Perché devono essere derivabili? Perché all'interno del grafo di computazione, si è andato a guardarlo un attimo, questo semplice grafo di computazione ci dice che a un certo punto se dobbiamo propagare le rette, a un certo punto proviamo come istituzione di attivazione. Quindi non è il nostro cambiamento. E l'antipo deve essere calcolabile in una realtà abbastanza semplice. Deve essere una funzione predefinita del nostro framework.

Ora, le funzioni di attivazione che possiamo utilizzare sono tante. Qui le trovate due. Questa è la funzione logistica e questa è la funzione d'agente metodica. Se andate a guardare il notebook che vi stavo mostrando precedentemente, il notebook si chiama il notebook.1.7 di Eronetworks. Notate che ci sono un po' di funzioni di attivazione. Cioè ci viene illustrato un po' di queste funzioni di attivazione. La funziona di attivazione logistica organizza la funziona di siti mobile e il plot che avete visto sulle slide è in realtà è questo. La cosa interessante è che questa funzione c'è una derivata di esprimibile, cioè questa funzione è una funzione continua, c'è una derivata di esprimibile in maniera abbastanza semplice. Non è altro che il prodotto della funzione stessa per l'inverso della funzione. Se volete la possiamo vedere qui.

Tenete a mente questo disegno perché poi questo disegno ci sar utile tra un po'. Quindi in rosso il dolore della funzione in blu trovate il valore della derivata. La stessa cosa vale per l'angente perponica, l'angente perponica è una funzione abbastanza simile. 


## La differenza tra l'agente di poli e la logistica

La differenza principale tra l'agente di poli e la logistica è che la logistica è una funzione con un valore sempre positivo, mentre la funzione di poli restituisce un valore compreso tra -1 e 1. 

### Calcolo della derivata

La derivata di entrambe le funzioni è relativamente semplice da calcolare. Nel nostro framework, le derivate sono predefinite e possono essere propagate facilmente. Il grafico mostra la derivata della funzione di poli.

### Architettura di rete e layer profondi

Quando si utilizzano funzioni come la logistica o la funzione di poli, è importante notare che il numero di layer nella rete neurale tende ad essere molto alto. Questo perché queste funzioni richiedono un'architettura di rete profonda per ottenere risultati accurati.

### Esempio di rete neurale

Un esempio di rete neurale che utilizza la funzione di poli è il seguente:

* **Input:** X
* **Peso:** W
* **Funzione di attivazione:** Sigmoide (σ)
* **Output:** σ(X * W)

In questo esempio, l'input è un vettore di scalari, mentre il peso è una matrice. La funzione di attivazione sigmoide applica una trasformazione non lineare all'output del prodotto tra input e peso.

### Backpropagation e calcolo della derivata

Il processo di backpropagation, che permette di aggiornare i pesi della rete neurale, richiede il calcolo della derivata della funzione di attivazione rispetto all'input. In questo caso, la derivata della funzione di poli è limitata a 0.25 alla quarta potenza.

### Conclusione

La scelta tra la funzione di poli e la logistica dipende dal problema specifico che si vuole risolvere. La funzione di poli è adatta per problemi con output limitato tra -1 e 1, mentre la logistica è più adatta per problemi con output positivo. 


## Il problema del gradiente svanente

**Introduzione:**

Il problema del gradiente svanente è un problema comune nell'addestramento di reti neurali profonde. Si verifica quando il gradiente, utilizzato per aggiornare i pesi della rete durante l'apprendimento, diventa molto piccolo durante la propagazione all'indietro. Questo può portare a un apprendimento lento o addirittura all'arresto dell'apprendimento.

**Esempio:**

Consideriamo un esempio semplice: 0.25 elevato alla quarta potenza. Questo valore è molto piccolo (0.00390625). Questo problema si verifica perché il gradiente si moltiplica per il valore della derivata della funzione di attivazione ad ogni layer della rete. Se la derivata è inferiore a 1, il gradiente si riduce ad ogni passo.

**Cause:**

Il problema del gradiente svanente è causato principalmente da:

* **Funzioni di attivazione:** Funzioni di attivazione come la sigmoide hanno una derivata che è limitata tra 0 e 1. Quando il valore di input è molto grande o molto piccolo, la derivata diventa molto piccola, causando la diminuzione del gradiente.
* **Numero di layer:** Più layer ha la rete, più il gradiente si moltiplica per le derivate delle funzioni di attivazione, portando a una diminuzione esponenziale del gradiente.

**Soluzioni:**

Esistono diverse soluzioni per mitigare il problema del gradiente svanente:

* **Funzioni di attivazione alternative:** Utilizzare funzioni di attivazione come ReLU (Rectified Linear Unit) o Leaky ReLU, che hanno una derivata costante per valori positivi, evitando la diminuzione del gradiente.
* **Inizializzazione dei pesi:** Inizializzare i pesi della rete in modo appropriato può aiutare a prevenire il problema del gradiente svanente.
* **Batch normalization:** La batch normalization aiuta a normalizzare gli input di ogni layer, rendendo il gradiente più stabile.
* **Shortcut connections:** Le shortcut connections, come quelle utilizzate nelle reti ResNet, permettono al gradiente di bypassare alcuni layer, evitando la sua diminuzione.

**Conclusione:**

Il problema del gradiente svanente è un problema significativo nell'addestramento di reti neurali profonde. Comprendere le cause e le soluzioni a questo problema è essenziale per costruire reti neurali efficaci. Le soluzioni descritte sopra possono aiutare a mitigare il problema e migliorare le prestazioni delle reti neurali.


## Funzioni di Attivazione e Funzioni di Loss

### Funzioni di Attivazione

Abbiamo visto che la **REC5 Units** è una funzione di attivazione che restituisce un valore di 10,25. Questo valore è diverso da quello ottenuto con la **rectified linearity**. 

La **REC5 Units** non è l'unica funzione di attivazione disponibile. All'interno del notebook sono presenti altre funzioni, tra cui la **soft class**, che ha un comportamento simile alla **rectified linearity**. 

Tutte queste funzioni sono adatte al problema che stiamo affrontando. Alcune di esse vengono utilizzate in specifiche architetture.

### Funzioni di Loss

Le funzioni di loss sono state già introdotte. La funzione di loss che abbiamo definito è la **negative log-likelihood**, che nel caso della classificazione binaria corrisponde alla **binary cross-entropy**. La **binary cross-entropy** è semplicemente la **log-likelihood** applicata alla classificazione binaria.

Nel caso della classificazione a più classi, abbiamo la **categorical cross-entropy**, che è un'altra variante della **log-likelihood**.

Il concetto di loss è più generale. Come abbiamo visto, la loss può essere applicata punto a punto. Questo ci permette di confrontare il risultato corrente con il risultato desiderato dalla nostra rete.

Possiamo definire la loss come la sommatoria su tutti i punti (o su un sottoinsieme di punti) di una funzione di distanza tra il risultato corrente **Y** e il risultato desiderato **Y_hat**.

**Y** è il risultato in uscita dal nostro programma di computazione, mentre **Y_hat** è il risultato che ci aspettiamo.

La funzione di loss deve essere derivabile. Ad esempio, la **binary cross-entropy** è una funzione che mette in corrispondenza **Y** con il logaritmo di **Y_hat**. Il logaritmo è una funzione derivabile, quindi siamo nello stesso contesto.

Il grafo di computazione si estende a questa ulteriore funzione. La **eta**, il quarto colomo, compare sulla **Y**. Quindi, alla fine, la funzione di loss è una funzione di tutti i parametri.

Questi parametri si propagano all'interno della rete tramite il risultato della rete stessa. Quando calcoliamo il gradiente rispetto a questi parametri, stiamo in realtà propagando, con lo stesso metodo della **backpropagation**, questo valore all'interno della rete, rispetto ai parametri che ci interessano.

Il concetto di loss è più generale. L'implementazione che abbiamo visto è quella della **cross-entropy**, ma ci sono molti altri modi per esprimere questa funzione, che vedremo in seguito. 


## Ottimizzazione e Gradiente di Scendito Stocastico

Questa sezione tratta l'ottimizzazione, un processo fondamentale nell'apprendimento automatico. In particolare, si concentra sul gradiente di scendito stocastico (SGD) e sulle sue varianti.

### Ottimizzazione: Il Problema

L'obiettivo dell'ottimizzazione è trovare i parametri che minimizzano una funzione di costo. Il gradiente di scendito è uno strumento popolare per questo scopo, ma presenta alcuni limiti.

**Limiti del Gradiente di Scendito:**

* **Dimensione dei parametri:** Per reti neurali con molti parametri, il calcolo della matrice Hessiana (necessaria per metodi di secondo ordine) diventa computazionalmente proibitivo.
* **Stabilità numerica:** Matrici di grandi dimensioni possono portare a problemi di stabilità numerica.

### Gradiente di Scendito Stocastico (SGD)

Il SGD è un'alternativa al gradiente di scendito che aggiorna i parametri utilizzando un sottoinsieme dei dati (batch) ad ogni passo. Questo rende il processo più efficiente, ma può portare a un percorso di ottimizzazione tortuoso.

**Problema del SGD:**

* **Percorso tortuoso:** Il SGD può seguire un percorso tortuoso e inefficiente, soprattutto se la funzione di costo presenta molti minimi locali.

### Varianti del SGD

Per mitigare i problemi del SGD, sono state sviluppate diverse varianti che cercano di migliorare la stabilità e l'efficienza del processo di ottimizzazione.

**Adam:**

* **Combinazione di gradienti:** Adam combina i gradienti dei passi precedenti per ottenere una direzione di aggiornamento più stabile.
* **Formula:** La formula di Adam utilizza una combinazione ponderata dei gradienti passati per aggiornare i parametri.

**Conclusione:**

Le varianti del SGD, come Adam, sono strumenti essenziali per l'ottimizzazione di modelli di apprendimento automatico. Queste varianti migliorano la stabilità e l'efficienza del processo di ottimizzazione, consentendo di trovare soluzioni più accurate e veloci.


## Appunti sulla Rete Neurale per la Classificazione di Immagini

### Introduzione

Questo documento riassume i concetti chiave relativi alla classificazione di immagini utilizzando le reti neurali. In particolare, si analizza la velocità di convergenza di diversi metodi di ottimizzazione e si presenta un esempio pratico di classificazione di cifre scritte a mano.

### Velocità di Convergenza

La velocità di convergenza di un algoritmo di ottimizzazione è un fattore cruciale per la sua efficacia. In questo contesto, si confrontano diversi metodi di ottimizzazione, evidenziando come alcuni, come il metodo del gradiente, convergono più rapidamente rispetto ad altri.

**Osservazioni:**

* Il metodo del gradiente mostra una convergenza più rapida rispetto ad altri metodi.
* La velocità di convergenza è influenzata dalla scelta del metodo di ottimizzazione.

### Esempio di Classificazione di Immagini

Si presenta un esempio di classificazione di immagini di cifre scritte a mano utilizzando una rete neurale.

**Dataset:**

* Il dataset utilizzato è composto da immagini di cifre scritte a mano di dimensione 28x28 pixel.
* Ogni immagine è rappresentata da un tensore di dimensione 784 (28x28).
* Le immagini sono in scala di grigi, con un solo canale (valori da 0 a 255).

**Obiettivo:**

* Classificare le immagini in base alla cifra rappresentata (da 0 a 9).

**Implementazione:**

* La rete neurale può essere implementata manualmente o utilizzando librerie come PyTorch.
* La prima dimensione del tensore di input rappresenta il canale (1 per le immagini in scala di grigi).
* Le altre due dimensioni rappresentano l'altezza e la larghezza dell'immagine.

**Nota:**

* La notazione utilizzata per il tensore di input è: `(canale, altezza, larghezza)`.

### Conclusione

Questo documento ha fornito una panoramica generale della classificazione di immagini utilizzando le reti neurali. Si è evidenziata l'importanza della velocità di convergenza dei metodi di ottimizzazione e si è presentato un esempio pratico di classificazione di cifre scritte a mano. 


## Appunti

Questo testo sembra essere una sequenza di numeri "due" ripetuti. Non è chiaro quale sia il contesto o l'obiettivo di questa sequenza. 

**Possibili interpretazioni:**

* **Errore di trascrizione:** Potrebbe essere un errore di trascrizione da un audio, dove il numero "due" è stato ripetuto per errore.
* **Sequenza numerica:** Potrebbe essere una sequenza numerica con un significato specifico, ma senza ulteriori informazioni è impossibile determinarlo.
* **Esercizio di memoria:** Potrebbe essere un esercizio di memoria per memorizzare una sequenza di numeri.

**Suggerimenti:**

* **Contesto:** Per comprendere il significato del testo, è necessario conoscere il contesto in cui è stato generato. 
* **Informazioni aggiuntive:** Se possibile, fornire informazioni aggiuntive come il titolo, l'autore o il tema degli appunti.

**Conclusione:**

Senza ulteriori informazioni, è impossibile fornire una formattazione significativa del testo. 


