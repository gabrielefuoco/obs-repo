
# Modello Booleano di Ricerca

## Descrizione

Il modello booleano di ricerca utilizza query booleane (termini di indice + operatori booleani: `AND`, `OR`, `NOT`) per interrogare un indice.  La corrispondenza è binaria: un documento soddisfa o non soddisfa la query. Questo modello è utilizzato in sistemi come WestLaw, sistemi di posta elettronica, cataloghi di biblioteche e macOS Spotlight.

## Esempio: WestLaw

WestLaw è un servizio di ricerca legale commerciale che utilizza query booleane con operatori di prossimità (es. `/3`, `/S`).  Un esempio di query è: `LIMIT! /3 STATUTE ACTION /S FEDERAL /2 TORT /3 CLAIM`. Questo esempio dimostra sia i vantaggi (precisione, raffinamento incrementale) che gli svantaggi (rigidità) del modello booleano.

## Vantaggi

* Query precise e lunghe.
* Supporto di operatori di prossimità.
* Sviluppo incrementale delle query.
* Maggiore precisione rispetto alle ricerche web.

## Limitazioni

### Rigidità

* L'operatore `AND` richiede la presenza di tutti i termini nella query.
* L'operatore `OR` richiede la presenza di almeno un termine nella query.
* Incoraggia query brevi e semplici.
* Scarsa flessibilità; non supporta l'espansione della query.
* Ogni termine è considerato in modo isolato.

### Difficoltà nel controllo dei risultati

* Nessun controllo sul numero di documenti recuperati.
* Nessuna classificazione dei risultati in base alla rilevanza.
* Impossibilità di utilizzare il feedback di rilevanza per migliorare la query.

### Espressività limitata

* Difficoltà nell'esprimere richieste complesse.
* Impossibilità di regolare l'importanza dei termini.
* Problema della sparsità nella rappresentazione dei dati.


## Esempio di difficoltà

Trovare opere di Shakespeare con "Brutus" e "Caesar" ma non "Calpurnia" è complesso e inefficiente con il modello booleano.  Anche le operazioni di prossimità (es. "Romans" vicino a "countrymen") sono problematiche.  Infine, il modello non supporta il recupero classificato.


## Conclusioni

Il modello booleano è adatto solo per query corte e semplici, quando l'obiettivo è solo determinare la presenza/assenza di un elemento.


# Estensioni del Modello Booleano per il Recupero dell'Informazione

## Estensione del Modello Booleano con Classificazione

**Obiettivo:** Ordinare i risultati del recupero booleano.

**Metodo:** Assegnazione di pesi (in [0,1]) ai termini; calcolo della similarità (es. Jaccard) tra query e documenti; ordinamento in base alla similarità.  Il feedback di rilevanza può essere utilizzato per raffinare ulteriormente l'ordinamento.

**Risultato:** Lista di risultati ordinata per rilevanza.


## Insiemi Fuzzy nel Recupero dell'Informazione

**Concetto:** Rilassamento dei confini degli insiemi booleani.

**Standard Booleano:** `d ∈ A` o `d ∉ A`.

**Fuzzy:** `d` è "più o meno" in `A`.

**Grado di Appartenenza:** `wA` indica il grado di appartenenza di `d` ad `A`.

**Operazioni Fuzzy:**

* Intersezione: $w(A∩B) = min(wA, wB)$
* Unione: $w(A∪B )= max(wA, wB)$


## Modelli di Similarità

### A. MMM (Mixed Min and Max Model)

**Query Disgiuntiva ($q_{or} = (t_1 \lor t_2 \lor \dots \lor t_n)$):** $S(q_{or}, d) = \lambda_{or} \cdot \max(w_1, \dots, w_n) + (1 - \lambda_{or}) \cdot \min(w_1, \dots, w_n)$ ($0 \le \lambda_{or} \le 1$)

**Query Congiuntiva ($q_{and} = (t_1 \land t_2 \land \dots \land t_n)$):** $S(q_{and}, d) = \lambda_{and} \cdot \min(w_1, \dots, w_n) + (1 - \lambda_{and}) \cdot \max(w_1, \dots, w_n)$ ($0 \le \lambda_{and} \le 1$)


### B. Modello di Paice

**Differenza da MMM:** Considera tutti i pesi dei termini, non solo il massimo e il minimo.

**Vantaggio:** Migliore risposta alle query.

**Svantaggio:** Maggior costo computazionale.


### C. Modello P-norma

**Caratteristiche:** Documenti e query come punti multidimensionali con pesi dei termini e operatori con coefficienti.

**Calcolo della Similarità:** Basato su due schemi di pesatura.


## Sparsità della Matrice Termine-Documento

**Rappresentazione:** Una matrice termine-documento densa è irrealistica.

**Esempio:** `N = 1M` documenti, `1000` parole/documento, `6 byte/parola` → `6 GB` di dati; `M = 500K` termini distinti.

**Problema:** Matrice `500K x 1M` con circa mezzo trilione di zeri. In realtà, non più di un miliardo di uni.

**Soluzione:** Rappresentazione sparsa: registrare solo le posizioni degli uni.

**Desiderata:** Struttura dati che rappresenti concetti e relazioni.


# Indice Inverso per la Ricerca di Documenti

## Definizione e Costruzione dell'Indice Inverso

### Definizione

Mappatura di ogni termine all'insieme dei documenti in cui appare.

---

# Indicizzazione e Ricerca di Informazioni

## I. Indice Inverted

**A. Vantaggi:** Efficienza di memorizzazione e velocità di ricerca.

**B. Costruzione:**

1. Identificazione dei documenti indicizzati per ogni termine (memorizzazione del `docID`).
2. Creazione della matrice termine-documento (traspone un array di documenti indicizzati).

**C. Struttura:**

1. Liste di postings (`docID` + frequenza): liste concatenate o array di lunghezza variabile.
2. Memorizzazione: su disco (sequenza continua) o in memoria.

**D. Considerazioni:** Compromessi tra efficienza di memorizzazione, velocità di accesso e facilità di aggiornamento.


## II. Struttura dell'Indice

**A. Dizionario:** Parole del corpus con puntatori alle liste di postings.

**B. Liste di postings:** Documenti in cui appare una parola (con frequenza).

**C. Doppia indicizzazione:**

1. Per chiave (dizionario).
2. Per documento (liste di postings).


## III. Processo di Indicizzazione (Indexer)

**A. Input:** Stream di coppie (termine, `docID`).

**B. Fasi:**

1. Generazione della sequenza di coppie (termine, `docID`).
2. Ordinamento per termine.
3. Ordinamento per `docID` (per ogni termine).
4. Unione di voci multiple (stesso termine, stesso documento).
5. Aggiunta della frequenza del termine nel documento.
6. Divisione in Dizionario (termini distinti con `termID`) e Postings (liste di postings con frequenze).


## IV. Elaborazione delle Query

**A. Esempio:** Query "*Brutus AND Caesar*".

**B. Passaggi:**

1. Recupero dei postings di "Brutus" dal dizionario.
2. Recupero dei postings di "Caesar" dal dizionario.
3. Intersezione delle liste di postings (algoritmo `INTERSECT`, tempo lineare rispetto alla somma delle dimensioni delle liste).


---

## Schema Riassuntivo: Elaborazione di Query nei Motori di Ricerca

### I. Unione di Postings (Intersezione di Insiemi)

* Algoritmo di intersezione lineare per due postings ordinati.
* Tempo di elaborazione proporzionale alla somma delle dimensioni dei postings.
* Esempio di elaborazione di query booleane AND.
* Pseudocodice:

```
INTERSECT(p1, p2)
answer ← ⟨ ⟩
while p1 ≠ NIL and p2 ≠ NIL do
  if docID(p1) = docID(p2) then
    ADD(answer, docID(p1))
    p1 ← next(p1)
    p2 ← next(p2)
  else if docID(p1) < docID(p2) then
    p1 ← next(p1)
  else
    p2 ← next(p2)
return answer
```

### II. Ottimizzazione dell'Elaborazione di Query

* **Query AND:** Ordinare i termini in base alla frequenza crescente (dal meno frequente al più frequente) per minimizzare la dimensione degli insiemi intermedi.
* **Esempio:** Query "Brutus AND Caesar AND Antony" (frequenze: Brutus 1000, Caesar 500, Antony 200) -> ordine ottimale: Antony, Caesar, Brutus.
* **Query Booleane arbitrarie (OR, NOT):** Stimare la dimensione degli insiemi OR (somma delle frequenze) e procedere in ordine crescente di queste stime.
* Tempo di elaborazione lineare rispetto al numero totale di voci nei postings.


### III. Query di Frase

* Importanza: Ricerca avanzata, comprensibilità per l'utente.
* Approcci:
    * **Indici Biword:** Indizza coppie consecutive di termini. Semplice per frasi a due parole.
    * **Scomposizione di frasi più lunghe:** Trasforma la frase in una query booleana sui biword. Rischio di falsi positivi e aumento della dimensione del dizionario. Non scalabile per frasi lunghe.
* Gli indici biword non sono la soluzione standard, ma parte di una strategia più complessa.


### IV. Etichettatura Morfologica (POST) e Biword Estensi

* Analisi POST: suddivisione del testo in termini e assegnazione di categorie grammaticali.
* Classificazione dei termini come nomi (N) o articoli/preposizioni (X).


---

## I. Indicizzazione Biword Estesa

**A. Definizione:** Identifica sequenze di termini $NX*N$, gestendo frasi complesse.

**Esempio:** "il cacciatore nella segale" -> "cacciatore segale"

**B. Elaborazione Query:**

1. Analisi: suddivisione della query in termini N e X.
2. Segmentazione: creazione di biword estesi dalla query.
3. Ricerca: ricerca dei biword estesi nell'indice.


## II. Indici Posizionali

**A. Funzionalità:** Memorizzano le posizioni di ogni termine nei documenti. `<termine, numero di documenti; doc1: posizione1, posizione2 … ; doc2: posizione1, posizione2 … ; …>`

Supporta query di frase e prossimità.

**B. Confronto con Biword:**

1. Indici posizionali: supportano query di frase e prossimità.
2. Indici biword: non supportano query di prossimità.

**C. Algoritmo di Unione Ricorsivo:**

Utilizza la fusione delle liste di `doc:posizione` per query di frase, gestendo complessità oltre la semplice uguaglianza.

---

# Indicizzazione di Grandi Collezioni di Documenti

## I. Algoritmo BSBI (Block-Sort-Based Indexing)

**A. Problema:** L'indicizzazione di grandi dataset (es. 100 milioni di record) in memoria è inefficiente.

**B. Soluzione:** Ordinamento esterno.

1. Suddivisione dei dati in blocchi più piccoli (es. 10 milioni di record).
2. Ordinamento interno di ogni blocco (es. Quicksort,  $O(N \log N)$).
3. Scrittura dei blocchi ordinati (run) su disco.
4. Unione delle run tramite merge esterno.

**C. Pseudocodice:**

```
BSBIndexConstruction()
1 n ← 0
2 while (all documents have not been processed)
3 do n ← n + 1
4 block ← ParseNextBlock()
5 BSBI-Invert(block)
6 WriteBlockToDisk(block, fn)
7 MergeBlocks(f_1, ..., f_n; f_merged)
```

**D. Ordinamento di 10 blocchi:** Due fasi: ordinamento interno (Quicksort) e merge esterno. Ottimizzazione dello spazio su disco per evitare due copie complete dei dati.


## II. Tecniche di Merge

**A. Merge Binario:**

1. Albero di merge con $\log_2(n)$ livelli (n = numero di run).
2. Merge parziali a ogni livello, leggendo, unendo e riscrivendo blocchi su disco.
3. Struttura a livelli: Partizionamento, merge parziale, aggiornamento dell'indice.

**B. Multi-way Merge:**

1. **Assunzione:** Condivisione parziale del lessico tra documenti.
2. Lettura simultanea da tutti i blocchi.
3. Richiede: apertura simultanea di file, buffer di lettura/scrittura, coda di priorità per `termID` più basso, unione di liste di postings.
4. Efficiente con blocchi di dimensioni adeguate.


## III. Problema della Crescita del Lessico durante il Merge

**A. Gestione di termini e ID:** Necessità di una corretta gestione.

**B. Compressione con perdita:** Applicabile solo a termini non essenziali.

**C. Valutazione dei token:** Strategie per valutare l'importanza dei token per la compressione.


## IV. Algoritmo SPIMI (Single-Pass In-Memory Indexing)

**A. Soluzione:** Approccio lazy per risolvere il problema della crescita del lessico durante l'indicizzazione di grandi collezioni.


## V. Dimensione dell'Indice Posizionale

**A. Espansione dell'archiviazione:** Una voce per ogni occorrenza, non solo per documento.

**B. Dipendenza dalla dimensione del documento:** La dimensione dipende dalla dimensione media dei documenti (compressione possibile).

**C. Regola empirica:**

1. 2-4 volte più grande di un indice non posizionale.
2. 35-50% del volume del testo originale.

**D. Utilizzo standard:** La potenza delle query di frase e prossimità ne giustifica l'utilizzo, anche implicito.


## VI. Costruzione dell'Indice: Scalabilità e Basi Hardware

**A. Limiti della costruzione in memoria:** Non scalabile per collezioni di grandi dimensioni (es. New York Times).

**B. Necessità di utilizzo del disco:** Vincoli di performance dovuti all'accesso ai dati.

**C. Basi hardware:** Server con ampia memoria (GB) e spazio su disco maggiore (2-3 ordini di grandezza). Preferenza per macchine standard a sistemi costosi con tolleranza ai guasti. Ottimizzazione I/O del disco tramite lettura/scrittura a blocchi (8KB-256KB).

**D. Ordinamento esterno:** Necessario per collezioni di grandi dimensioni, in quanto l'ordinamento diretto su disco è troppo lento.


## VII. Block Sort-Based Indexing

**A. Soluzione per la scalabilità:** Algoritmo di ordinamento esterno per la costruzione dell'indice su disco per grandi quantità di dati. (Dettagli non forniti nel testo).


## VIII. Superamento delle Limitazioni degli Algoritmi Basati sull'Ordinamento

**Idea Chiave 1: Generazione di Dizionari Separati per Blocco**

* Elimina la necessità di mantenere la mappatura termine-termID tra blocchi (mapping across block).

**Idea Chiave 2: Eliminazione dell'Ordinamento**

* Accumulo di postings nelle liste di postings durante l'elaborazione.
* Generazione di indici invertiti completi per ogni blocco, successivamente mergeabili.
* Maggiore velocità e risparmio di memoria rispetto agli algoritmi basati sull'ordinamento.
* Liste di postings come strutture dinamiche riallocate all'occorrenza.
* Esempio: Algoritmo SPIMI (vedi sotto).


## IX. Algoritmo SPIMI (Single-Pass Inverted index with Memory-mapped files)

**Pseudocodice:**

```python
1. output_file = NEWFILE()
2. dictionary = NEWHASH()
3. while (free memory available)
4. do token ← next(token_stream)
5. if term(token) ∉ dictionary
6. then postings_list = ADDToDICTIONARY(dictionary, term(token))
7. else postings_list = GETPOSTINGSLIST(dictionary, term(token))
8. if full(postings_list)
9.  then WRITEPOSTINGSLIST(postings_list, output_file)
10.     postings_list = NEWPOSTINGSLIST()
11. ADDToPOSTINGSLIST(postings_list, docID)
12. WRITEINDEX(dictionary, output_file)
```

**(Nota: Il codice Python è incompleto nel testo originale.  Ho completato la parte mancante in modo logico, ma potrebbe necessitare di adattamenti a seconda dell'implementazione specifica.)**

---

# Indicizzazione di Documenti: Tecniche e Strategie

## I. Schema MapReduce per la Costruzione dell'Indice

**Funzioni Map e Reduce:**

* `map`: input → list(k, v)
* `reduce`: (k,list(v)) → output

**Istanza per l'Indicizzazione:**

* `map`: collection → list(termID, docID)
* `reduce`: (`<termID1, list(docID)>`, `<termID2, list(docID)>`, …) → (postings list1, postings list2, …)


## II. Gestione di Documenti Dinamici

**Strategie:**

* **Indice Principale e Ausiliario:** Un indice principale contiene i documenti esistenti, mentre uno o più indici ausiliari vengono utilizzati per i nuovi documenti. Le ricerche vengono eseguite su entrambi gli indici, combinando i risultati.  *Problema*: Questa strategia è inefficiente con un unico grande file per l'indice a causa di frequenti operazioni di merge.

* **Eliminazione:** Un vettore di bit può indicare i documenti eliminati, filtrando i risultati della ricerca.

* **Re-indicizzazione:** La re-indicizzazione periodica dell'intero indice aggiorna le liste di postings per i termini esistenti e aggiunge nuovi termini al dizionario.


## III. Indicizzazione Distribuita

**Architettura:**

* Una macchina *master* coordina il processo.
* L'indice viene suddiviso in task paralleli (blocchi).
* I ruoli vengono assegnati ai nodi.

**Parsing Distribuito:**

* Porzioni di documenti (split) vengono assegnate a parser inattivi.
* Vengono estratte coppie (termine, documento ID).
* Le coppie vengono scritte in *j* partizioni (fold) basate su una suddivisione lessicografica dei termini.

**Inversione Distribuita dell'Indice:**

* Le coppie (termine, documento ID) vengono raccolte per ogni partizione.
* Le liste di postings vengono ordinate per termine.
* I risultati vengono scritti su disco.

**Modello MapReduce:**

* **Fase di Map:** Produce liste di coppie (termine, documento).
* **Fase di Reduce:** Produce le liste di postings (liste di documenti in cui un termine compare).


## IV. MapReduce e Sistemi di Indicizzazione

**MapReduce:** È un framework robusto e semplice per il calcolo distribuito.

**Sistema di indicizzazione di Google (circa 2002):** Era composto da fasi implementate in MapReduce.


## V. Tecniche di Fusione

**Fusione Logaritmica:**

* **Principio:** Utilizza una serie di indici di dimensioni crescenti (1, 2, 4, 8...). L'indice più piccolo risiede in memoria, mentre gli altri sono su disco.  La fusione avviene iterativamente fino all'ordinamento completo.
* **Memoria e Disco:** $Z_0$ (in memoria), $I_0, I_1, ...$ (su disco).
* **Complessità:** Ogni posting viene fuso al massimo $O\left( \log\left( \frac{T}{n} \right) \right)$ volte, con complessità totale $O\left( T \cdot \log\left( \frac{T}{n} \right) \right)$.

**Confronto con Fusione T/n (Indice Ausiliario e Principale):**

* **Fusione T/n:** Complessità nel caso peggiore $O\left( \frac{T^2}{n} \right)$.
* **Vantaggi Fusione Logaritmica:** Più efficiente della fusione T/n per la costruzione dell'indice.
* **Svantaggi Fusione Logaritmica:** L'elaborazione delle query è più complessa: $O\left( \log\left( \frac{T}{n} \right) \right)$ contro $O(1)$ della fusione semplice.


## VI. Problemi con Più Indici

**Gestione delle statistiche:** È difficile mantenere statistiche a livello di collezione (es. correzione ortografica) con più indici.

**Problema:** Come mantenere le migliori alternative con più indici e vettori di bit di invalidazione?

**Possibile soluzione:** Ignorare gli indici ausiliari per l'ordinamento, basando il ranking solo sull'indice principale.


## VII. Indicizzazione Dinamica nei Motori di Ricerca

**Approccio:**  Vengono effettuate modifiche incrementali frequenti per gestire dati dinamici (notizie, blog, nuove pagine web).


## VIII. Ricerca in Tempo Reale e Costruzione dell'Indice

**I. Ricostruzione Periodica dell'Indice:**

* Commutazione dell'elaborazione delle query su un nuovo indice.
* Eliminazione del vecchio indice.

**II. Requisiti per la Ricerca in Tempo Reale:**

* Bassa latenza: elevata produttività di valutazione delle query.
* Elevato tasso di ingestione: immediata disponibilità dei dati.
* Letture e scritture concorrenti: gestione simultanea di letture e scritture sull'indice.
* Dominanza del segnale temporale: priorità ai dati più recenti.

**III. Tecniche di Indicizzazione:**

**A. Indicizzazione basata sull'ordinamento:**

* Inversione in memoria naive.
* Indicizzazione basata sull'ordinamento bloccato (BSBI).
* Ordinamento per fusione (efficace per l'ordinamento basato su disco rigido).

**B. Indicizzazione in memoria a passaggio singolo (SPIMI):**

* Nessun dizionario globale.
* Generazione di un dizionario separato per ogni blocco.

```
5.  token ← NEXTTOKEN(document)
6.  IF dictionary.contains(token) THEN
7.     postings_list ← GETPOSTINGSLIST(dictionary, term(token))
8.     IF postings_list.size() == MAX_POSTINGS_LIST_SIZE THEN
9.        postings_list ← DOUBLEPOSTINGSLIST(postings_list)
10.    ADDToPOSTINGSLIST(postings_list, docID(token))
11. ELSE
12.    postings_list ← NEWPOSTINGSLIST()
13.    ADDToPOSTINGSLIST(postings_list, docID(token))
14.    dictionary.add(token, postings_list)
15. ENDIF
```

* **Spiegazione:**
    * Linea 5: pre-processing del token raw in index-term.
    * Linea 10 e 13: aggiunta immediata del posting.
    * Linee 8-9: raddoppio della lista di postings se piena.
    * Linea 11: ordinamento dei termini dopo aver raccolto tutti i postings per un blocco.


---

# Postings non ordinati

I postings vengono accumulati nelle liste in modo non ordinato, man mano che si verificano.  Questo significa che l'ordine di inserimento dei postings nella lista non riflette necessariamente un ordine specifico (cronologico, alfabetico, etc.), ma semplicemente l'ordine in cui sono stati incontrati durante il processo.

---

Per favore, forniscimi il testo da formattare.  Non ho ricevuto alcun testo da elaborare nell'input precedente.  Inserisci il testo che desideri formattare e io lo elaborerò secondo le tue istruzioni.

---
