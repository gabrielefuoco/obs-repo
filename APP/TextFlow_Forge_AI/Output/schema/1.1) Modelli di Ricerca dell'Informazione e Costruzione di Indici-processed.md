
**Modello Booleano di Ricerca**

I. **Descrizione:**
    * Utilizza query booleane (termini di indice + operatori booleani: `AND`, `OR`, `NOT`) per interrogare un indice.
    * Corrispondenza binaria: documento soddisfa o non soddisfa la query.
    * Utilizzato in sistemi come WestLaw, sistemi di posta elettronica, cataloghi di biblioteche e macOS Spotlight.

II. **Esempio: WestLaw**
    * Servizio di ricerca legale commerciale.
    * Utilizza query booleane con operatori di prossimità (es. `/3`, `/S`).
    * Esempio di query: `LIMIT! /3 STATUTE ACTION /S FEDERAL /2 TORT /3 CLAIM`
    * Dimostra sia vantaggi (precisione, raffinamento incrementale) che svantaggi (rigidità).

III. **Vantaggi:**
    * Query precise e lunghe.
    * Operatori di prossimità.
    * Sviluppo incrementale delle query.
    * Maggiore precisione rispetto alle ricerche web.

IV. **Limitazioni:**
    * **Rigidità:**
        * `AND`: richiede tutti i termini.
        * `OR`: richiede almeno un termine.
        * Incoraggia query brevi e semplici.
        * Scarsa flessibilità; non supporta l'espansione della query.
        * Ogni termine è considerato in modo isolato.
    * **Difficoltà nel controllo dei risultati:**
        * Nessun controllo sul numero di documenti recuperati.
        * Nessuna classificazione dei risultati in base alla rilevanza.
        * Impossibile utilizzare il feedback di rilevanza per migliorare la query.
    * **Espressività limitata:**
        * Difficoltà nell'esprimere richieste complesse.
        * Impossibilità di regolare l'importanza dei termini.
        * Problema della sparsità nella rappresentazione dei dati.

V. **Esempio di difficoltà:**
    * Trovare opere di Shakespeare con "Brutus" e "Caesar" ma non "Calpurnia" è complesso e inefficiente.
    * Operazioni di prossimità (es. "Romans" vicino a "countrymen") sono problematiche.
    * Non supporta il recupero classificato.

VI. **Conclusioni:**
    * Adatto solo per query corte e semplici, quando l'obiettivo è solo determinare la presenza/assenza di un elemento.


---

## Estensioni del Modello Booleano per il Recupero dell'Informazione

**I. Estensione del Modello Booleano con Classificazione:**

* **Obiettivo:** Ordinare i risultati del recupero booleano.
* **Metodo:** Assegnazione di pesi (in [0,1]) ai termini; calcolo della similarità (es. Jaccard) tra query e documenti; ordinamento in base alla similarità.
* **Feedback di Rilevanza:** Raffinamento dell'ordinamento basato sulla classificazione dei documenti.
* **Risultato:** Lista di risultati ordinata per rilevanza.

**II. Insiemi Fuzzy nel Recupero dell'Informazione:**

* **Concetto:** Rilassamento dei confini degli insiemi booleani.
* **Standard Booleano:**  `d ∈ A` o `d ∉ A`.
* **Fuzzy:** `d` è "più o meno" in `A`.
* **Grado di Appartenenza:** `wA` indica il grado di appartenenza di `d` ad `A`.
* **Operazioni Fuzzy:**
    * Intersezione:  $w(A∩B) = min(wA, wB)$
    * Unione: $w(A∪B )= max(wA, wB)$

**III. Modelli di Similarità:**

* **A. MMM (Mixed Min and Max Model):**
    * **Query Disgiuntiva ($q_{or} = (t_1 \lor t_2 \lor \dots \lor t_n)$):** $S(q_{or}, d) = \lambda_{or} \cdot \max(w_1, \dots, w_n) + (1 - \lambda_{or}) \cdot \min(w_1, \dots, w_n)$  ($0 \le \lambda_{or} \le 1$)
    * **Query Congiuntiva ($q_{and} = (t_1 \land t_2 \land \dots \land t_n)$):** $S(q_{and}, d) = \lambda_{and} \cdot \min(w_1, \dots, w_n) + (1 - \lambda_{and}) \cdot \max(w_1, \dots, w_n)$ ($0 \le \lambda_{and} \le 1$)
* **B. Modello di Paice:**
    * **Differenza da MMM:** Considera tutti i pesi dei termini, non solo il massimo e il minimo.
    * **Vantaggio:** Migliore risposta alle query.
    * **Svantaggio:** Maggior costo computazionale.
* **C. Modello P-norma:**
    * **Caratteristiche:** Documenti e query come punti multidimensionali con pesi dei termini e operatori con coefficienti.
    * **Calcolo della Similarità:** Basato su due schemi di pesatura.

**IV. Sparsità della Matrice Termine-Documento:**

* **Rappresentazione:** Una matrice termine-documento densa è irrealistica.
* **Esempio:**  `N = 1M` documenti, `1000` parole/documento, `6 byte/parola` → `6 GB` di dati; `M = 500K` termini distinti.
* **Problema:** Matrice `500K x 1M` con circa mezzo trilione di zeri.  In realtà, non più di un miliardo di uni.
* **Soluzione:** Rappresentazione sparsa: registrare solo le posizioni degli uni.
* **Desiderata:** Struttura dati che rappresenti concetti e relazioni.

---

**Indice Inverso per la Ricerca di Documenti**

I. **Definizione e Costruzione dell'Indice Inverso:**

    A. **Definizione:** Mappatura di ogni termine all'insieme dei documenti in cui appare.  Vantaggi: efficienza di memorizzazione e velocità di ricerca.
    B. **Costruzione:**
        1. Identificazione dei documenti indicizzati per ogni termine (memorizzazione docID).
        2. Creazione della matrice termine-documento (traspone un array di documenti indicizzati).
    C. **Struttura:**
        1. Liste di postings (docID + frequenza): liste concatenate o array di lunghezza variabile.
        2. Memorizzazione: su disco (sequenza continua) o in memoria.
    D. **Considerazioni:** Compromessi tra efficienza di memorizzazione, velocità di accesso e facilità di aggiornamento.

II. **Struttura dell'Indice:**

    A. **Dizionario:** Parole del corpus con puntatori alle liste di postings.
    B. **Liste di postings:** Documenti in cui appare una parola (con frequenza).
    C. **Doppia indicizzazione:**
        1. Per chiave (dizionario).
        2. Per documento (liste di postings).

III. **Processo di Indicizzazione (Indexer):**

    A. **Input:** Stream di coppie (termine, docID).
    B. **Fasi:**
        1. Generazione della sequenza di coppie (termine, docID).
        2. Ordinamento per termine.
        3. Ordinamento per docID (per ogni termine).
        4. Unione di voci multiple (stesso termine, stesso documento).
        5. Aggiunta della frequenza del termine nel documento.
        6. Divisione in Dizionario (termini distinti con termID) e Postings (liste di postings con frequenze).

IV. **Elaborazione delle Query:**

    A. **Esempio:** Query "*Brutus AND Caesar*".
    B. **Passaggi:**
        1. Recupero dei postings di "Brutus" dal dizionario.
        2. Recupero dei postings di "Caesar" dal dizionario.
        3. Intersezione delle liste di postings (algoritmo `INTERSECT`, tempo lineare rispetto alla somma delle dimensioni delle liste).


---

**Schema Riassuntivo: Elaborazione di Query nei Motori di Ricerca**

I. **Unione di Postings (Intersezione di Insiemi)**
    *   Algoritmo di intersezione lineare per due postings ordinati.
    *   Tempo di elaborazione proporzionale alla somma delle dimensioni dei postings.
    *   Esempio di elaborazione di query booleane AND.
    *   Pseudocodice:
        ```
        INTERSECT(p1, p2) 
        answer ← ⟨ ⟩ 
        while p1 ≠ NIL and p2 ≠ NIL do 
            if docID(p1) = docID(p2) then 
                ADD(answer, docID(p1)) 
            p1 ← next(p1) 
            p2 ← next(p2) 
            else if docID(p1) < docID(p2) then 
                p1 ← next(p1) 
            else 
                p2 ← next(p2) 
        return answer 
        ```

II. **Ottimizzazione dell'Elaborazione di Query**
    *   **Query AND:** Ordinare i termini in base alla frequenza crescente (dal meno frequente al più frequente) per minimizzare la dimensione degli insiemi intermedi.
    *   **Esempio:** Query "Brutus AND Caesar AND Antony" (frequenze: Brutus 1000, Caesar 500, Antony 200) -> ordine ottimale: Antony, Caesar, Brutus.
    *   **Query Booleane arbitrarie (OR, NOT):** Stimare la dimensione degli insiemi OR (somma delle frequenze) e procedere in ordine crescente di queste stime.
    *   Tempo di elaborazione lineare rispetto al numero totale di voci nei postings.

III. **Query di Frase**
    *   Importanza: Ricerca avanzata, comprensibilità per l'utente.
    *   Approcci:
        *   **Indici Biword:** Indizza coppie consecutive di termini. Semplice per frasi a due parole.
        *   **Scomposizione di frasi più lunghe:**  Trasforma la frase in una query booleana sui biword. Rischio di falsi positivi e aumento della dimensione del dizionario. Non scalabile per frasi lunghe.
        *   Gli indici biword non sono la soluzione standard, ma parte di una strategia più complessa.

IV. **Etichettatura Morfologica (POST) e Biword Estensi**
    *   Analisi POST: suddivisione del testo in termini e assegnazione di categorie grammaticali.
    *   Classificazione dei termini come nomi (N) o articoli/preposizioni (X).


---

**I. Indicizzazione Biword Estesa**

* **A. Definizione:** Identifica sequenze di termini $NX*N$, gestendo frasi complesse.
    * **Esempio:** "il cacciatore nella segale" -> "cacciatore segale"
* **B. Elaborazione Query:**
    * 1. Analisi: suddivisione della query in termini N e X.
    * 2. Segmentazione: creazione di biword estesi dalla query.
    * 3. Ricerca: ricerca dei biword estesi nell'indice.

**II. Indici Posizionali**

* **A. Funzionalità:** Memorizzano le posizioni di ogni termine nei documenti.  `<termine, numero di documenti; doc1: posizione1, posizione2 … ; doc2: posizione1, posizione2 … ; …>`
    * Supporta query di frase e prossimità.
* **B. Confronto con Biword:**
    * 1. Indici posizionali: supportano query di frase e prossimità.
    * 2. Indici biword: non supportano query di prossimità.
* **C. Algoritmo di Unione Ricorsivo:**
    * Utilizza la fusione delle liste di `doc:posizione` per query di frase, gestendo complessità oltre la semplice uguaglianza.
    * Esempio: "to be or not to be".

**III. Dimensione dell'Indice Posizionale**

* **A. Espansione dell'archiviazione:**  Una voce per ogni occorrenza, non solo per documento.
* **B. Dipendenza dalla dimensione del documento:**  La dimensione dipende dalla dimensione media dei documenti (compressione possibile).
* **C. Regola empirica:**
    * 1. 2-4 volte più grande di un indice non posizionale.
    * 2. 35-50% del volume del testo originale.
* **D. Utilizzo standard:**  La potenza delle query di frase e prossimità ne giustifica l'utilizzo, anche implicito.

**IV. Costruzione dell'Indice: Scalabilità e Basi Hardware**

* **A. Limiti della costruzione in memoria:** Non scalabile per collezioni di grandi dimensioni (es. New York Times).
* **B. Necessità di utilizzo del disco:** Vincoli di performance dovuti all'accesso ai dati.
* **C. Basi hardware:** Server con ampia memoria (GB) e spazio su disco maggiore (2-3 ordini di grandezza). Preferenza per macchine standard a sistemi costosi con tolleranza ai guasti. Ottimizzazione I/O del disco tramite lettura/scrittura a blocchi (8KB-256KB).
* **D. Ordinamento esterno:** Necessario per collezioni di grandi dimensioni, in quanto l'ordinamento diretto su disco è troppo lento.

**V. Block Sort-Based Indexing**

* **A. Soluzione per la scalabilità:**  Algoritmo di ordinamento esterno per la costruzione dell'indice su disco per grandi quantità di dati.  (Dettagli non forniti nel testo).

---

**Indicizzazione di Grandi Collezioni di Documenti**

I. **Algoritmo BSBI (Block-Sort-Based Indexing)**

    A. **Problema:** L'indicizzazione di grandi dataset (es. 100 milioni di record) in memoria è inefficiente.
    B. **Soluzione:** Ordinamento esterno.
        1. Suddivisione dei dati in blocchi più piccoli (es. 10 milioni di record).
        2. Ordinamento interno di ogni blocco (es. Quicksort, $O(N \log N)$).
        3. Scrittura dei blocchi ordinati (run) su disco.
        4. Unione delle run tramite merge esterno.
    C. **Pseudocodice:**
        ```
        BSBIndexConstruction()
        1 n ← 0
        2 while (all documents have not been processed)
        3 do n ← n + 1
        4 block ← ParseNextBlock()
        5 BSBI-Invert(block) 
        6 WriteBlockToDisk(block, fn) 
        7 MergeBlocks(f_1, ..., f_n; f_merged)
        ```
    D. **Ordinamento di 10 blocchi:** Due fasi: ordinamento interno (Quicksort) e merge esterno.  Ottimizzazione dello spazio su disco per evitare due copie complete dei dati.

II. **Tecniche di Merge**

    A. **Merge Binario:**
        1. Albero di merge con $\log_2(n)$ livelli (n = numero di run).
        2. Merge parziali a ogni livello, leggendo, unendo e riscrivendo blocchi su disco.
        3. Struttura a livelli: Partizionamento, merge parziale, aggiornamento dell'indice.
    B. **Multi-way Merge:**
        1. **Assunzione:** Condivisione parziale del lessico tra documenti.
        2. Lettura simultanea da tutti i blocchi.
        3. Richiede: apertura simultanea di file, buffer di lettura/scrittura, coda di priorità per `termID` più basso, unione di liste di postings.
        4. Efficiente con blocchi di dimensioni adeguate.

III. **Problema della Crescita del Lessico durante il Merge**

    A. **Gestione di termini e ID:** Necessità di una corretta gestione.
    B. **Compressione con perdita:** Applicabile solo a termini non essenziali.
    C. **Valutazione dei token:** Strategie per valutare l'importanza dei token per la compressione.

IV. **Algoritmo SPIMI (Single-Pass In-Memory Indexing)**

    A. **Soluzione:** Approccio lazy per risolvere il problema della crescita del lessico durante l'indicizzazione di grandi collezioni.


---

## Schema Riassuntivo: Indicizzazione di Documenti

**I. Superamento delle Limitazioni degli Algoritmi Basati sull'Ordinamento**

* **Idea Chiave 1: Generazione di Dizionari Separati per Blocco**
    * Elimina la necessità di mantenere la mappatura termine-termID tra blocchi (mapping across block).
* **Idea Chiave 2: Eliminazione dell'Ordinamento**
    * Accumulo di postings nelle liste di postings durante l'elaborazione.
    * Generazione di indici invertiti completi per ogni blocco, successivamente mergeabili.
    * Maggiore velocità e risparmio di memoria rispetto agli algoritmi basati sull'ordinamento.
    * Liste di postings come strutture dinamiche riallocate all'occorrenza.
    * Esempio: Algoritmo SPIMI (vedi sotto).

**II. Algoritmo SPIMI (Single-Pass Inverted index with Memory-mapped files)**

* **Pseudocodice:**
    ```python
    1. output_file = NEWFILE()
    2. dictionary = NEWHASH()
    3. while (free memory available)
    4. do token ← next(token_stream)
    5. if term(token) ∉ dictionary
    6. then postings_list = ADDToDICTIONARY(dictionary, term(token))
    7. else postings_list = GETPOSTINGSLIST(dictionary, term(token))
    8. if full(postings_list)
    9. then postings_list = DOUBLEPOSTINGSLIST(dictionary, term(token))
    10. ADDToPOSTINGSLIST(postings_list, docID(token))
    11. sorted_terms ← SORTTERMS(dictionary)
    12. WRITEBLOCKToDISK(sorted_terms, dictionary, output_file)
    13. return output_file
    ```
* **Spiegazione:**
    * Linea 5: pre-processing del token raw in index-term.
    * Linea 10: aggiunta immediata del posting.
    * Linee 8-9: raddoppio della lista di postings se piena.
    * Linea 11: ordinamento dei termini dopo aver raccolto tutti i postings per un blocco.


**III. Indicizzazione Distribuita**

* **Architettura:**
    * Macchina master per la coordinazione.
    * Suddivisione dell'indice in task paralleli (blocchi).
    * Assegnazione di ruoli ai nodi.
* **Parsing Distribuito:**
    * Assegnazione di porzioni di documenti (split) a parser inattivi.
    * Estrazione di coppie (termine, documento ID).
    * Scrittura in *j* partizioni (fold) basate su suddivisione lessicografica dei termini.
* **Inversione Distribuita dell'Indice:**
    * Raccolta delle coppie (termine, documento ID) per partizione.
    * Ordinamento delle liste di postings per termine.
    * Scrittura su disco.
* **Modello MapReduce:**
    * **Fase di Map:** Produzione di liste di coppie (termine, documento).
    * **Fase di Reduce:** Produzione delle liste di postings (liste di documenti in cui un termine compare).

**IV. MapReduce e Sistemi di Indicizzazione**

* **MapReduce:** Framework robusto e semplice per il calcolo distribuito.
* **Sistema di indicizzazione di Google (circa 2002):**  Composto da fasi implementate in MapReduce.


---

**I. Schema MapReduce per la Costruzione dell'Indice**

* **Funzioni Map e Reduce:**
    * `map`: input → list(k, v)
    * `reduce`: (k,list(v)) → output
* **Istanza per l'Indicizzazione:**
    * `map`: collection → list(termID, docID)
    * `reduce`: (<termID1, list(docID)>, <termID2, list(docID)>, …) → (postings list1, postings list2, …)

**II. Gestione di Documenti Dinamici**

* **Strategie:**
    * **Indice Principale e Ausiliario:** Indice principale + uno o più indici ausiliari per nuovi documenti. Ricerca su entrambi, combinando i risultati.  *Problemi*: Inefficiente con un unico grande file per l'indice a causa di merge frequenti.
    * **Eliminazione:** Vettore di bit per indicare documenti eliminati, filtrando i risultati di ricerca.
    * **Re-indicizzazione:** Re-indicizzazione periodica di tutto l'indice. Aggiornamento liste di postings per termini esistenti, aggiunta di nuovi termini al dizionario.

**III. Tecniche di Fusione**

* **Fusione Logaritmica:**
    * **Principio:** Serie di indici di dimensioni crescenti (1, 2, 4, 8...). L'indice più piccolo in memoria, gli altri su disco. Fusione iterativa fino all'ordinamento completo.
    * **Memoria e Disco:** $Z_0$ (in memoria), $I_0, I_1, ...$ (su disco).
    * **Complessità:** Ogni posting fuso al massimo $O\left( log\left( \frac{T}{n} \right) \right)$ volte, complessità totale $O\left( T \cdot log\left( \frac{T}{n} \right) \right)$.
* **Confronto con Fusione T/n (Indice Ausiliario e Principale):**
    * **Fusione T/n:** Complessità nel caso peggiore $O\left( \frac{T^2}{n} \right)$.
    * **Vantaggi Fusione Logaritmica:** Più efficiente della fusione T/n per la costruzione dell'indice.
    * **Svantaggi Fusione Logaritmica:** Elaborazione query più complessa: $O\left( log\left( \frac{T}{n} \right) \right)$ contro $O(1)$ della fusione semplice.

**IV. Problemi con Più Indici**

* **Gestione delle statistiche:** Difficoltà nel mantenere statistiche a livello di collezione (es. correzione ortografica).
* **Problema:** Come mantenere le migliori alternative con più indici e vettori di bit di invalidazione?
* **Possibile soluzione:** Ignorare indici ausiliari per l'ordinamento, basando il ranking solo sull'indice principale.

**V. Indicizzazione Dinamica nei Motori di Ricerca**

* **Approccio:** Modifiche incrementali frequenti per gestire dati dinamici (notizie, blog, nuove pagine web).

---

**Ricerca in Tempo Reale e Costruzione dell'Indice**

I. **Ricostruzione Periodica dell'Indice:**
    *  Commutazione dell'elaborazione delle query su un nuovo indice.
    *  Eliminazione del vecchio indice.

II. **Requisiti per la Ricerca in Tempo Reale:**
    *  Bassa latenza: elevata produttività di valutazione delle query.
    *  Elevato tasso di ingestione: immediata disponibilità dei dati.
    *  Letture e scritture concorrenti: gestione simultanea di letture e scritture sull'indice.
    *  Dominanza del segnale temporale: priorità ai dati più recenti.

III. **Tecniche di Indicizzazione:**
    A. **Indicizzazione basata sull'ordinamento:**
        * Inversione in memoria naive.
        * Indicizzazione basata sull'ordinamento bloccato (BSBI).
        * Ordinamento per fusione (efficace per l'ordinamento basato su disco rigido).
    B. **Indicizzazione in memoria a passaggio singolo (SPIMI):**
        * Nessun dizionario globale.
        * Generazione di un dizionario separato per ogni blocco.
        * Postings non ordinati.
        * Accumulo dei postings nelle liste man mano che si verificano.

---
