
**Schema Riassuntivo del Modello Booleano**

**I. Modello Booleano: Fondamenti**

*   Definizione: Utilizza query booleane (termini di indice + operatori `AND`, `OR`, `NOT`) per interrogare un indice di termini associati a documenti testuali.
*   Corrispondenza: Binaria (documento soddisfa o non soddisfa la query).
*   Applicazioni: Sistemi di posta elettronica, cataloghi di biblioteche, macOS Spotlight, sistemi legali (es. WestLaw).

**II. Esempio: WestLaw**

*   Descrizione: Servizio commerciale di ricerca legale a pagamento.
*   Dati: Gestisce decine di terabyte di dati.
*   Utenti: Circa 700.000.
*   Query: Utilizza principalmente query booleane.
*   Esempio di Espressione: `LIMIT! /3 STATUTE ACTION /S FEDERAL /2 TORT /3 CLAIM`
    *   Operatori di Prossimità: `/3` (entro 3 parole), `/S` (nella stessa frase).
    *   Raffinamento Incrementale: Permette di specificare con precisione i criteri di ricerca.
    *   Rigidità: Limita la flessibilità.

**III. Vantaggi del Modello Booleano**

*   Query Precise e Lunghe: Consentono di specificare con precisione i criteri di ricerca.
*   Operatori di Prossimità: Permettono di definire la relazione spaziale tra i termini.
*   Sviluppo Incrementale: Le query possono essere raffinate gradualmente.
*   Differenze dalla Ricerca sul Web: Le query booleane sono più precise e controllate.

**IV. Limitazioni del Modello Booleano**

*   Rigidità: `AND` richiede tutti i termini, `OR` richiede almeno uno.
*   Query Brevi: Incoraggia l'utilizzo di query brevi e semplici.
*   Scarsa Flessibilità: Richiede una scelta precisa dei termini di indice.
    *   Nessuna Espansione della Query: Non prevede l'espansione della query con termini semanticamente equivalenti.
    *   Isolamento dei Termini: Ogni termine di indice è considerato in modo isolato.
*   Difficoltà nel Controllo dei Risultati:
    *   Numero di Documenti Recuperati: Restituisce tutti i documenti corrispondenti, senza controllo sulla quantità.
    *   Classificazione dei Risultati: Nessun ordinamento in base alla rilevanza.
    *   Feedback di Rilevanza: Difficile da utilizzare per migliorare la query.
*   Espressività Limitata:
    *   Complessi Requisiti dell'Utente: Difficoltà nell'esprimere richieste complesse.
    *   Importanza dei Termini: Non permette di regolare l'importanza dei termini nella query.
    *   Sparsità: Soffre del problema della sparsità.

**V. Conclusioni**

*   Adatto per: Esigenze esprimibili tramite query corte e semplici.
*   Obiettivo: Determinare la presenza o l'assenza di un elemento.

---

## Schema Riassuntivo: Estensioni del Modello Booleano e Sparsità

**1. Estensione del Modello Booleano**

   *   **1.1 Incorporare Metodi di Classificazione**
        *   Obiettivo: Aggiungere ordinamento dei risultati mantenendo il modello booleano.
        *   Metodo:
            *   Assegnare pesi (in [0,1]) a termini in documenti e query.
            *   Calcolare la somiglianza (es. Jaccard) tra query e documenti.
            *   Ordinare i risultati in base alla somiglianza.
        *   Feedback di rilevanza: Selezionare documenti in base alla classificazione per raffinare l'ordinamento.
        *   Risultato: Ordine all'interno della lista dei risultati.

   *   **1.2 Insiemi Fuzzy**
        *   Concetto: Rilassare i confini degli insiemi booleani.
        *   Standard: d ∈ A oppure d ∉ A.
        *   Fuzzy: d è più o meno in A.
        *   Grado di appartenenza: wA = grado di appartenenza di un elemento all'insieme A.
        *   Operazioni:
            *   Intersezione (and): $w(A∩B) = min(wA, wB)$
            *   Unione (or): $w(A∪B )= max(wA, wB)$

   *   **1.3 MMM: Mixed Min and Max Model**
        *   Calcola la similarità S tra query e documento usando una combinazione lineare del massimo e del minimo dei pesi.
        *   Sia d il documento con pesi dei termini $w_1, w_2, \dots, w_n$ corrispondenti ai termini $t_1, t_2, \dots, t_n$.
        *   Query disgiuntiva:
            *   $q_{or} = (t_1 \lor t_2 \lor \dots \lor t_n)$
            *   $S(q_{or}, d) = \lambda_{or} \cdot \max(w_1, \dots, w_n) + (1 - \lambda_{or}) \cdot \min(w_1, \dots, w_n)$
            *   $\lambda_{or}$ ($0 \le \lambda_{or} \le 1$) controlla il peso relativo del massimo e del minimo.
            *   In logica booleana standard, $\lambda_{or} = 1$.
        *   Query congiuntiva:
            *   $q_{and} = (t_1 \land t_2 \land \dots \land t_n)$
            *   $S(q_{and}, d) = \lambda_{and} \cdot \min(w_1, \dots, w_n) + (1 - \lambda_{and}) \cdot \max(w_1, \dots, w_n)$
            *   $\lambda_{and}$ ($0 \le \lambda_{and} \le 1$) bilancia il peso del minimo e del massimo, assumendo il valore 1 nella logica booleana standard.

   *   **1.4 Modello di Paice**
        *   Differenza da MMM: Considera tutti i pesi dei documenti.
        *   Vantaggio: Migliora la risposta alla query.
        *   Svantaggio: Costo computazionale più alto.

   *   **1.5 Modello P-norma**
        *   Caratteristiche:
            *   Documenti con pesi dei termini.
            *   Termini di query con pesi associati.
            *   Operatori con coefficienti che indicano il grado di rigore.
        *   Calcolo della somiglianza: Considera documenti e query come punti multidimensionali.

**2. Sparsità**

   *   **2.1 Problema della Sparsità**
        *   La sparsità della rappresentazione matrice termine-documento è un problema significativo.
        *   Un modello di rappresentazione poco sparso è irrealistico.

   *   **2.2 Esempio**
        *   N = 1 milione di documenti, ognuno con circa 1000 parole (6 byte/parola = 6 GB di dati).
        *   M = 500K termini distinti.

   *   **2.3 Problemi della Matrice di Incidenza**
        *   Una matrice di incidenza termine-documento di dimensioni 500K x 1M avrebbe mezzo Trillion di 0 e 1.
        *   Nella realtà: La matrice ha non più di un miliardo di 1.
        *   Le matrici di incidenza termine-documento sono estremamente sparse.

   *   **2.4 Rappresentazione Migliore**
        *   Registrare solo le posizioni 1.
        *   Desiderata per una struttura dati: Capacità di rappresentare concetti e relazioni.

---

**Schema Riassuntivo: Indice Inverso**

**1. Indice Inverso: Concetto Chiave**
    *   Definizione: Mappa ogni termine all'insieme dei documenti in cui compare.
    *   Vantaggi:
        *   Efficienza di memorizzazione.
        *   Velocità di ricerca.
        *   Gestione della sparsità dei dati.

**2. Costruzione dell'Indice Inverso**
    *   Identificazione dei Documenti Indicizzati:
        *   Per ogni termine, identifica i documenti in cui appare.
        *   Memorizza gli ID dei documenti (docID).
    *   Creazione della Matrice Termine-Documento:
        *   Rappresentazione iniziale come array di documenti indicizzati.
        *   Trasposizione per ottenere la matrice termine-documento.

**3. Struttura dell'Indice Inverso**
    *   Lista di Postings:
        *   Definizione: Elenco di docID per ogni termine.
        *   Implementazione: Liste concatenate o array di lunghezza variabile.
        *   Memorizzazione: Su disco (sequenza continua) o in memoria.
    *   Core dell'Indice:
        *   Dizionario:
            *   Contiene le parole del corpus.
            *   Ogni parola è associata a un puntatore alla lista di posting corrispondente.
        *   Liste di Posting:
            *   Contengono i documenti in cui la parola compare.
            *   Includono la frequenza del termine nel documento.
    *   Indicizzazione Doppia:
        *   Per chiave (Dizionario): Accesso rapido alla lista di posting per una parola.
        *   Per documento (Liste di Posting): Identificazione rapida dei documenti in cui una parola compare e la sua frequenza.

**4. Considerazioni sull'Indice Inverso**
    *   Scelta della struttura dati: Dipende dalle esigenze specifiche dell'applicazione.
    *   Compromessi: Efficienza di memorizzazione, velocità di accesso, facilità di aggiornamento.

**5. Indexer: Raccolta dei Postings**
    *   Input: Stream di coppie (Termine, docID).
    *   Funzione: Raccoglie i postings per ogni token (insieme di documenti in cui il token appare).

**6. Passaggi dell'Indexer (Processo di Indicizzazione)**
    *   Generazione: Sequenza di coppie (Termine, docID).
    *   Ordinamento:
        *   Per Termine.
        *   Per docID (all'interno di ogni termine).
    *   Unione: Voci multiple per lo stesso termine nello stesso documento.
    *   Aggiunta: Frequenza del termine nel documento.
    *   Divisione:
        *   Dizionario: Termini distinti con termID.
        *   Postings: Liste di postings per ogni termine con frequenza.

**7. Elaborazione delle Query**
    *   Esempio: "*Brutus AND Caesar*"
    *   Metodo: Intersezione delle liste di postings.
    *   Algoritmo: `INTERSECT` (tempo lineare rispetto alla somma delle dimensioni delle liste).
    *   Passaggi:
        *   Individua "Brutus" nel Dizionario e recupera i suoi postings.
        *   Individua "Caesar" nel Dizionario e recupera i suoi postings.

---

## Schema Riassuntivo del Testo

**1. Unione dei Postings (Intersezione di Insiemi di Documenti)**

*   **1.1. Algoritmo di Intersezione:**
    *   Attraversamento simultaneo dei postings in tempo lineare.
    *   Efficienza garantita dall'ordinamento delle liste.
    *   Tempo proporzionale a: (numero documenti con Brutus) + (numero documenti con Caesar).
    *   **Algoritmo:**
        ```
        INTERSECT(p1, p2)
        answer ← ⟨ ⟩
        while p1 ≠ NIL and p2 ≠ NIL do
            if docID(p1) = docID(p2) then
                ADD(answer, docID(p1))
                p1 ← next(p1)
                p2 ← next(p2)
            else if docID(p1) < docID(p2) then
                p1 ← next(p1)
            else
                p2 ← next(p2)
        return answer
        ```
*   **1.2. Applicazione:** Esempio di elaborazione di query booleane (AND, OR, NOT).

**2. Ottimizzazione dell'Elaborazione delle Query**

*   **2.1. Scenario:** Query congiuntiva AND di *n* termini.
*   **2.2. Obiettivo:** Determinare l'ordine ottimale di elaborazione.
*   **2.3. Strategia Ottimale:**
    *   Elaborare i termini in ordine crescente di frequenza documentale.
    *   Iniziare dal termine meno frequente per minimizzare gli insiemi intermedi.
*   **2.4. Esempio:**
    *   Query: "Brutus AND Caesar AND Antony"
    *   Frequenze: Brutus (1000), Caesar (500), Antony (200)
    *   Ordine Ottimale: Antony, Caesar, Brutus
*   **2.5. Query Booleane Arbitrarie:**
    *   Esempio: (Brutus OR Caesar) AND NOT (Antony OR Cleopatra)
    *   Strategia: Stimare la dimensione degli insiemi OR (somma delle frequenze) e procedere in ordine crescente.
    *   Tempo lineare rispetto al numero totale di voci nei postings.
*   **2.6. Nota:** L'ordine di elaborazione influenza significativamente l'efficienza, specialmente per query complesse.

**3. Query di Frase**

*   **3.1. Importanza:**
    *   Elemento chiave per la "ricerca avanzata".
    *   Facilmente comprensibili dagli utenti.
    *   Obiettivo: Rispondere a query come "Dipartimenti Unical" come frase completa.
*   **3.2. Approcci:**
    *   **3.2.1. Indici Biword:**
        *   Indicizzazione di ogni coppia consecutiva di termini.
        *   Esempio: "Amici, Romani, Concittadini" -> "amici romani", "romani concittadini".
        *   Ogni biword diventa un termine del dizionario.
        *   Elaborazione immediata per query di frase a due parole.
        *   Scomposizione di frasi più lunghe in query booleane sui biword (es. "Corsi del dipartimento DIMES" -> "dipartimento DIMES AND corsi dipartimento").
        *   Rischio di falsi positivi.
        *   Espansione dell'indice.
        *   Inattuabile per più di due parole.
        *   Non sono la soluzione standard, ma parte di strategie composite.
    *   **3.2.2. Etichettatura Morfologica (POST) e Biword Estesi:**
        *   Analisi del testo con POST (Part-of-Speech tagging).
        *   Classificazione dei termini come Nomi (N) e Articoli/Preposizioni (X).

---

Ecco lo schema riassuntivo del testo fornito:

**1. Biword Estesi**

*   Definizione: Sequenze di termini nella forma $NX*N$ per gestire frasi complesse.
*   Esempio:
    *   POST: $N X X N$
    *   Biword Esteso: "cacciatore segale"
*   Elaborazione Query:
    *   Analisi: Suddivisione query in termini N e X.
    *   Segmentazione: Segmentazione in biword estesi.
    *   Ricerca: Ricerca dei biword estesi nell'indice.

**2. Indici Posizionali**

*   Definizione: Memorizzano le posizioni di ogni occorrenza dei termini nei documenti.
    *   Formato: `<termine, numero di documenti contenenti il termine; doc1: posizione1, posizione2 … ; doc2: posizione1, posizione2 … ; …>`
*   Supporto: Query di frase e di prossimità (non gestibili da indici biword).
*   Algoritmo di Unione Ricorsivo:
    *   Utilizzo: Processa query di frase.
    *   Funzionamento:
        *   Estrae voci indice invertito per ogni termine (es. "to", "be", "or", "not").
        *   Fonde liste doc:posizione per trovare posizioni con la frase completa (es. "to be or not to be").
    *   Necessità: Gestione di complessità oltre la semplice uguaglianza.
*   Applicazioni:
    *   Query di prossimità (non supportate da indici biword).

**3. Dimensione Indice Posizionale**

*   Espansione: Aumenta sostanzialmente l'archiviazione dei postings.
    *   Motivo: Una voce per ogni occorrenza, non solo per documento.
    *   Dipendenza: Dimensione media del documento.
*   Regola Empirica:
    *   Dimensione: 2-4 volte più grande di un indice non posizionale.
    *   Percentuale: 35-50% del volume del testo originale.
*   Standard: Utilizzo standard grazie alla potenza e utilità per query di frase e prossimità.

**4. Costruzione Indice Basata sull'Ordinamento**

*   Scalabilità:
    *   Limitazione: Costruzione in memoria non scalabile per grandi collezioni.
    *   Necessità: Utilizzo del disco.
*   Basi Hardware:
    *   Server: Ampia memoria (GB) e spazio su disco (ordini di grandezza superiori).
    *   Tolleranza ai guasti: Preferenza per molte macchine standard.
    *   Accesso: Memoria più veloce del disco; I/O disco ottimizzato per blocchi (8KB-256KB).
*   Ordinamento su Disco:
    *   Inefficienza: Ordinare grandi quantità di record su disco è troppo lento.
    *   Necessità: Algoritmo di ordinamento esterno.

**5. Block Sort-Based Indexing: Indicizzazione basata sull'ordinamento a blocchi**

*   Ordinamento diretto su disco di grandi quantità di dati.

---

**Schema Riassuntivo: Costruzione di Indici Invertiti su Larga Scala**

**1. BSBI (Block Sort-Based Indexing): Approccio Basato sull'Ordinamento Esterno**

   *   **Problema:** Indicizzazione inefficiente di grandi collezioni (es. 100 milioni di record).
   *   **Soluzione:** Suddivisione in blocchi, ordinamento interno, merge esterno.
   *   **Algoritmo `BSBIndexConstruction()`:**
        ```
        BSBIndexConstruction()
        1 n ← 0
        2 while (all documents have not been processed)
        3 do n ← n + 1
        4 block ← ParseNextBlock()
        5 BSBI-Invert(block) //costruisce inverted index
        6 WriteBlockToDisk(block, fn) //scriviamo sul disco, presuppone la presenza di una struttura di blocco sul disco
        7 MergeBlocks(f_1, ..., f_n; f_merged)
        ```
   *   **Fasi:**
        *   Accumulo postings per blocco, ordinamento, scrittura su disco.
        *   Unione dei blocchi in un unico indice ordinato.

**2. Ordinamento dei Blocchi**

   *   **Processo:** Ordinamento di *n* blocchi da *x* milioni di record ciascuno.
   *   **Fasi:**
        *   **Ordinamento Interno:** Ordinamento di ogni blocco in memoria (es. Quicksort, complessità $O(N \log N)$).
        *   **Merge Esterno:** Fusione delle run ordinate tramite algoritmo di ordinamento esterno (es. merge sort esterno).
   *   **Ottimizzazione:** Evitare due copie complete dei dati su disco.

**3. Tecniche di Merge**

   *   **Merge Binario:**
        *   Albero di merge con $\log_2(n)$ livelli (n = numero di run).
        *   Merge parziali ad ogni livello.
        *   **Processo:**
            *   Partizionamento dei dati.
            *   Merge parziale di ogni partizione in memoria.
            *   Aggiornamento dell'indice.
   *   **Multi-way Merge:**
        *   **Assunzione:** Condivisione parziale del lessico tra i documenti.
        *   Lettura simultanea da tutti i blocchi.
        *   **Requisiti:**
            *   Apertura simultanea dei file di blocco.
            *   Buffer di lettura per ogni blocco, buffer di scrittura per l'output.
            *   Coda di priorità per selezionare il `termID` più basso.
        *   Unione delle liste di postings e scrittura del risultato.

**4. Problema della Crescita del Lessico (Durante il Merge)**

   *   **Sfide:**
        *   Gestione dei termini e degli ID.
        *   Compressione con perdita (solo su termini non essenziali).
        *   Valutazione dell'importanza dei token.

**5. SPIMI (Single-Pass In-Memory Indexing): Indicizzazione in Memoria a Passaggio Singolo (Approccio Lazy)**

   *   **Soluzione:** Risolve il problema della crescita del lessico durante l'indicizzazione.

---

**Schema Riassuntivo: Indicizzazione su Larga Scala**

**I. SPIMI (Single-Pass In-Memory Indexing)**

*   **A. Superamento delle Limitazioni degli Algoritmi Basati sull'Ordinamento:**
    *   Non richiede il mantenimento in memoria della mappatura (termine, termID) e del dizionario in crescita.
*   **B. Idee Chiave:**
    *   **1. Generazione di Dizionari Separati per Ogni Blocco:**
        *   Non è necessario mantenere la mappatura termine-termID tra i blocchi.
    *   **2. Nessun Ordinamento Intermedio:**
        *   Accumulo diretto dei postings nelle liste di postings man mano che si verificano.
        *   Generazione di indici invertiti completi per ogni blocco, successivamente mergeabili.
*   **C. Vantaggi di SPIMI:**
    *   Più veloce e con minor consumo di memoria rispetto agli approcci basati sull'ordinamento.
    *   Evita l'ordinamento e la memorizzazione dei `termID` intermedi.
*   **D. Algoritmo SPIMI-Invert (token_stream):**
    ```python
    1. output_file = NEWFILE()
    2. dictionary = NEWHASH()
    3. while (free memory available)
    4. do token ← next(token_stream)
    5. if term(token) ∉ dictionary
    6. then postings_list = ADDToDICTIONARY(dictionary, term(token))
    7. else postings_list = GETPOSTINGSLIST(dictionary, term(token))
    8. if full(postings_list)
    9. then postings_list = DOUBLEPOSTINGSLIST(dictionary, term(token))
    10. ADDToPOSTINGSLIST(postings_list, docID(token))
    11. sorted_terms ← SORTTERMS(dictionary)
    12. WRITEBLOCKToDISK(sorted_terms, dictionary, output_file)
    13. return output_file
    ```
    *   **Note sull'Algoritmo:**
        *   Linea 5: Pre-elaborazione del token raw per ottenere l'index-term.
        *   Linea 10: Aggiunta immediata del posting (occorrenza del termine) nel documento.
        *   Linee 8-9: Raddoppio della lista di postings se raggiunge la dimensione limite.
        *   Linea 11: Ordinamento dei termini dopo aver raccolto tutti i postings per un blocco.

**II. Indicizzazione Distribuita**

*   **A. Concetto Generale:**
    *   Esecuzione parallela di parsing e inversione dell'indice.
    *   Macchina master coordina il processo e suddivide l'indice in task paralleli.
    *   Ogni split rappresenta un insieme di documenti gestito come blocco.
*   **B. Parsing Distribuito:**
    *   Il master assegna porzioni di documenti (split) a macchine parser inattive.
    *   Ogni parser estrae le coppie (termine, documento ID) e le scrive in *j* partizioni (fold) basate su una suddivisione lessicografica dei termini (es. a-f, g-p, q-z per j=3).
*   **C. Inversione Distribuita dell'Indice:**
    *   Ogni inverter raccoglie le coppie (termine, documento ID) per una specifica partizione.
    *   Ordina le liste di occorrenze (postings) per termine.
    *   Scrive le liste di postings su disco.
*   **D. Indicizzazione Distribuita e MapReduce:**
    *   L'indicizzazione distribuita è un'istanza del modello MapReduce.
    *   **Fase di Map:** Produce liste di coppie (termine, documento) a partire dalla collezione di documenti in input.
    *   **Fase di Reduce:** Prende le liste di occorrenze (coppie termine-documento) e produce le liste di postings.

**III. MapReduce e Indicizzazione**

*   **A. MapReduce:**
    *   Framework robusto e concettualmente semplice per il calcolo distribuito.
    *   Permette di eseguire calcoli complessi senza dover scrivere codice per la parte di distribuzione.
*   **B. Sistema di Indicizzazione di Google (circa 2002):**
    *   Composto da una serie di fasi, ciascuna implementata in MapReduce.

---

**I. Costruzione dell'Indice con MapReduce**

   *   **A. Funzioni Map e Reduce**
        *   `map`: input → list(k, v)
        *   `reduce`: (k,list(v)) → output
   *   **B. Schema per la Costruzione dell'Indice**
        *   `map`: collection → list(termID, docID)
        *   `reduce`: (<termID1, list(docID)>, <termID2, list(docID)>, …) → (postings list1, postings list2, …)

**II. Gestione di Documenti Dinamici**

   *   **A. Strategie**
        *   **1. Indice Principale e Ausiliario:**
            *   Mantenere un indice principale e uno o più indici ausiliari.
            *   Ricerca combinata su entrambi gli indici.
        *   **2. Eliminazione:**
            *   Utilizzare un vettore di bit per indicare i documenti eliminati.
            *   Filtrare i risultati di ricerca.
        *   **3. Re-indicizzazione:**
            *   Re-indicizzare periodicamente tutto in un unico indice principale.
            *   Aggiornamento di termini esistenti e aggiunta di nuovi termini.
   *   **B. Problemi con Indici Principali e Ausiliari**
        *   Inefficienza nella fusione con un unico grande file per l'indice.
        *   Problemi di performance durante i merge frequenti.

**III. Fusione Logaritmica**

   *   **A. Principio di Funzionamento**
        *   **1. Serie di Indici:** Indici di dimensioni crescenti (es. 1, 2, 4, 8, 16...).
        *   **2. Memoria e Disco:**
            *   Indice più piccolo $(Z_0)$ in memoria.
            *   Indici più grandi $(I_0, I_1, ...)$ su disco.
        *   **3. Fusione e Scrittura:**
            *   Se $Z_0$ supera la capacità, viene scritto su disco come $I_0$.
            *   Altrimenti, $Z_0$ viene unito con $I_0$ per formare $Z_1$.
        *   **4. Iterazione:** Il processo si ripete fino a ordinare tutti i dati.

**IV. Indicizzazione Dinamica (Confronto)**

   *   **A. Indice Ausiliario e Principale (Fusione T/n)**
        *   Indici ausiliari di dimensione $n$ e indice principale con $T$ postings.
        *   Tempo di costruzione dell'indice: $O\left( \frac{T^2}{n} \right)$ (caso peggiore).
   *   **B. Fusione Logaritmica**
        *   **1. Efficienza:** Ogni posting fuso al massimo $O\left( log\left( \frac{T}{n} \right) \right)$ volte.
        *   **2. Complessità:** $O\left( T \cdot log\left( \frac{T}{n} \right) \right)$
        *   **3. Vantaggi:** Più efficiente della fusione $\frac{T}{n}$.
        *   **4. Svantaggi:** Query richiede fusione di $O\left( log\left( \frac{T}{n} \right) \right)$ indici (vs. $O(1)$ con indice principale e ausiliario).

**V. Ulteriori Problemi con Più Indici**

   *   **A. Difficoltà nel Mantenere Statistiche a Livello di Collezione**
        *   Esempio: Correzione ortografica (scelta dell'alternativa con più risultati).
   *   **B. Problema:** Come mantenere le migliori alternative con più indici e vettori di bit di invalidazione?
   *   **C. Possibile Soluzione:** Ignorare tutto tranne l'indice principale per l'ordinamento.

**VI. Indicizzazione Dinamica nei Motori di Ricerca**

   *   **A. Applicazioni:** Modifiche incrementali frequenti (es. notizie, blog, nuove pagine web).

---

Ecco uno schema riassuntivo del testo fornito, organizzato gerarchicamente:

**I. Ricerca in Tempo Reale**

    A. Requisiti:
        1. Bassa latenza: Elevata produttività di valutazione delle query.
        2. Elevato tasso di ingestione: Immediata disponibilità dei dati.
        3. Letture e scritture concorrenti: Gestione di letture e scritture simultanee dell'indice.
        4. Dominanza del segnale temporale: Priorità ai dati più recenti.

**II. Ricostruzioni Periodiche dell'Indice**

    A. Processo:
        1. Commutazione dell'elaborazione delle query sul nuovo indice.
        2. Eliminazione del vecchio indice.

**III. Costruzione dell'Indice: Riepilogo**

    A. Indicizzazione basata sull'ordinamento:
        1. Tecniche:
            a. Inversione in memoria naive.
            b. Indicizzazione basata sull'ordinamento bloccato (BSBI).
            c. Ordinamento per fusione (efficace per l'ordinamento basato su disco rigido).

    B. Indicizzazione in memoria a passaggio singolo (SPIMI):
        1. Caratteristiche:
            a. Nessun dizionario globale.
            b. Genera un dizionario separato per ogni blocco.
            c. Non ordinare i postings.
            d. Accumulare i postings nelle liste di postings man mano che si verificano.

---
