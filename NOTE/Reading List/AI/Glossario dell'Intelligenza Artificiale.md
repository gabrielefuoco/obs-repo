L'intelligenza artificiale è la nuova frontiera della tecnologia — sembra che ogni azienda stia parlando di come sta facendo progressi utilizzando o sviluppando l'IA. Ma il campo dell'IA è anche così pieno di gergo che può essere notevolmente difficile capire cosa stia effettivamente accadendo con ogni nuovo sviluppo.

Per aiutarti a comprendere meglio ciò che sta accadendo, abbiamo messo insieme un elenco di alcuni dei termini più comuni dell'IA. Faremo del nostro meglio per spiegare cosa significano e perché sono importanti.

## Cos'è esattamente l'IA?

**Intelligenza artificiale:** Spesso abbreviata in IA, il termine "intelligenza artificiale" è tecnicamente la disciplina dell'informatica dedicata alla creazione di sistemi informatici che possono pensare come un essere umano.

Ma in questo momento, sentiamo parlare principalmente di IA come tecnologia o addirittura come entità, e cosa significhi esattamente è più difficile da definire. Viene anche frequentemente utilizzata come parola d'ordine di marketing, il che rende la sua definizione più mutevole di quanto dovrebbe essere.

Google, ad esempio, parla molto di come stia investendo nell'IA da anni. Ciò si riferisce a come molti dei suoi prodotti siano migliorati dall'intelligenza artificiale e a come l'azienda offra strumenti come Gemini che sembrano essere intelligenti. Ci sono i modelli di IA sottostanti che alimentano molti strumenti di IA, come il GPT di OpenAI. Poi c'è Mark Zuckerberg, CEO di Meta, che ha usato l'IA come sostantivo per riferirsi a singoli chatbot.

> Man mano che più aziende cercano di vendere l'IA come la prossima grande novità, i modi in cui usano il termine e altre nomenclature correlate potrebbero diventare ancora più confusi.

Per aiutarti a comprenderli meglio, ho messo insieme una panoramica di molti dei termini chiave nell'intelligenza artificiale che attualmente vengono sbandierati. In definitiva, tuttavia, tutto si riduce al tentativo di rendere i computer più intelligenti.

(Nota che sto dando solo una panoramica rudimentale di molti di questi termini. Molti di essi possono spesso diventare molto scientifici, ma questo articolo dovrebbe sperabilmente darti una comprensione delle basi.)

**Apprendimento automatico:** I sistemi di apprendimento automatico vengono addestrati (spiegheremo più avanti cosa significa addestramento) sui dati in modo da poter fare previsioni su nuove informazioni. In questo modo, possono "imparare". L'apprendimento automatico è un campo all'interno dell'intelligenza artificiale ed è fondamentale per molte tecnologie di IA.

**Intelligenza artificiale generale (AGI):** Intelligenza artificiale che è intelligente quanto o più di un essere umano. (OpenAI in particolare sta investendo pesantemente nell'AGI.) Questa potrebbe essere una tecnologia incredibilmente potente, ma per molte persone è anche potenzialmente la prospettiva più spaventosa sulle possibilità dell'IA — pensa a tutti i film che abbiamo visto su macchine superintelligenti che prendono il controllo del mondo! Se non bastasse, si sta anche lavorando sulla "superintelligenza", o IA che è molto più intelligente di un essere umano.

**IA generativa:** Una tecnologia di IA capace di generare nuovo testo, immagini, codice e altro. Pensa a tutte le interessanti (se occasionalmente problematiche) risposte e immagini che hai visto prodotte da ChatGPT o Gemini di Google. Gli strumenti di IA generativa sono alimentati da modelli di IA che sono tipicamente addestrati su vaste quantità di dati.

**Allucinazioni:** No, non stiamo parlando di visioni strane. È questo: poiché gli strumenti di IA generativa sono buoni solo quanto i dati su cui sono stati addestrati, possono "allucinare", o inventare con sicurezza quelle che pensano siano le migliori risposte alle domande. Queste allucinazioni (o, se vuoi essere completamente onesto, stronzate) significano che i sistemi possono commettere errori fattuali o dare risposte senza senso. C'è anche qualche controversia sul fatto che le allucinazioni dell'IA possano mai essere "corrette".

**Pregiudizio:** Le allucinazioni non sono gli unici problemi che sono emersi quando si ha a che fare con l'IA — e questo potrebbe essere stato previsto poiché le IA sono, dopo tutto, programmate da esseri umani. Di conseguenza, a seconda dei loro dati di addestramento, gli strumenti di IA possono dimostrare pregiudizi. Ad esempio, una ricerca del 2018 di Joy Buolamwini, una scienziata informatica del MIT Media Lab, e Timnit Gebru, la fondatrice e direttrice esecutiva del Distributed Artificial Intelligence Research Institute (DAIR), ha co-autore un articolo che illustrava come il software di riconoscimento facciale avesse tassi di errore più elevati quando tentava di identificare il genere di donne dalla pelle più scura.

## Continuo a sentire molti discorsi sui modelli. Cosa sono?

**Modello di IA:** I modelli di IA sono addestrati sui dati in modo da poter eseguire compiti o prendere decisioni autonomamente.

**Modelli di linguaggio di grandi dimensioni, o LLM:** Un tipo di modello di IA che può elaborare e generare testo in linguaggio naturale. Claude di Anthropic, che, secondo l'azienda, è "un assistente utile, onesto e innocuo con un tono conversazionale", è un esempio di LLM.

**Modelli di diffusione:** Modelli di IA che possono essere utilizzati per cose come generare immagini da prompt di testo. Vengono addestrati aggiungendo prima rumore — come statica — a un'immagine e poi invertendo il processo in modo che l'IA abbia imparato come creare un'immagine chiara. Ci sono anche modelli di diffusione che funzionano con audio e video.

**Modelli di base:** Questi modelli di IA generativa sono addestrati su una enorme quantità di dati e, di conseguenza, possono essere la base per una vasta gamma di applicazioni senza addestramento specifico per quei compiti. (Il termine è stato coniato dai ricercatori di Stanford nel 2021.) GPT di OpenAI, Gemini di Google, Llama di Meta e Claude di Anthropic sono tutti esempi di modelli di base. Molte aziende stanno anche commercializzando i loro modelli di IA come multimodali, il che significa che possono elaborare più tipi di dati, come testo, immagini e video.

**Modelli di frontiera:** Oltre ai modelli di base, le aziende di IA stanno lavorando su quelli che chiamano "modelli di frontiera", che è fondamentalmente solo un termine di marketing per i loro futuri modelli non ancora rilasciati. Teoricamente, questi modelli potrebbero essere molto più potenti dei modelli di IA disponibili oggi, anche se ci sono anche preoccupazioni che potrebbero comportare rischi significativi.

## Ma come fanno i modelli di IA a ottenere tutte quelle informazioni?

Beh, vengono addestrati. L'**addestramento** è un processo mediante il quale i modelli di IA imparano a comprendere i dati in modi specifici analizzando set di dati in modo da poter fare previsioni e riconoscere schemi. Ad esempio, i modelli di linguaggio di grandi dimensioni sono stati addestrati "leggendo" vaste quantità di testo. Ciò significa che quando strumenti di IA come ChatGPT rispondono alle tue domande, possono "capire" cosa stai dicendo e generare risposte che suonano come linguaggio umano e affrontano l'argomento della tua domanda.

L'addestramento spesso richiede una quantità significativa di risorse e potenza di calcolo, e molte aziende si affidano a potenti GPU per aiutare con questo addestramento. I modelli di IA possono essere alimentati con diversi tipi di dati, tipicamente in vaste quantità, come testo, immagini, musica e video. Questi sono — logicamente — noti come **dati di addestramento**.

I **parametri**, in breve, sono le variabili che un modello di IA apprende come parte del suo addestramento. La migliore descrizione che ho trovato di cosa significhi effettivamente viene da Helen Toner, la direttrice della strategia e delle sovvenzioni di ricerca fondamentale presso il Center for Security and Emerging Technology di Georgetown e ex membro del consiglio di OpenAI:

> I parametri sono i numeri all'interno di un modello di IA che determinano come un input (ad esempio, un pezzo di testo prompt) viene convertito in un output (ad esempio, la parola successiva dopo il prompt). Il processo di 'addestramento' di un modello di IA consiste nell'usare tecniche di ottimizzazione matematica per modificare i valori dei parametri del modello più e più volte finché il modello non è molto bravo a convertire input in output.

In altre parole, i parametri di un modello di IA aiutano a determinare le risposte che poi ti sputeranno fuori. Le aziende a volte si vantano di quanti parametri ha un modello come modo per dimostrare la complessità di quel modello.

## Ci sono altri termini che potrei incontrare?

**Elaborazione del linguaggio naturale (NLP):** La capacità delle macchine di comprendere il linguaggio umano grazie all'apprendimento automatico. ChatGPT di OpenAI è un esempio di base: può comprendere le tue query di testo e generare testo in risposta. Un altro potente strumento che può fare NLP è la tecnologia di riconoscimento vocale Whisper di OpenAI, che l'azienda ha usato per trascrivere audio da più di un milione di ore di video di YouTube per aiutare ad addestrare GPT-4.

**Inferenza:** Quando un'applicazione di IA generativa effettivamente genera qualcosa, come ChatGPT che risponde a una richiesta su come fare i biscotti con gocce di cioccolato condividendo una ricetta. Questo è il compito che il tuo computer esegue quando esegui comandi di IA locali.

**Token:** I token si riferiscono a pezzi di testo, come parole, parti di parole o anche singoli caratteri. Ad esempio, gli LLM suddivideranno il testo in token in modo da poterli analizzare, determinare come i token si relazionano tra loro e generare risposte. Più token un modello può elaborare contemporaneamente (una quantità nota come "finestra di contesto"), più sofisticati possono essere i risultati.

**Rete neurale:** Una rete neurale è un'architettura informatica che aiuta i computer a elaborare dati utilizzando nodi, che possono essere in qualche modo paragonati ai neuroni del cervello umano. Le reti neurali sono fondamentali per i popolari sistemi di IA generativa perché possono imparare a comprendere schemi complessi senza una programmazione esplicita — ad esempio, addestrandosi su dati medici per essere in grado di fare diagnosi.

**Transformer:** Un transformer è un tipo di architettura di rete neurale che utilizza un meccanismo di "attenzione" per elaborare come le parti di una sequenza si relazionano tra loro. Amazon ha un buon esempio di cosa significa questo in pratica:

> Considera questa sequenza di input: "Qual è il colore del cielo?" Il modello transformer utilizza una rappresentazione matematica interna che identifica la rilevanza e la relazione tra le parole colore, cielo e blu. Usa quella conoscenza per generare l'output: "Il cielo è blu."

Non solo i transformer sono molto potenti, ma possono anche essere addestrati più velocemente di altri tipi di reti neurali. Da quando ex dipendenti di Google hanno pubblicato il primo articolo sui transformer nel 2017, sono diventati una grande ragione per cui stiamo parlando così tanto delle tecnologie di IA generativa in questo momento. (La T in ChatGPT sta per transformer.)

**RAG:** Questo acronimo sta per "generazione aumentata dal recupero". Quando un modello di IA sta generando qualcosa, RAG permette al modello di trovare e aggiungere contesto da oltre ciò su cui è stato addestrato, il che può migliorare l'accuratezza di ciò che alla fine genera.

Supponiamo che tu chieda a un chatbot di IA qualcosa che, in base al suo addestramento, in realtà non conosce la risposta. Senza RAG, il chatbot potrebbe semplicemente allucinare una risposta sbagliata. Con RAG, tuttavia, può controllare fonti esterne — come, diciamo, altri siti su internet — e utilizzare quei dati per aiutare a informare la sua risposta.

## E l'hardware? Su cosa girano i sistemi di IA?

**Chip H100 di Nvidia:** Una delle unità di elaborazione grafica (GPU) più popolari utilizzate per l'addestramento dell'IA. Le aziende stanno facendo a gara per l'H100 perché è considerato il migliore nel gestire carichi di lavoro di IA rispetto ad altri chip AI di livello server. Tuttavia, mentre la straordinaria domanda per i chip di Nvidia l'ha resa una delle aziende più preziose al mondo, molte altre aziende tecnologiche stanno sviluppando i propri chip AI, che potrebbero erodere la presa di Nvidia sul mercato.

**Unità di elaborazione neurale (NPU):** Processori dedicati in computer, tablet e smartphone che possono eseguire inferenze di IA sul tuo dispositivo. (Apple usa il termine "motore neurale".) Le NPU possono essere più efficienti nell'esecuzione di molte attività alimentate dall'IA sui tuoi dispositivi (come aggiungere sfocatura dello sfondo durante una videochiamata) rispetto a una CPU o una GPU.

**TOPS:** Questo acronimo, che sta per "trilioni di operazioni al secondo", è un termine che i fornitori di tecnologia stanno usando per vantarsi di quanto siano capaci i loro chip nell'inferenza AI.

