
##### ChatGPT-4: una rivoluzione?

* ChatGPT-4 è una versione migliorata di ChatGPT, con importanti cambiamenti.
* È importante fare chiarezza sul marketing di questi modelli, che spesso crea false illusioni di umanità.
* I Large Language Models (LLM) come ChatGPT sono intelligenti, ma la loro intelligenza è diversa da quella umana.
* È fondamentale capire le differenze tra l'intelligenza artificiale e quella umana.

##### Cosa fa un Large Language Model?

* Un LLM è un software che completa il testo.
* Viene fornito un "prompt" (un frammento di testo) e l'algoritmo lo continua.
* Il meccanismo interno si chiama "prediction of the next token", ovvero la predizione del prossimo token (simile a una parola).
* L'LLM impara dai dati, analizzando miliardi di esempi di testo e cercando di predire la prossima parola più probabile.
* La "temperatura" è un parametro che controlla la creatività della predizione.

##### Come funziona la predizione?

* L'LLM non memorizza i fatti come Wikipedia, ma li elabora internamente.
* La predizione del prossimo token si basa su tutte le parole precedenti nel prompt.
* Questo spiega perché gli LLM possono commettere errori grossolani, soprattutto in compiti di ragionamento.
* Gli LLM non sono ragionatori logici, ma simulano il ragionamento attraverso la predizione di token.

##### Esempio: Strawberry e il problema del ragionamento

* Se si chiede a ChatGPT quante "R" ci sono in "Strawberry", risponde due invece di tre.
* Questo dimostra che il ragionamento di ChatGPT non è come quello umano.
* Non c'è una catena logica di nozioni, ma un meccanismo di predizione di token.

##### OpenAI e il problema del ragionamento

* OpenAI è consapevole dei limiti degli LLM in termini di ragionamento.
* Hanno sviluppato ChatGPT-4 per migliorare le capacità di ragionamento.
* Il nuovo modello si chiama "Strawberry" (nome non ufficiale), proprio per affrontare il problema del ragionamento.

##### Chain of Thought (CoT)

* Un modo per migliorare il ragionamento degli LLM è chiedere loro di spiegare i passaggi del loro ragionamento.
* Questo approccio si chiama "Chain of Thought" (CoT).
* Esempio: chiedere a ChatGPT di risolvere un problema logico e di spiegare i passaggi.
##### Problema iniziale:

* ChatGPT, pur essendo in grado di generare testo, non riesce a ragionare in modo logico e matematico.
* Esempio: se gli si chiede il numero di blocchi rossi in una torre, fornisce una risposta errata (8) invece della corretta (20).

##### Soluzione: Chain of Thought (CoT)

* Per sollecitare ChatGPT a ragionare in modo più corretto, si può utilizzare il metodo "Chain of Thought" (CoT).
* CoT consiste nel chiedere a ChatGPT di illustrare i passaggi del suo ragionamento uno per uno.
* Esempio: "Determina il numero di blocchi gialli... Calcola il numero totale di blocchi blu e gialli... Determina il numero di blocchi rossi...".

##### Come funziona CoT?

* CoT sfrutta il meccanismo di predizione di token di ChatGPT.
* Fornendo a ChatGPT una serie di token (parole) che descrivono i passaggi del ragionamento, si influenza la predizione del prossimo token.
* In questo modo, ChatGPT è "guidato" a generare una risposta più accurata.

##### CoT come base di ChatGPT-4:

* L'idea di CoT è stata così efficace che è diventata la base del nuovo modello di ChatGPT, ChatGPT-4 (o1).
* ChatGPT-4 è stato addestrato a generare risposte in forma di catena di ragionamento (CoT) in modo nativo.
* L'esperienza di utilizzo di ChatGPT-4 è diversa: invece di ottenere una risposta immediata, si vede un messaggio "I'm thinking" mentre il modello genera la catena di ragionamento.

##### Miglioramenti di ChatGPT-4:

* ChatGPT-4 mostra un miglioramento significativo nella capacità di rispondere correttamente alle domande.
* Questo miglioramento è dovuto sia all'aumento del tempo di addestramento (training) sia all'utilizzo di CoT.
* Si è scoperto che anche durante la fase di inferenza (quando il modello genera la risposta), il tempo dedicato alla generazione di catene di ragionamento influenza positivamente la precisione.

##### Come funziona ChatGPT-4?

* OpenAI non ha rivelato dettagli precisi sul funzionamento interno di ChatGPT-4.
* Si ipotizza che il modello utilizzi il Reinforcement Learning (RL) applicato a CoT.
* RL consiste nell'addestrare un modello a compiere azioni che massimizzano una ricompensa (reward).

##### Reinforcement Learning in ChatGPT-4:

* Per addestrare ChatGPT-4 a generare catene di ragionamento corrette, si utilizzano due modelli di ricompensa (reward models):
 * **Outcome reward model:** valuta la correttezza della risposta finale.
 * **Process reward model:** valuta la correttezza dei passaggi intermedi della catena di ragionamento.
* Questi modelli vengono addestrati su dati sintetici (per l'outcome) e su dati annotati da umani (per il process).
* **Processo:**
 1. Si fa una domanda a ChatGPT-4.
 2. ChatGPT-4 genera una catena di ragionamento e una risposta finale.
 3. I due modelli di ricompensa valutano la catena e la risposta.
 4. ChatGPT-4 riceve un feedback sui suoi errori e aggiorna la sua rappresentazione interna per migliorare la generazione di CoT.
* **Importanza:** RL è costoso, soprattutto per la parte supervised, ma permette di ottenere miglioramenti significativi nelle prestazioni.

##### Fase di Inferenza (Utilizzo)

* **Problema:** OpenAI non rivela i dettagli del processo di inferenza di ChatGPT-4.
* **Ipotesi:** ChatGPT-4 genera diverse catene di ragionamento e poi ne crea un riassunto per produrre la risposta finale.
* **Motivazione:** OpenAI nasconde le catene di ragionamento per motivi di competitività e per evitare manipolazioni da parte del modello.
* **Conseguenze:** Non si ha accesso al processo di ragionamento di ChatGPT-4, solo alla risposta finale e a un riassunto delle idee principali.

##### Confronto tra ChatGPT-4 e versioni precedenti:

* ChatGPT-4 mostra un miglioramento significativo nelle prestazioni, soprattutto nei compiti di calcolo matematico.
* Questo miglioramento è dovuto all'addestramento con RL e all'utilizzo di CoT.
* Tuttavia, ChatGPT-4 non è un ragionatore logico come gli umani.

##### Interpretazione di ChatGPT-4:

* ChatGPT-4 è stato addestrato a generare testo come una serie di passaggi di ragionamento, ma non significa che stia effettivamente ragionando.
* È importante non personificare il modello e non attribuirgli capacità di ragionamento umano.
* ChatGPT-4 è un modello di linguaggio che si basa su dati e che è stato addestrato a generare risposte che sembrano ragionevoli.

##### Conclusione:

* ChatGPT-4 è un modello di linguaggio potente che ha fatto progressi significativi nella capacità di generare risposte che sembrano ragionevoli.
* Tuttavia, è importante ricordare che il modello non è un ragionatore logico come gli umani e che il suo funzionamento interno è ancora in parte sconosciuto.
* È fondamentale utilizzare ChatGPT-4 in modo consapevole e non attribuirgli capacità che non possiede.

